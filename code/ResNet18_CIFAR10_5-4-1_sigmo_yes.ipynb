{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/ndb796/Deep-Learning-Paper-Review-and-Practice/blob/master/code_practices/ResNet18_CIFAR10_Train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "\n",
    "torch.cuda.is_available()\n",
    "\n",
    "start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed(0)\n",
    "torch.cuda.manual_seed_all(0)\n",
    "cudnn.benchmark = False\n",
    "cudnn.deterministic = True\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x2SSsQMSknm2"
   },
   "source": [
    "#### ResNet18 모델 정의 및 인스턴스 초기화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "zpUcgk5xkgGZ"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import os\n",
    "\n",
    "\n",
    "# ResNet18을 위해 최대한 간단히 수정한 BasicBlock 클래스 정의\n",
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "\n",
    "        # 3x3 필터를 사용 (너비와 높이를 줄일 때는 stride 값 조절)\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes) # 배치 정규화(batch normalization)\n",
    "\n",
    "        # 3x3 필터를 사용 (패딩을 1만큼 주기 때문에 너비와 높이가 동일)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes) # 배치 정규화(batch normalization)\n",
    "\n",
    "        self.shortcut = nn.Sequential() # identity인 경우\n",
    "        if stride != 1: # stride가 1이 아니라면, Identity mapping이 아닌 경우\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, planes, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.sigmoid(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x) # (핵심) skip connection\n",
    "        out = F.sigmoid(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "# ResNet 클래스 정의\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 64\n",
    "\n",
    "        # 64개의 3x3 필터(filter)를 사용\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "        self.linear = nn.Linear(512, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1] * (num_blocks - 1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes # 다음 레이어를 위해 채널 수 변경\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.sigmoid(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "# ResNet18 함수 정의\n",
    "def ResNet18():\n",
    "    return ResNet(BasicBlock, [2, 2, 2, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nCNacrgtktlr"
   },
   "source": [
    "#### 데이터셋(Dataset) 다운로드 및 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 125,
     "referenced_widgets": [
      "c33e7c07bfc847efa64429ee4eb640db",
      "987ce5cdc16f4c568f979204fa7506f2",
      "0dea8eb11bbc4c779008942559cff4db",
      "0ec3fad637ae4f5d8f9aa3a84e2cd7bd",
      "ff98ccdfba314fe5a6d9e477c6d4bd4b",
      "a1d1034a83034942b9174d8a46447ef0",
      "516e46a6995e4c10b928f2dbbbdd005a",
      "1c9448bb0e7b4d4bb219f9313bff333f"
     ]
    },
    "id": "EmmQZ8p5kq_C",
    "outputId": "ae6624d1-332f-412c-b2fc-51141afb1520"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import ConcatDataset\n",
    "\n",
    "\n",
    "data_transformations = {\n",
    "    \"crop_flip\": transforms.Compose([  # 크롭 + 뒤집기\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),]), \n",
    "\n",
    "    \"color_blur\": transforms.Compose([  # 색깔 + 블러\n",
    "     transforms.ColorJitter(brightness=(0.5, 0.9), \n",
    "                           contrast=(0.4, 0.8), \n",
    "                           saturation=(0.7, 0.9),\n",
    "                           hue=(-0.2, 0.2),\n",
    "                          ),\n",
    "    transforms.GaussianBlur(kernel_size=(19, 19), sigma=(1.0, 2.0)),\n",
    "    transforms.ToTensor()]),\n",
    "\n",
    "    \"basic\": transforms.Compose([\n",
    "    transforms.ToTensor()])\n",
    "}\n",
    "\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=data_transformations[\"basic\"])\n",
    "train_aug_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, transform=data_transformations[\"crop_flip\"])\n",
    "train_aug_dataset2 = torchvision.datasets.CIFAR10(root='./data', train=True, transform=data_transformations[\"color_blur\"])\n",
    "                                                  \n",
    "augmented_train_data = ConcatDataset((train_dataset,train_aug_dataset, train_aug_dataset2 ))\n",
    "\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=data_transformations[\"basic\"])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(augmented_train_data, batch_size=128, shuffle=True, num_workers=4)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=100, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dl1-47E7pHD_"
   },
   "source": [
    "#### 환경 설정 및 학습(Training) 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "bhm_eVykk-Z8"
   },
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "\n",
    "net = ResNet18()\n",
    "net = net.to(device)\n",
    "net = torch.nn.DataParallel(net)\n",
    "cudnn.benchmark = True\n",
    "\n",
    "learning_rate = 0.1\n",
    "file_name = 'resnet18_cifar10.pt'\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9, weight_decay=0.0002)\n",
    "\n",
    "\n",
    "def train(epoch):\n",
    "    print('\\n[ Train epoch: %d ]' % epoch)\n",
    "    net.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        benign_outputs = net(inputs)\n",
    "        loss = criterion(benign_outputs, targets)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = benign_outputs.max(1)\n",
    "\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "        \n",
    "        if batch_idx % 100 == 0:\n",
    "            print('\\nCurrent batch:', str(batch_idx))\n",
    "            print('Current benign train accuracy:', str(predicted.eq(targets).sum().item() / targets.size(0)))\n",
    "            print('Current benign train loss:', loss.item())\n",
    "\n",
    "    print('\\nTotal benign train accuarcy:', 100. * correct / total)\n",
    "    print('Total benign train loss:', train_loss)\n",
    "\n",
    "\n",
    "def test(epoch):\n",
    "    print('\\n[ Test epoch: %d ]' % epoch)\n",
    "    net.eval()\n",
    "    loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for batch_idx, (inputs, targets) in enumerate(test_loader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        total += targets.size(0)\n",
    "\n",
    "        outputs = net(inputs)\n",
    "        loss += criterion(outputs, targets).item()\n",
    "\n",
    "        _, predicted = outputs.max(1)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "    print('\\nTest accuarcy:', 100. * correct / total)\n",
    "    print('Test average loss:', loss / total)\n",
    "\n",
    "    state = {\n",
    "        'net': net.state_dict()\n",
    "    }\n",
    "    if not os.path.isdir('checkpoint'):\n",
    "        os.mkdir('checkpoint')\n",
    "    torch.save(state, './checkpoint/' + file_name)\n",
    "    print('Model Saved!')\n",
    "\n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    lr = learning_rate\n",
    "    if epoch >= 50:\n",
    "        lr = 0.01\n",
    "    if epoch >= 90:\n",
    "        lr = 0.001\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0mv5z7CEMRrn"
   },
   "source": [
    "#### 학습(Training) 진행"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IFdh-H1MPf0c"
   },
   "source": [
    "* 대략 20번의 epoch 이후에도 85%가량의 test accuracy를 얻을 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "4voLj7TKlaB1",
    "outputId": "76463b85-2f4f-4bc0-a945-c73cc669c67e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ Train epoch: 0 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.0625\n",
      "Current benign train loss: 2.3492259979248047\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.25\n",
      "Current benign train loss: 5.259955406188965\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.1640625\n",
      "Current benign train loss: 2.2781264781951904\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.234375\n",
      "Current benign train loss: 2.1446478366851807\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.3046875\n",
      "Current benign train loss: 2.0405046939849854\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.25\n",
      "Current benign train loss: 2.2752797603607178\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.2578125\n",
      "Current benign train loss: 2.0282793045043945\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.2421875\n",
      "Current benign train loss: 2.13023042678833\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.296875\n",
      "Current benign train loss: 2.016525983810425\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.3203125\n",
      "Current benign train loss: 1.9906177520751953\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.375\n",
      "Current benign train loss: 1.829494595527649\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.3515625\n",
      "Current benign train loss: 1.8189588785171509\n",
      "\n",
      "Total benign train accuarcy: 24.840666666666667\n",
      "Total benign train loss: 3140.728483080864\n",
      "\n",
      "[ Test epoch: 0 ]\n",
      "\n",
      "Test accuarcy: 17.17\n",
      "Test average loss: 0.04483401942253113\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 1 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.3671875\n",
      "Current benign train loss: 1.602442979812622\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.3828125\n",
      "Current benign train loss: 1.6596388816833496\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.3828125\n",
      "Current benign train loss: 1.758766531944275\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.3203125\n",
      "Current benign train loss: 1.814286231994629\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.3515625\n",
      "Current benign train loss: 1.6705559492111206\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.40625\n",
      "Current benign train loss: 1.7221132516860962\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.46875\n",
      "Current benign train loss: 1.5474965572357178\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.390625\n",
      "Current benign train loss: 1.6598376035690308\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.4375\n",
      "Current benign train loss: 1.6329768896102905\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.4453125\n",
      "Current benign train loss: 1.4696624279022217\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.46875\n",
      "Current benign train loss: 1.436025857925415\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.3984375\n",
      "Current benign train loss: 1.7725507020950317\n",
      "\n",
      "Total benign train accuarcy: 41.40533333333333\n",
      "Total benign train loss: 1899.294646859169\n",
      "\n",
      "[ Test epoch: 1 ]\n",
      "\n",
      "Test accuarcy: 22.29\n",
      "Test average loss: 0.03663166224956513\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 2 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.4140625\n",
      "Current benign train loss: 1.5576473474502563\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.484375\n",
      "Current benign train loss: 1.48432457447052\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.4765625\n",
      "Current benign train loss: 1.5124284029006958\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.4921875\n",
      "Current benign train loss: 1.24570894241333\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.421875\n",
      "Current benign train loss: 1.6195998191833496\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.40625\n",
      "Current benign train loss: 1.6256804466247559\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.53125\n",
      "Current benign train loss: 1.342210054397583\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.46875\n",
      "Current benign train loss: 1.4337453842163086\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.4765625\n",
      "Current benign train loss: 1.4632412195205688\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.4609375\n",
      "Current benign train loss: 1.5618987083435059\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.5234375\n",
      "Current benign train loss: 1.2200106382369995\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.5078125\n",
      "Current benign train loss: 1.4043872356414795\n",
      "\n",
      "Total benign train accuarcy: 49.718\n",
      "Total benign train loss: 1640.930825829506\n",
      "\n",
      "[ Test epoch: 2 ]\n",
      "\n",
      "Test accuarcy: 29.69\n",
      "Test average loss: 0.03475383386611938\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 3 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.5546875\n",
      "Current benign train loss: 1.1599096059799194\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.53125\n",
      "Current benign train loss: 1.2539751529693604\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.515625\n",
      "Current benign train loss: 1.3345202207565308\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.5625\n",
      "Current benign train loss: 1.5385843515396118\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.6015625\n",
      "Current benign train loss: 1.1280778646469116\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.5234375\n",
      "Current benign train loss: 1.2807046175003052\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.5703125\n",
      "Current benign train loss: 1.149761438369751\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.5859375\n",
      "Current benign train loss: 1.2142970561981201\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.5234375\n",
      "Current benign train loss: 1.3311309814453125\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.6640625\n",
      "Current benign train loss: 0.9603280425071716\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.546875\n",
      "Current benign train loss: 1.2590630054473877\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.4921875\n",
      "Current benign train loss: 1.4536938667297363\n",
      "\n",
      "Total benign train accuarcy: 55.580666666666666\n",
      "Total benign train loss: 1467.2188338637352\n",
      "\n",
      "[ Test epoch: 3 ]\n",
      "\n",
      "Test accuarcy: 15.25\n",
      "Test average loss: 0.04117860884666443\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 4 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.5546875\n",
      "Current benign train loss: 1.1502039432525635\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.5859375\n",
      "Current benign train loss: 1.1426665782928467\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.5859375\n",
      "Current benign train loss: 1.1369866132736206\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.6015625\n",
      "Current benign train loss: 1.18728506565094\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.5234375\n",
      "Current benign train loss: 1.1427313089370728\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.546875\n",
      "Current benign train loss: 1.2912763357162476\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.5234375\n",
      "Current benign train loss: 1.3506768941879272\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.6015625\n",
      "Current benign train loss: 1.1313668489456177\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.5859375\n",
      "Current benign train loss: 1.1699638366699219\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.625\n",
      "Current benign train loss: 1.1194579601287842\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.6484375\n",
      "Current benign train loss: 0.9205101728439331\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.6640625\n",
      "Current benign train loss: 1.0248464345932007\n",
      "\n",
      "Total benign train accuarcy: 58.71\n",
      "Total benign train loss: 1370.503515303135\n",
      "\n",
      "[ Test epoch: 4 ]\n",
      "\n",
      "Test accuarcy: 19.58\n",
      "Test average loss: 0.03616460485458374\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 5 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.65625\n",
      "Current benign train loss: 1.0114388465881348\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.6484375\n",
      "Current benign train loss: 1.0140447616577148\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.6171875\n",
      "Current benign train loss: 1.16416335105896\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.625\n",
      "Current benign train loss: 0.9824109673500061\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.6171875\n",
      "Current benign train loss: 1.014574646949768\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.609375\n",
      "Current benign train loss: 0.9703977108001709\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.6328125\n",
      "Current benign train loss: 0.9791516661643982\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.6484375\n",
      "Current benign train loss: 1.0173488855361938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.625\n",
      "Current benign train loss: 1.1469601392745972\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.65625\n",
      "Current benign train loss: 1.0290660858154297\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.6640625\n",
      "Current benign train loss: 1.046841025352478\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.6796875\n",
      "Current benign train loss: 0.9467443227767944\n",
      "\n",
      "Total benign train accuarcy: 62.184666666666665\n",
      "Total benign train loss: 1260.392986357212\n",
      "\n",
      "[ Test epoch: 5 ]\n",
      "\n",
      "Test accuarcy: 34.66\n",
      "Test average loss: 0.03425693490505218\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 6 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.6796875\n",
      "Current benign train loss: 0.8838958144187927\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.71875\n",
      "Current benign train loss: 0.9818999171257019\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.640625\n",
      "Current benign train loss: 0.9619137048721313\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.6796875\n",
      "Current benign train loss: 1.0317285060882568\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.71875\n",
      "Current benign train loss: 0.8385255932807922\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.6640625\n",
      "Current benign train loss: 0.9614452719688416\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.640625\n",
      "Current benign train loss: 1.09068763256073\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.640625\n",
      "Current benign train loss: 1.0659313201904297\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.65625\n",
      "Current benign train loss: 0.9543055891990662\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.609375\n",
      "Current benign train loss: 1.0366612672805786\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.6328125\n",
      "Current benign train loss: 1.1053794622421265\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.734375\n",
      "Current benign train loss: 0.9202859997749329\n",
      "\n",
      "Total benign train accuarcy: 64.274\n",
      "Total benign train loss: 1200.4835542440414\n",
      "\n",
      "[ Test epoch: 6 ]\n",
      "\n",
      "Test accuarcy: 28.08\n",
      "Test average loss: 0.0342372686624527\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 7 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.6953125\n",
      "Current benign train loss: 0.8726786375045776\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.6171875\n",
      "Current benign train loss: 1.0037363767623901\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.6484375\n",
      "Current benign train loss: 0.9271056056022644\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.5859375\n",
      "Current benign train loss: 1.1257538795471191\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.59375\n",
      "Current benign train loss: 1.069467306137085\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.6171875\n",
      "Current benign train loss: 1.0156831741333008\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.7421875\n",
      "Current benign train loss: 0.8113554120063782\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.5859375\n",
      "Current benign train loss: 1.1900761127471924\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.7265625\n",
      "Current benign train loss: 0.9032825231552124\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.5625\n",
      "Current benign train loss: 1.2034822702407837\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.65625\n",
      "Current benign train loss: 0.9944231510162354\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.640625\n",
      "Current benign train loss: 1.0021330118179321\n",
      "\n",
      "Total benign train accuarcy: 65.59666666666666\n",
      "Total benign train loss: 1155.6793295741081\n",
      "\n",
      "[ Test epoch: 7 ]\n",
      "\n",
      "Test accuarcy: 35.47\n",
      "Test average loss: 0.027750733947753906\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 8 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.5859375\n",
      "Current benign train loss: 0.96086585521698\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.671875\n",
      "Current benign train loss: 0.9223635792732239\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.59375\n",
      "Current benign train loss: 1.1290172338485718\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.7109375\n",
      "Current benign train loss: 0.8518723249435425\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.8125\n",
      "Current benign train loss: 0.6260121464729309\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.5859375\n",
      "Current benign train loss: 1.1444696187973022\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.7109375\n",
      "Current benign train loss: 0.8231327533721924\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.7421875\n",
      "Current benign train loss: 0.7622172236442566\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.6796875\n",
      "Current benign train loss: 0.9778013229370117\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.609375\n",
      "Current benign train loss: 1.086803674697876\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.6640625\n",
      "Current benign train loss: 0.8981465697288513\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.6953125\n",
      "Current benign train loss: 0.9558203816413879\n",
      "\n",
      "Total benign train accuarcy: 66.70333333333333\n",
      "Total benign train loss: 1116.993435561657\n",
      "\n",
      "[ Test epoch: 8 ]\n",
      "\n",
      "Test accuarcy: 33.51\n",
      "Test average loss: 0.030649742150306702\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 9 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.734375\n",
      "Current benign train loss: 0.7738200426101685\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.703125\n",
      "Current benign train loss: 0.7720165252685547\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.6484375\n",
      "Current benign train loss: 0.9749001264572144\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.7734375\n",
      "Current benign train loss: 0.6734839081764221\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.6953125\n",
      "Current benign train loss: 0.9493659138679504\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.7265625\n",
      "Current benign train loss: 0.8632469177246094\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.734375\n",
      "Current benign train loss: 0.7265336513519287\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.7265625\n",
      "Current benign train loss: 0.9131374955177307\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.6328125\n",
      "Current benign train loss: 1.003970980644226\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.734375\n",
      "Current benign train loss: 0.8204576373100281\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.6953125\n",
      "Current benign train loss: 0.9397558569908142\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.71875\n",
      "Current benign train loss: 0.7589627504348755\n",
      "\n",
      "Total benign train accuarcy: 68.15466666666667\n",
      "Total benign train loss: 1072.1956257224083\n",
      "\n",
      "[ Test epoch: 9 ]\n",
      "\n",
      "Test accuarcy: 32.65\n",
      "Test average loss: 0.04228371567726135\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 10 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.640625\n",
      "Current benign train loss: 1.0024468898773193\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.75\n",
      "Current benign train loss: 0.7421276569366455\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.7109375\n",
      "Current benign train loss: 0.871961772441864\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.671875\n",
      "Current benign train loss: 0.9353817701339722\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.6328125\n",
      "Current benign train loss: 1.0908403396606445\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.6796875\n",
      "Current benign train loss: 0.9165443181991577\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.6640625\n",
      "Current benign train loss: 0.9494016170501709\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.6328125\n",
      "Current benign train loss: 1.135993480682373\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.6796875\n",
      "Current benign train loss: 0.9620453715324402\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.6796875\n",
      "Current benign train loss: 1.0805425643920898\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.7421875\n",
      "Current benign train loss: 0.774819016456604\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.6171875\n",
      "Current benign train loss: 1.0515451431274414\n",
      "\n",
      "Total benign train accuarcy: 68.59533333333333\n",
      "Total benign train loss: 1060.365757882595\n",
      "\n",
      "[ Test epoch: 10 ]\n",
      "\n",
      "Test accuarcy: 23.18\n",
      "Test average loss: 0.05268630881309509\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 11 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.71875\n",
      "Current benign train loss: 0.894698441028595\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.78125\n",
      "Current benign train loss: 0.6654548048973083\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.6953125\n",
      "Current benign train loss: 0.9318276047706604\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.765625\n",
      "Current benign train loss: 0.7105392217636108\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.671875\n",
      "Current benign train loss: 0.9131094217300415\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.6875\n",
      "Current benign train loss: 0.8688023686408997\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.6796875\n",
      "Current benign train loss: 0.8606628775596619\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.59375\n",
      "Current benign train loss: 1.1537410020828247\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.7109375\n",
      "Current benign train loss: 0.8493379354476929\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.6953125\n",
      "Current benign train loss: 0.8873419761657715\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.6328125\n",
      "Current benign train loss: 0.9816259145736694\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.7578125\n",
      "Current benign train loss: 0.6945039629936218\n",
      "\n",
      "Total benign train accuarcy: 69.65733333333333\n",
      "Total benign train loss: 1021.8133013248444\n",
      "\n",
      "[ Test epoch: 11 ]\n",
      "\n",
      "Test accuarcy: 41.89\n",
      "Test average loss: 0.034288860821723936\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 12 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.71875\n",
      "Current benign train loss: 0.7819612622261047\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.640625\n",
      "Current benign train loss: 1.0035665035247803\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.6640625\n",
      "Current benign train loss: 0.916057288646698\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.7734375\n",
      "Current benign train loss: 0.8382620811462402\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.7109375\n",
      "Current benign train loss: 0.8501638174057007\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.6796875\n",
      "Current benign train loss: 1.098275899887085\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.75\n",
      "Current benign train loss: 0.7714892625808716\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.7578125\n",
      "Current benign train loss: 0.6573764085769653\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.734375\n",
      "Current benign train loss: 0.7407227158546448\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.75\n",
      "Current benign train loss: 0.85252445936203\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.75\n",
      "Current benign train loss: 0.9035412669181824\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.640625\n",
      "Current benign train loss: 0.9924419522285461\n",
      "\n",
      "Total benign train accuarcy: 70.184\n",
      "Total benign train loss: 1007.2194905877113\n",
      "\n",
      "[ Test epoch: 12 ]\n",
      "\n",
      "Test accuarcy: 14.63\n",
      "Test average loss: 0.07811966018676758\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 13 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.7265625\n",
      "Current benign train loss: 0.747931182384491\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.6640625\n",
      "Current benign train loss: 0.9181559681892395\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.6796875\n",
      "Current benign train loss: 0.9186303615570068\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.71875\n",
      "Current benign train loss: 0.9019355773925781\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.6953125\n",
      "Current benign train loss: 0.8695253729820251\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.7421875\n",
      "Current benign train loss: 0.7600099444389343\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.7265625\n",
      "Current benign train loss: 0.8266645073890686\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.71875\n",
      "Current benign train loss: 0.914246141910553\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.7109375\n",
      "Current benign train loss: 0.7982335090637207\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.7109375\n",
      "Current benign train loss: 0.8173750638961792\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.7265625\n",
      "Current benign train loss: 0.7938673496246338\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.6640625\n",
      "Current benign train loss: 0.8992517590522766\n",
      "\n",
      "Total benign train accuarcy: 70.69466666666666\n",
      "Total benign train loss: 989.8329887390137\n",
      "\n",
      "[ Test epoch: 13 ]\n",
      "\n",
      "Test accuarcy: 37.55\n",
      "Test average loss: 0.0408789318561554\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 14 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.65625\n",
      "Current benign train loss: 1.037684440612793\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.7578125\n",
      "Current benign train loss: 0.7781750559806824\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.7421875\n",
      "Current benign train loss: 0.770779550075531\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.796875\n",
      "Current benign train loss: 0.5526029467582703\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.7421875\n",
      "Current benign train loss: 0.7722696661949158\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.75\n",
      "Current benign train loss: 0.7864841222763062\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.5625\n",
      "Current benign train loss: 1.18729567527771\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.71875\n",
      "Current benign train loss: 0.7971535921096802\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.7421875\n",
      "Current benign train loss: 0.7703140377998352\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.8046875\n",
      "Current benign train loss: 0.6288284659385681\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.734375\n",
      "Current benign train loss: 0.8756726980209351\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.7421875\n",
      "Current benign train loss: 0.8157703280448914\n",
      "\n",
      "Total benign train accuarcy: 71.626\n",
      "Total benign train loss: 965.7393457889557\n",
      "\n",
      "[ Test epoch: 14 ]\n",
      "\n",
      "Test accuarcy: 11.86\n",
      "Test average loss: 0.08387372789382934\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 15 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.734375\n",
      "Current benign train loss: 0.758659303188324\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.6796875\n",
      "Current benign train loss: 0.9005241990089417\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.7421875\n",
      "Current benign train loss: 0.8088982105255127\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.703125\n",
      "Current benign train loss: 0.770451009273529\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.7578125\n",
      "Current benign train loss: 0.6797441244125366\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.7578125\n",
      "Current benign train loss: 0.7513246536254883\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.6640625\n",
      "Current benign train loss: 1.0474584102630615\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.7109375\n",
      "Current benign train loss: 0.796802282333374\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.7265625\n",
      "Current benign train loss: 0.8305254578590393\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.7421875\n",
      "Current benign train loss: 0.7195816040039062\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.7109375\n",
      "Current benign train loss: 0.8412883281707764\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.7890625\n",
      "Current benign train loss: 0.7437312602996826\n",
      "\n",
      "Total benign train accuarcy: 71.764\n",
      "Total benign train loss: 958.1713872253895\n",
      "\n",
      "[ Test epoch: 15 ]\n",
      "\n",
      "Test accuarcy: 19.82\n",
      "Test average loss: 0.08270265216827392\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 16 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.7578125\n",
      "Current benign train loss: 0.719566822052002\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.75\n",
      "Current benign train loss: 0.7465317845344543\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.71875\n",
      "Current benign train loss: 0.8215616941452026\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.7421875\n",
      "Current benign train loss: 0.7235126495361328\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.7109375\n",
      "Current benign train loss: 0.8981642723083496\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.8359375\n",
      "Current benign train loss: 0.5474061965942383\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.7265625\n",
      "Current benign train loss: 0.7887076139450073\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.734375\n",
      "Current benign train loss: 0.7461240887641907\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.75\n",
      "Current benign train loss: 0.7316787838935852\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.703125\n",
      "Current benign train loss: 0.8675180077552795\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.6953125\n",
      "Current benign train loss: 0.8085516095161438\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.8203125\n",
      "Current benign train loss: 0.6751338243484497\n",
      "\n",
      "Total benign train accuarcy: 72.52133333333333\n",
      "Total benign train loss: 935.462976694107\n",
      "\n",
      "[ Test epoch: 16 ]\n",
      "\n",
      "Test accuarcy: 33.87\n",
      "Test average loss: 0.027510344982147217\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 17 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.8046875\n",
      "Current benign train loss: 0.6120865345001221\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.7109375\n",
      "Current benign train loss: 0.8232333660125732\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.7421875\n",
      "Current benign train loss: 0.7495113611221313\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.75\n",
      "Current benign train loss: 0.8463245034217834\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.7421875\n",
      "Current benign train loss: 0.7858662605285645\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.71875\n",
      "Current benign train loss: 0.8843191862106323\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.7578125\n",
      "Current benign train loss: 0.7429903745651245\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.765625\n",
      "Current benign train loss: 0.7970980405807495\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.7890625\n",
      "Current benign train loss: 0.5992322564125061\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.7265625\n",
      "Current benign train loss: 0.8382446765899658\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.6796875\n",
      "Current benign train loss: 0.8583267331123352\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.6953125\n",
      "Current benign train loss: 0.7741117477416992\n",
      "\n",
      "Total benign train accuarcy: 72.73133333333334\n",
      "Total benign train loss: 924.0654158890247\n",
      "\n",
      "[ Test epoch: 17 ]\n",
      "\n",
      "Test accuarcy: 52.97\n",
      "Test average loss: 0.020514091038703917\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 18 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.7421875\n",
      "Current benign train loss: 0.6609024405479431\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.7734375\n",
      "Current benign train loss: 0.6460721492767334\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.765625\n",
      "Current benign train loss: 0.6740213632583618\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.7890625\n",
      "Current benign train loss: 0.6461371183395386\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.765625\n",
      "Current benign train loss: 0.6907184720039368\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.75\n",
      "Current benign train loss: 0.831669270992279\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.7734375\n",
      "Current benign train loss: 0.6486427187919617\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.734375\n",
      "Current benign train loss: 0.7229655981063843\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.734375\n",
      "Current benign train loss: 0.898699164390564\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.6640625\n",
      "Current benign train loss: 0.8028992414474487\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.640625\n",
      "Current benign train loss: 1.0501629114151\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.734375\n",
      "Current benign train loss: 0.6971760392189026\n",
      "\n",
      "Total benign train accuarcy: 73.424\n",
      "Total benign train loss: 905.1441044211388\n",
      "\n",
      "[ Test epoch: 18 ]\n",
      "\n",
      "Test accuarcy: 35.03\n",
      "Test average loss: 0.030198673343658448\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 19 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.6640625\n",
      "Current benign train loss: 0.829846978187561\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.6875\n",
      "Current benign train loss: 0.8987440466880798\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.6953125\n",
      "Current benign train loss: 0.8392360210418701\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.734375\n",
      "Current benign train loss: 0.8480920195579529\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.75\n",
      "Current benign train loss: 0.7483401894569397\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.7890625\n",
      "Current benign train loss: 0.7106553912162781\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.6640625\n",
      "Current benign train loss: 0.9577459692955017\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.796875\n",
      "Current benign train loss: 0.6856231689453125\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.7578125\n",
      "Current benign train loss: 0.6678821444511414\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.7734375\n",
      "Current benign train loss: 0.7044519782066345\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.8515625\n",
      "Current benign train loss: 0.5279313921928406\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.765625\n",
      "Current benign train loss: 0.6405426859855652\n",
      "\n",
      "Total benign train accuarcy: 73.22\n",
      "Total benign train loss: 906.8984381556511\n",
      "\n",
      "[ Test epoch: 19 ]\n",
      "\n",
      "Test accuarcy: 45.78\n",
      "Test average loss: 0.023666758394241334\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 20 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.78125\n",
      "Current benign train loss: 0.7578729391098022\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.7109375\n",
      "Current benign train loss: 0.9083322882652283\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.703125\n",
      "Current benign train loss: 0.951587438583374\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.796875\n",
      "Current benign train loss: 0.6214999556541443\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.7734375\n",
      "Current benign train loss: 0.7212364673614502\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.765625\n",
      "Current benign train loss: 0.7810867428779602\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.7421875\n",
      "Current benign train loss: 0.6884649395942688\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.7578125\n",
      "Current benign train loss: 0.7470006346702576\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.8125\n",
      "Current benign train loss: 0.566006064414978\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.65625\n",
      "Current benign train loss: 1.0648058652877808\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.734375\n",
      "Current benign train loss: 0.8249318599700928\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.734375\n",
      "Current benign train loss: 0.681784987449646\n",
      "\n",
      "Total benign train accuarcy: 73.65666666666667\n",
      "Total benign train loss: 900.1612161099911\n",
      "\n",
      "[ Test epoch: 20 ]\n",
      "\n",
      "Test accuarcy: 57.76\n",
      "Test average loss: 0.015175137269496918\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 21 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.796875\n",
      "Current benign train loss: 0.6174391508102417\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.6875\n",
      "Current benign train loss: 0.8765789866447449\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.7734375\n",
      "Current benign train loss: 0.6265665888786316\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.75\n",
      "Current benign train loss: 0.6898816227912903\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.6796875\n",
      "Current benign train loss: 0.9121508002281189\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.7890625\n",
      "Current benign train loss: 0.7353085875511169\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.7421875\n",
      "Current benign train loss: 0.7135874629020691\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.765625\n",
      "Current benign train loss: 0.7805823087692261\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.734375\n",
      "Current benign train loss: 0.8085598349571228\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.75\n",
      "Current benign train loss: 0.6586096286773682\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.71875\n",
      "Current benign train loss: 0.8761498332023621\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.7734375\n",
      "Current benign train loss: 0.7743538618087769\n",
      "\n",
      "Total benign train accuarcy: 74.11\n",
      "Total benign train loss: 879.232738494873\n",
      "\n",
      "[ Test epoch: 21 ]\n",
      "\n",
      "Test accuarcy: 26.81\n",
      "Test average loss: 0.04126989371776581\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 22 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.71875\n",
      "Current benign train loss: 0.8276349306106567\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.7734375\n",
      "Current benign train loss: 0.5942398309707642\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.7734375\n",
      "Current benign train loss: 0.6896080374717712\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.703125\n",
      "Current benign train loss: 0.8173459768295288\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.71875\n",
      "Current benign train loss: 0.7996648550033569\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.75\n",
      "Current benign train loss: 0.7240889072418213\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.78125\n",
      "Current benign train loss: 0.6624529361724854\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.7421875\n",
      "Current benign train loss: 0.7692282795906067\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.6640625\n",
      "Current benign train loss: 1.0093878507614136\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.7265625\n",
      "Current benign train loss: 0.7377869486808777\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.703125\n",
      "Current benign train loss: 0.826921284198761\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.796875\n",
      "Current benign train loss: 0.6497030854225159\n",
      "\n",
      "Total benign train accuarcy: 74.488\n",
      "Total benign train loss: 869.8129425644875\n",
      "\n",
      "[ Test epoch: 22 ]\n",
      "\n",
      "Test accuarcy: 14.91\n",
      "Test average loss: 0.05829474806785583\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 23 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.703125\n",
      "Current benign train loss: 0.8532827496528625\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.6796875\n",
      "Current benign train loss: 0.8726574778556824\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.7421875\n",
      "Current benign train loss: 0.7409979104995728\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.6796875\n",
      "Current benign train loss: 0.9567379951477051\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.7421875\n",
      "Current benign train loss: 0.7321379780769348\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.7734375\n",
      "Current benign train loss: 0.7090517282485962\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.7890625\n",
      "Current benign train loss: 0.6127874851226807\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.765625\n",
      "Current benign train loss: 0.7056821584701538\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.78125\n",
      "Current benign train loss: 0.6517587900161743\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.671875\n",
      "Current benign train loss: 0.8140483498573303\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.765625\n",
      "Current benign train loss: 0.670366644859314\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.7421875\n",
      "Current benign train loss: 0.7333988547325134\n",
      "\n",
      "Total benign train accuarcy: 74.76666666666667\n",
      "Total benign train loss: 862.4331262409687\n",
      "\n",
      "[ Test epoch: 23 ]\n",
      "\n",
      "Test accuarcy: 43.7\n",
      "Test average loss: 0.0294820778131485\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 24 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.671875\n",
      "Current benign train loss: 0.8686047792434692\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.7265625\n",
      "Current benign train loss: 0.7559323906898499\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.734375\n",
      "Current benign train loss: 0.8943958878517151\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.7578125\n",
      "Current benign train loss: 0.6769142150878906\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.6953125\n",
      "Current benign train loss: 0.9050979614257812\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.8046875\n",
      "Current benign train loss: 0.6130608320236206\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.6875\n",
      "Current benign train loss: 0.8783336281776428\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.703125\n",
      "Current benign train loss: 1.0453975200653076\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.71875\n",
      "Current benign train loss: 0.7299349308013916\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.8046875\n",
      "Current benign train loss: 0.5759558081626892\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.7734375\n",
      "Current benign train loss: 0.7096455693244934\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.7578125\n",
      "Current benign train loss: 0.6672707796096802\n",
      "\n",
      "Total benign train accuarcy: 74.70333333333333\n",
      "Total benign train loss: 861.2096993327141\n",
      "\n",
      "[ Test epoch: 24 ]\n",
      "\n",
      "Test accuarcy: 48.73\n",
      "Test average loss: 0.019873969173431396\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 25 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.8125\n",
      "Current benign train loss: 0.649474024772644\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.75\n",
      "Current benign train loss: 0.7836828231811523\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.765625\n",
      "Current benign train loss: 0.6249090433120728\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.8203125\n",
      "Current benign train loss: 0.5889474749565125\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.734375\n",
      "Current benign train loss: 0.6464877128601074\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.703125\n",
      "Current benign train loss: 0.7530808448791504\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.7421875\n",
      "Current benign train loss: 0.6716823577880859\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.734375\n",
      "Current benign train loss: 0.7947647571563721\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.796875\n",
      "Current benign train loss: 0.5974273085594177\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.703125\n",
      "Current benign train loss: 0.7761486172676086\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.765625\n",
      "Current benign train loss: 0.775109589099884\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.7421875\n",
      "Current benign train loss: 0.6240555047988892\n",
      "\n",
      "Total benign train accuarcy: 75.10466666666666\n",
      "Total benign train loss: 854.6273474395275\n",
      "\n",
      "[ Test epoch: 25 ]\n",
      "\n",
      "Test accuarcy: 10.0\n",
      "Test average loss: 0.130615202999115\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 26 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.7265625\n",
      "Current benign train loss: 0.7918117642402649\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.7890625\n",
      "Current benign train loss: 0.6475244164466858\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.7421875\n",
      "Current benign train loss: 0.6955544948577881\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.6953125\n",
      "Current benign train loss: 0.8344320058822632\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.765625\n",
      "Current benign train loss: 0.7099471092224121\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.7578125\n",
      "Current benign train loss: 0.748681902885437\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.75\n",
      "Current benign train loss: 0.7854080200195312\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.75\n",
      "Current benign train loss: 0.8751541376113892\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.796875\n",
      "Current benign train loss: 0.6837160587310791\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.8046875\n",
      "Current benign train loss: 0.4762837588787079\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.65625\n",
      "Current benign train loss: 1.0436968803405762\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.765625\n",
      "Current benign train loss: 0.740885853767395\n",
      "\n",
      "Total benign train accuarcy: 75.20066666666666\n",
      "Total benign train loss: 848.4150170087814\n",
      "\n",
      "[ Test epoch: 26 ]\n",
      "\n",
      "Test accuarcy: 42.94\n",
      "Test average loss: 0.03229490618705749\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 27 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.796875\n",
      "Current benign train loss: 0.6794190406799316\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.75\n",
      "Current benign train loss: 0.7801828384399414\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.7421875\n",
      "Current benign train loss: 0.6961292624473572\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.7109375\n",
      "Current benign train loss: 0.846723198890686\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.7734375\n",
      "Current benign train loss: 0.7334913015365601\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.7421875\n",
      "Current benign train loss: 0.6814996600151062\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.796875\n",
      "Current benign train loss: 0.5740318298339844\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.7734375\n",
      "Current benign train loss: 0.6883482336997986\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.765625\n",
      "Current benign train loss: 0.6910093426704407\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.75\n",
      "Current benign train loss: 0.7094082236289978\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.765625\n",
      "Current benign train loss: 0.6594741344451904\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.8125\n",
      "Current benign train loss: 0.5885545611381531\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total benign train accuarcy: 75.55333333333333\n",
      "Total benign train loss: 838.8730950057507\n",
      "\n",
      "[ Test epoch: 27 ]\n",
      "\n",
      "Test accuarcy: 39.03\n",
      "Test average loss: 0.03205243570804596\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 28 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.859375\n",
      "Current benign train loss: 0.4611940383911133\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.734375\n",
      "Current benign train loss: 0.6372594833374023\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.7109375\n",
      "Current benign train loss: 0.7791913151741028\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.75\n",
      "Current benign train loss: 0.6987541913986206\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.6796875\n",
      "Current benign train loss: 0.8490572571754456\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.7734375\n",
      "Current benign train loss: 0.5421475768089294\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.765625\n",
      "Current benign train loss: 0.6491736173629761\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.7265625\n",
      "Current benign train loss: 0.7181512713432312\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.765625\n",
      "Current benign train loss: 0.6613357067108154\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.75\n",
      "Current benign train loss: 0.7182202935218811\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.78125\n",
      "Current benign train loss: 0.6209248900413513\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.75\n",
      "Current benign train loss: 0.6977104544639587\n",
      "\n",
      "Total benign train accuarcy: 76.06466666666667\n",
      "Total benign train loss: 818.3626663982868\n",
      "\n",
      "[ Test epoch: 28 ]\n",
      "\n",
      "Test accuarcy: 22.15\n",
      "Test average loss: 0.0485704080581665\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 29 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.7265625\n",
      "Current benign train loss: 0.790440022945404\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.7421875\n",
      "Current benign train loss: 0.8547857403755188\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.7421875\n",
      "Current benign train loss: 0.642151951789856\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.7578125\n",
      "Current benign train loss: 0.8109196424484253\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.8046875\n",
      "Current benign train loss: 0.6279042363166809\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.7421875\n",
      "Current benign train loss: 0.833506166934967\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.7734375\n",
      "Current benign train loss: 0.7385686635971069\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.7578125\n",
      "Current benign train loss: 0.7325390577316284\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.7421875\n",
      "Current benign train loss: 0.5842307209968567\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.78125\n",
      "Current benign train loss: 0.649694561958313\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.8203125\n",
      "Current benign train loss: 0.6261241436004639\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.7421875\n",
      "Current benign train loss: 0.7689769864082336\n",
      "\n",
      "Total benign train accuarcy: 75.73666666666666\n",
      "Total benign train loss: 827.037495136261\n",
      "\n",
      "[ Test epoch: 29 ]\n",
      "\n",
      "Test accuarcy: 12.95\n",
      "Test average loss: 0.08156023859977722\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 30 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.7890625\n",
      "Current benign train loss: 0.7416865229606628\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.75\n",
      "Current benign train loss: 0.6999148726463318\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.7734375\n",
      "Current benign train loss: 0.6800013184547424\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.7578125\n",
      "Current benign train loss: 0.6180562376976013\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.734375\n",
      "Current benign train loss: 0.7476863265037537\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.7578125\n",
      "Current benign train loss: 0.722465991973877\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.7421875\n",
      "Current benign train loss: 0.8699465990066528\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.7890625\n",
      "Current benign train loss: 0.6475602984428406\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.7265625\n",
      "Current benign train loss: 0.756210207939148\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.7578125\n",
      "Current benign train loss: 0.6958035230636597\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.6875\n",
      "Current benign train loss: 0.8800016641616821\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.7890625\n",
      "Current benign train loss: 0.6489649415016174\n",
      "\n",
      "Total benign train accuarcy: 76.196\n",
      "Total benign train loss: 815.5559104979038\n",
      "\n",
      "[ Test epoch: 30 ]\n",
      "\n",
      "Test accuarcy: 16.48\n",
      "Test average loss: 0.05824297080039978\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 31 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.8046875\n",
      "Current benign train loss: 0.6549805402755737\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.8125\n",
      "Current benign train loss: 0.565911591053009\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.8203125\n",
      "Current benign train loss: 0.5095011591911316\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.703125\n",
      "Current benign train loss: 0.8347369432449341\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.7890625\n",
      "Current benign train loss: 0.7109664082527161\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.8046875\n",
      "Current benign train loss: 0.5319522619247437\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.796875\n",
      "Current benign train loss: 0.5812750458717346\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.7890625\n",
      "Current benign train loss: 0.6571537256240845\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.7109375\n",
      "Current benign train loss: 0.8806662559509277\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.7578125\n",
      "Current benign train loss: 0.6687109470367432\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.765625\n",
      "Current benign train loss: 0.6387902498245239\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.7109375\n",
      "Current benign train loss: 0.8105574250221252\n",
      "\n",
      "Total benign train accuarcy: 76.14533333333334\n",
      "Total benign train loss: 815.4449639618397\n",
      "\n",
      "[ Test epoch: 31 ]\n",
      "\n",
      "Test accuarcy: 12.72\n",
      "Test average loss: 0.08371657710075378\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 32 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.6875\n",
      "Current benign train loss: 0.7923377752304077\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.7890625\n",
      "Current benign train loss: 0.6407368183135986\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.734375\n",
      "Current benign train loss: 0.7517521381378174\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.7734375\n",
      "Current benign train loss: 0.7015177011489868\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.7890625\n",
      "Current benign train loss: 0.6010152101516724\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.6328125\n",
      "Current benign train loss: 1.0584192276000977\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.8359375\n",
      "Current benign train loss: 0.5381768345832825\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.75\n",
      "Current benign train loss: 0.8011108636856079\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.78125\n",
      "Current benign train loss: 0.6372833847999573\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.7421875\n",
      "Current benign train loss: 0.7305397391319275\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.78125\n",
      "Current benign train loss: 0.6274248957633972\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.7734375\n",
      "Current benign train loss: 0.7561230063438416\n",
      "\n",
      "Total benign train accuarcy: 76.01133333333334\n",
      "Total benign train loss: 818.1056891679764\n",
      "\n",
      "[ Test epoch: 32 ]\n",
      "\n",
      "Test accuarcy: 48.99\n",
      "Test average loss: 0.030329987072944643\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 33 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.7109375\n",
      "Current benign train loss: 0.889062762260437\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.8046875\n",
      "Current benign train loss: 0.5657016634941101\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.703125\n",
      "Current benign train loss: 0.9643206000328064\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.7890625\n",
      "Current benign train loss: 0.6600927710533142\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.7578125\n",
      "Current benign train loss: 0.6914670467376709\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.75\n",
      "Current benign train loss: 0.8282363414764404\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.796875\n",
      "Current benign train loss: 0.6312462687492371\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.78125\n",
      "Current benign train loss: 0.6018363237380981\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.7265625\n",
      "Current benign train loss: 0.8537000417709351\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.7421875\n",
      "Current benign train loss: 0.6193497180938721\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.7421875\n",
      "Current benign train loss: 0.6812538504600525\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.7578125\n",
      "Current benign train loss: 0.6748925447463989\n",
      "\n",
      "Total benign train accuarcy: 76.61933333333333\n",
      "Total benign train loss: 801.6804249286652\n",
      "\n",
      "[ Test epoch: 33 ]\n",
      "\n",
      "Test accuarcy: 23.65\n",
      "Test average loss: 0.03954837176799774\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 34 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.7890625\n",
      "Current benign train loss: 0.7646360993385315\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.8046875\n",
      "Current benign train loss: 0.5398051738739014\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.7890625\n",
      "Current benign train loss: 0.6437855958938599\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.8046875\n",
      "Current benign train loss: 0.5357170104980469\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.8203125\n",
      "Current benign train loss: 0.591223418712616\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.828125\n",
      "Current benign train loss: 0.5559043288230896\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.7578125\n",
      "Current benign train loss: 0.6711660623550415\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.8359375\n",
      "Current benign train loss: 0.4906750023365021\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.84375\n",
      "Current benign train loss: 0.4766925275325775\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.8046875\n",
      "Current benign train loss: 0.551945149898529\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.71875\n",
      "Current benign train loss: 0.6375402808189392\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.796875\n",
      "Current benign train loss: 0.5537376999855042\n",
      "\n",
      "Total benign train accuarcy: 76.81733333333334\n",
      "Total benign train loss: 790.6309080421925\n",
      "\n",
      "[ Test epoch: 34 ]\n",
      "\n",
      "Test accuarcy: 30.94\n",
      "Test average loss: 0.037209167647361756\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 35 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.7578125\n",
      "Current benign train loss: 0.782069206237793\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.7734375\n",
      "Current benign train loss: 0.5783694386482239\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.7890625\n",
      "Current benign train loss: 0.6785802245140076\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.7890625\n",
      "Current benign train loss: 0.594584584236145\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.78125\n",
      "Current benign train loss: 0.7115048766136169\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.71875\n",
      "Current benign train loss: 0.6650290489196777\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.7421875\n",
      "Current benign train loss: 0.8050873875617981\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.7734375\n",
      "Current benign train loss: 0.7418963313102722\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.71875\n",
      "Current benign train loss: 0.7985268831253052\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.8125\n",
      "Current benign train loss: 0.5866416096687317\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.7578125\n",
      "Current benign train loss: 0.5782045722007751\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.71875\n",
      "Current benign train loss: 0.9659644961357117\n",
      "\n",
      "Total benign train accuarcy: 76.574\n",
      "Total benign train loss: 806.568319439888\n",
      "\n",
      "[ Test epoch: 35 ]\n",
      "\n",
      "Test accuarcy: 28.12\n",
      "Test average loss: 0.04216185848712921\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 36 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.796875\n",
      "Current benign train loss: 0.658306896686554\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.75\n",
      "Current benign train loss: 0.666970431804657\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.71875\n",
      "Current benign train loss: 0.7644658088684082\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.7890625\n",
      "Current benign train loss: 0.5739470720291138\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.7890625\n",
      "Current benign train loss: 0.6322106122970581\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.8125\n",
      "Current benign train loss: 0.5871492624282837\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.7734375\n",
      "Current benign train loss: 0.6083294153213501\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.7578125\n",
      "Current benign train loss: 0.6539246439933777\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.796875\n",
      "Current benign train loss: 0.6154196262359619\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.78125\n",
      "Current benign train loss: 0.6052178144454956\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.734375\n",
      "Current benign train loss: 0.8058668971061707\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.7421875\n",
      "Current benign train loss: 0.6068366169929504\n",
      "\n",
      "Total benign train accuarcy: 76.834\n",
      "Total benign train loss: 792.3961746394634\n",
      "\n",
      "[ Test epoch: 36 ]\n",
      "\n",
      "Test accuarcy: 23.84\n",
      "Test average loss: 0.037486781072616576\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 37 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.7890625\n",
      "Current benign train loss: 0.5408101677894592\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.7734375\n",
      "Current benign train loss: 0.7386116981506348\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.7890625\n",
      "Current benign train loss: 0.5823657512664795\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.75\n",
      "Current benign train loss: 0.9144056439399719\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.7734375\n",
      "Current benign train loss: 0.6438487768173218\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.7734375\n",
      "Current benign train loss: 0.579829216003418\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.765625\n",
      "Current benign train loss: 0.7483393549919128\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.8125\n",
      "Current benign train loss: 0.4805658459663391\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.6484375\n",
      "Current benign train loss: 0.8042872548103333\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.78125\n",
      "Current benign train loss: 0.5647402405738831\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.78125\n",
      "Current benign train loss: 0.5403259992599487\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.7734375\n",
      "Current benign train loss: 0.6509416699409485\n",
      "\n",
      "Total benign train accuarcy: 76.88533333333334\n",
      "Total benign train loss: 791.1230559051037\n",
      "\n",
      "[ Test epoch: 37 ]\n",
      "\n",
      "Test accuarcy: 39.92\n",
      "Test average loss: 0.033354338383674624\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 38 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.7421875\n",
      "Current benign train loss: 0.6558175086975098\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.78125\n",
      "Current benign train loss: 0.6929399967193604\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.78125\n",
      "Current benign train loss: 0.6877431273460388\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.75\n",
      "Current benign train loss: 0.6590434908866882\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.8125\n",
      "Current benign train loss: 0.5691822171211243\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.765625\n",
      "Current benign train loss: 0.7530631422996521\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.7890625\n",
      "Current benign train loss: 0.724898099899292\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.7734375\n",
      "Current benign train loss: 0.5439966320991516\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.84375\n",
      "Current benign train loss: 0.553337037563324\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.7421875\n",
      "Current benign train loss: 0.6373142004013062\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.7421875\n",
      "Current benign train loss: 0.6609482169151306\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.796875\n",
      "Current benign train loss: 0.7910401821136475\n",
      "\n",
      "Total benign train accuarcy: 77.22266666666667\n",
      "Total benign train loss: 782.9022767543793\n",
      "\n",
      "[ Test epoch: 38 ]\n",
      "\n",
      "Test accuarcy: 31.38\n",
      "Test average loss: 0.035342721366882324\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 39 ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.8203125\n",
      "Current benign train loss: 0.5237210988998413\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.796875\n",
      "Current benign train loss: 0.6091739535331726\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.7734375\n",
      "Current benign train loss: 0.7538700103759766\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.7109375\n",
      "Current benign train loss: 0.865795373916626\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.796875\n",
      "Current benign train loss: 0.6318843364715576\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.734375\n",
      "Current benign train loss: 0.8743775486946106\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.78125\n",
      "Current benign train loss: 0.61684650182724\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.828125\n",
      "Current benign train loss: 0.42796698212623596\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.78125\n",
      "Current benign train loss: 0.6292020082473755\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.796875\n",
      "Current benign train loss: 0.5560873746871948\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.796875\n",
      "Current benign train loss: 0.5380523204803467\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.8125\n",
      "Current benign train loss: 0.6171042323112488\n",
      "\n",
      "Total benign train accuarcy: 77.35466666666666\n",
      "Total benign train loss: 775.8132255971432\n",
      "\n",
      "[ Test epoch: 39 ]\n",
      "\n",
      "Test accuarcy: 36.89\n",
      "Test average loss: 0.030655112433433534\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 40 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.75\n",
      "Current benign train loss: 0.7063611745834351\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.8046875\n",
      "Current benign train loss: 0.5160448551177979\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.765625\n",
      "Current benign train loss: 0.6084687113761902\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.7265625\n",
      "Current benign train loss: 0.6692726016044617\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.734375\n",
      "Current benign train loss: 0.6833975911140442\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.828125\n",
      "Current benign train loss: 0.51691734790802\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.7734375\n",
      "Current benign train loss: 0.7459589242935181\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.796875\n",
      "Current benign train loss: 0.5880486369132996\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.796875\n",
      "Current benign train loss: 0.6268532276153564\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.78125\n",
      "Current benign train loss: 0.5673456788063049\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.71875\n",
      "Current benign train loss: 0.8452197909355164\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.7734375\n",
      "Current benign train loss: 0.8045847415924072\n",
      "\n",
      "Total benign train accuarcy: 77.22933333333333\n",
      "Total benign train loss: 782.0906692147255\n",
      "\n",
      "[ Test epoch: 40 ]\n",
      "\n",
      "Test accuarcy: 47.93\n",
      "Test average loss: 0.02442366350889206\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 41 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.765625\n",
      "Current benign train loss: 0.7094548940658569\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.765625\n",
      "Current benign train loss: 0.6352511048316956\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.796875\n",
      "Current benign train loss: 0.5994423031806946\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.8359375\n",
      "Current benign train loss: 0.4998476207256317\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.8125\n",
      "Current benign train loss: 0.5882871150970459\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.78125\n",
      "Current benign train loss: 0.5835110545158386\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.8046875\n",
      "Current benign train loss: 0.6105553507804871\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.71875\n",
      "Current benign train loss: 0.7871707081794739\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.703125\n",
      "Current benign train loss: 0.800460934638977\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.71875\n",
      "Current benign train loss: 0.7777685523033142\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.78125\n",
      "Current benign train loss: 0.7085335850715637\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.8046875\n",
      "Current benign train loss: 0.6158450841903687\n",
      "\n",
      "Total benign train accuarcy: 77.22466666666666\n",
      "Total benign train loss: 781.3239389955997\n",
      "\n",
      "[ Test epoch: 41 ]\n",
      "\n",
      "Test accuarcy: 27.54\n",
      "Test average loss: 0.059363056421279904\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 42 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.7890625\n",
      "Current benign train loss: 0.6522349119186401\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.71875\n",
      "Current benign train loss: 0.7277411818504333\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.7578125\n",
      "Current benign train loss: 0.6423681974411011\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.734375\n",
      "Current benign train loss: 0.7556745409965515\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.78125\n",
      "Current benign train loss: 0.6524748802185059\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.765625\n",
      "Current benign train loss: 0.6297268271446228\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.8203125\n",
      "Current benign train loss: 0.47266754508018494\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.765625\n",
      "Current benign train loss: 0.7530853152275085\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.78125\n",
      "Current benign train loss: 0.6197464466094971\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.7890625\n",
      "Current benign train loss: 0.6796526908874512\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.796875\n",
      "Current benign train loss: 0.5659757256507874\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.796875\n",
      "Current benign train loss: 0.591363251209259\n",
      "\n",
      "Total benign train accuarcy: 77.37466666666667\n",
      "Total benign train loss: 771.7622313499451\n",
      "\n",
      "[ Test epoch: 42 ]\n",
      "\n",
      "Test accuarcy: 21.78\n",
      "Test average loss: 0.05189426512718201\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 43 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.7578125\n",
      "Current benign train loss: 0.7055588960647583\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.765625\n",
      "Current benign train loss: 0.5785744786262512\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.7890625\n",
      "Current benign train loss: 0.6187353730201721\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.828125\n",
      "Current benign train loss: 0.48160994052886963\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.78125\n",
      "Current benign train loss: 0.7116629481315613\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.7265625\n",
      "Current benign train loss: 0.7635502815246582\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.71875\n",
      "Current benign train loss: 0.7447360157966614\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.7578125\n",
      "Current benign train loss: 0.70744788646698\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.7734375\n",
      "Current benign train loss: 0.6358873248100281\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.84375\n",
      "Current benign train loss: 0.4489072561264038\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.7421875\n",
      "Current benign train loss: 0.716729462146759\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.7734375\n",
      "Current benign train loss: 0.6325141191482544\n",
      "\n",
      "Total benign train accuarcy: 77.57533333333333\n",
      "Total benign train loss: 768.244722366333\n",
      "\n",
      "[ Test epoch: 43 ]\n",
      "\n",
      "Test accuarcy: 14.14\n",
      "Test average loss: 0.08745210976600647\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 44 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.7578125\n",
      "Current benign train loss: 0.5656507015228271\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.7109375\n",
      "Current benign train loss: 0.8593425750732422\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.8046875\n",
      "Current benign train loss: 0.5461037755012512\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.78125\n",
      "Current benign train loss: 0.6895667910575867\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.7265625\n",
      "Current benign train loss: 0.7759627103805542\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.765625\n",
      "Current benign train loss: 0.6968305110931396\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.6796875\n",
      "Current benign train loss: 0.8986279368400574\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.8203125\n",
      "Current benign train loss: 0.5196526646614075\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.75\n",
      "Current benign train loss: 0.6292442083358765\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.8515625\n",
      "Current benign train loss: 0.4013836085796356\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.7578125\n",
      "Current benign train loss: 0.6960470676422119\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.734375\n",
      "Current benign train loss: 0.9399548172950745\n",
      "\n",
      "Total benign train accuarcy: 77.65266666666666\n",
      "Total benign train loss: 766.1722764670849\n",
      "\n",
      "[ Test epoch: 44 ]\n",
      "\n",
      "Test accuarcy: 20.67\n",
      "Test average loss: 0.06219208717346191\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 45 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.8125\n",
      "Current benign train loss: 0.5350275635719299\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.734375\n",
      "Current benign train loss: 0.7015774250030518\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.796875\n",
      "Current benign train loss: 0.5845203399658203\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.8046875\n",
      "Current benign train loss: 0.6015361547470093\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.765625\n",
      "Current benign train loss: 0.6359777450561523\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.828125\n",
      "Current benign train loss: 0.5230476260185242\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.7734375\n",
      "Current benign train loss: 0.6222009658813477\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.71875\n",
      "Current benign train loss: 0.902079164981842\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.7890625\n",
      "Current benign train loss: 0.6591804027557373\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.7890625\n",
      "Current benign train loss: 0.652407169342041\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.7890625\n",
      "Current benign train loss: 0.5796439051628113\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.8046875\n",
      "Current benign train loss: 0.6073572635650635\n",
      "\n",
      "Total benign train accuarcy: 77.608\n",
      "Total benign train loss: 766.508387774229\n",
      "\n",
      "[ Test epoch: 45 ]\n",
      "\n",
      "Test accuarcy: 25.82\n",
      "Test average loss: 0.045685997891426085\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 46 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.84375\n",
      "Current benign train loss: 0.4711892604827881\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.8125\n",
      "Current benign train loss: 0.4610936641693115\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.7578125\n",
      "Current benign train loss: 0.7327358722686768\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.6796875\n",
      "Current benign train loss: 0.7427536845207214\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.75\n",
      "Current benign train loss: 0.7508708834648132\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.7265625\n",
      "Current benign train loss: 0.8014097213745117\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.828125\n",
      "Current benign train loss: 0.6286302804946899\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.796875\n",
      "Current benign train loss: 0.5875855684280396\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.8125\n",
      "Current benign train loss: 0.5302150249481201\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.7890625\n",
      "Current benign train loss: 0.6711615324020386\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.8046875\n",
      "Current benign train loss: 0.5942328572273254\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.8125\n",
      "Current benign train loss: 0.6519700884819031\n",
      "\n",
      "Total benign train accuarcy: 77.77\n",
      "Total benign train loss: 764.7401878833771\n",
      "\n",
      "[ Test epoch: 46 ]\n",
      "\n",
      "Test accuarcy: 27.32\n",
      "Test average loss: 0.05203825359344483\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 47 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.71875\n",
      "Current benign train loss: 0.8509141802787781\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.6875\n",
      "Current benign train loss: 0.9816091656684875\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.8515625\n",
      "Current benign train loss: 0.4483368992805481\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.7578125\n",
      "Current benign train loss: 0.8342554569244385\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.8125\n",
      "Current benign train loss: 0.6014591455459595\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.75\n",
      "Current benign train loss: 0.6412389874458313\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.765625\n",
      "Current benign train loss: 0.6489723920822144\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.7421875\n",
      "Current benign train loss: 0.6220077276229858\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.8125\n",
      "Current benign train loss: 0.5633692145347595\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.78125\n",
      "Current benign train loss: 0.6559099555015564\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.8125\n",
      "Current benign train loss: 0.6784795522689819\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.78125\n",
      "Current benign train loss: 0.6244899034500122\n",
      "\n",
      "Total benign train accuarcy: 77.85466666666666\n",
      "Total benign train loss: 760.0072719454765\n",
      "\n",
      "[ Test epoch: 47 ]\n",
      "\n",
      "Test accuarcy: 33.07\n",
      "Test average loss: 0.0338803786277771\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 48 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.7578125\n",
      "Current benign train loss: 0.9352886080741882\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.765625\n",
      "Current benign train loss: 0.6408199071884155\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.7578125\n",
      "Current benign train loss: 0.6196252703666687\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.8203125\n",
      "Current benign train loss: 0.49153026938438416\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.734375\n",
      "Current benign train loss: 0.7219544053077698\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.8125\n",
      "Current benign train loss: 0.5352579355239868\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.7734375\n",
      "Current benign train loss: 0.6871089339256287\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.7265625\n",
      "Current benign train loss: 0.8097827434539795\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.8046875\n",
      "Current benign train loss: 0.5364649891853333\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.734375\n",
      "Current benign train loss: 0.6366913914680481\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.796875\n",
      "Current benign train loss: 0.590644121170044\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.78125\n",
      "Current benign train loss: 0.5624656677246094\n",
      "\n",
      "Total benign train accuarcy: 77.75466666666667\n",
      "Total benign train loss: 762.0809558928013\n",
      "\n",
      "[ Test epoch: 48 ]\n",
      "\n",
      "Test accuarcy: 30.31\n",
      "Test average loss: 0.05202372088432312\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 49 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.8046875\n",
      "Current benign train loss: 0.4890175759792328\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.78125\n",
      "Current benign train loss: 0.7331582307815552\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.828125\n",
      "Current benign train loss: 0.49169856309890747\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.8125\n",
      "Current benign train loss: 0.5771511793136597\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.8203125\n",
      "Current benign train loss: 0.5789526104927063\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.7890625\n",
      "Current benign train loss: 0.7266080379486084\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.78125\n",
      "Current benign train loss: 0.6150012612342834\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.7734375\n",
      "Current benign train loss: 0.6517716646194458\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.7734375\n",
      "Current benign train loss: 0.6836996674537659\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.7578125\n",
      "Current benign train loss: 0.662507951259613\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.7734375\n",
      "Current benign train loss: 0.6069490909576416\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.78125\n",
      "Current benign train loss: 0.6366551518440247\n",
      "\n",
      "Total benign train accuarcy: 77.918\n",
      "Total benign train loss: 760.5653059184551\n",
      "\n",
      "[ Test epoch: 49 ]\n",
      "\n",
      "Test accuarcy: 45.94\n",
      "Test average loss: 0.02758473973274231\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 50 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.7578125\n",
      "Current benign train loss: 0.6042360663414001\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.84375\n",
      "Current benign train loss: 0.43796417117118835\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.8203125\n",
      "Current benign train loss: 0.46351122856140137\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9140625\n",
      "Current benign train loss: 0.2867470979690552\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.859375\n",
      "Current benign train loss: 0.3666524291038513\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.78125\n",
      "Current benign train loss: 0.5776546597480774\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.8671875\n",
      "Current benign train loss: 0.4253613352775574\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.8359375\n",
      "Current benign train loss: 0.4262178838253021\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.828125\n",
      "Current benign train loss: 0.4838889539241791\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.84375\n",
      "Current benign train loss: 0.3918052315711975\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.890625\n",
      "Current benign train loss: 0.34998661279678345\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.9140625\n",
      "Current benign train loss: 0.28337445855140686\n",
      "\n",
      "Total benign train accuarcy: 86.53\n",
      "Total benign train loss: 458.41406811773777\n",
      "\n",
      "[ Test epoch: 50 ]\n",
      "\n",
      "Test accuarcy: 84.83\n",
      "Test average loss: 0.004515505973994732\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 51 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.8671875\n",
      "Current benign train loss: 0.34781986474990845\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.8671875\n",
      "Current benign train loss: 0.3449152708053589\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.890625\n",
      "Current benign train loss: 0.38157451152801514\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.84375\n",
      "Current benign train loss: 0.39058902859687805\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.8828125\n",
      "Current benign train loss: 0.3805314600467682\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.8671875\n",
      "Current benign train loss: 0.38687843084335327\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.859375\n",
      "Current benign train loss: 0.31431758403778076\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.90625\n",
      "Current benign train loss: 0.2783662676811218\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.90625\n",
      "Current benign train loss: 0.29372739791870117\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.8984375\n",
      "Current benign train loss: 0.34101516008377075\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.875\n",
      "Current benign train loss: 0.322765588760376\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.8984375\n",
      "Current benign train loss: 0.2311447262763977\n",
      "\n",
      "Total benign train accuarcy: 87.85266666666666\n",
      "Total benign train loss: 414.1421012580395\n",
      "\n",
      "[ Test epoch: 51 ]\n",
      "\n",
      "Test accuarcy: 84.48\n",
      "Test average loss: 0.004749497061967849\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 52 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.875\n",
      "Current benign train loss: 0.3623700737953186\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.8671875\n",
      "Current benign train loss: 0.3587653338909149\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9296875\n",
      "Current benign train loss: 0.20199698209762573\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.8828125\n",
      "Current benign train loss: 0.35179075598716736\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.890625\n",
      "Current benign train loss: 0.3242548704147339\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9140625\n",
      "Current benign train loss: 0.26103606820106506\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.875\n",
      "Current benign train loss: 0.29560065269470215\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.8359375\n",
      "Current benign train loss: 0.48668715357780457\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.8515625\n",
      "Current benign train loss: 0.3592967689037323\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.8671875\n",
      "Current benign train loss: 0.3510151505470276\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.9140625\n",
      "Current benign train loss: 0.20466427505016327\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.9140625\n",
      "Current benign train loss: 0.29193079471588135\n",
      "\n",
      "Total benign train accuarcy: 88.532\n",
      "Total benign train loss: 392.60823206603527\n",
      "\n",
      "[ Test epoch: 52 ]\n",
      "\n",
      "Test accuarcy: 84.37\n",
      "Test average loss: 0.00476474826335907\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 53 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.921875\n",
      "Current benign train loss: 0.34245193004608154\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.875\n",
      "Current benign train loss: 0.3517311215400696\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.8828125\n",
      "Current benign train loss: 0.33993417024612427\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.921875\n",
      "Current benign train loss: 0.22497999668121338\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.875\n",
      "Current benign train loss: 0.3153155744075775\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.8984375\n",
      "Current benign train loss: 0.32490772008895874\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.8515625\n",
      "Current benign train loss: 0.3795689046382904\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.17593221366405487\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.90625\n",
      "Current benign train loss: 0.23655973374843597\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.8828125\n",
      "Current benign train loss: 0.32639628648757935\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.8828125\n",
      "Current benign train loss: 0.2985835373401642\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.875\n",
      "Current benign train loss: 0.32015717029571533\n",
      "\n",
      "Total benign train accuarcy: 88.77533333333334\n",
      "Total benign train loss: 379.8806454241276\n",
      "\n",
      "[ Test epoch: 53 ]\n",
      "\n",
      "Test accuarcy: 83.97\n",
      "Test average loss: 0.004962134407460689\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 54 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9296875\n",
      "Current benign train loss: 0.20419466495513916\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.90625\n",
      "Current benign train loss: 0.2750013470649719\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.8671875\n",
      "Current benign train loss: 0.3204309940338135\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.875\n",
      "Current benign train loss: 0.31720876693725586\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.8984375\n",
      "Current benign train loss: 0.3703349828720093\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.90625\n",
      "Current benign train loss: 0.23598864674568176\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.90625\n",
      "Current benign train loss: 0.29513439536094666\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.890625\n",
      "Current benign train loss: 0.3567105233669281\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.8984375\n",
      "Current benign train loss: 0.2878964841365814\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.8671875\n",
      "Current benign train loss: 0.32305893301963806\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.8828125\n",
      "Current benign train loss: 0.3109707832336426\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.90625\n",
      "Current benign train loss: 0.29776084423065186\n",
      "\n",
      "Total benign train accuarcy: 89.03533333333333\n",
      "Total benign train loss: 374.18316723406315\n",
      "\n",
      "[ Test epoch: 54 ]\n",
      "\n",
      "Test accuarcy: 79.92\n",
      "Test average loss: 0.006527544367313385\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 55 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9296875\n",
      "Current benign train loss: 0.2007899433374405\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.8828125\n",
      "Current benign train loss: 0.3112455904483795\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.890625\n",
      "Current benign train loss: 0.26329919695854187\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.2032621204853058\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.8671875\n",
      "Current benign train loss: 0.33775651454925537\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.21999147534370422\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.890625\n",
      "Current benign train loss: 0.29358452558517456\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.9296875\n",
      "Current benign train loss: 0.26213353872299194\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.921875\n",
      "Current benign train loss: 0.28969496488571167\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.828125\n",
      "Current benign train loss: 0.4707890450954437\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.859375\n",
      "Current benign train loss: 0.36916878819465637\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.8515625\n",
      "Current benign train loss: 0.3585885465145111\n",
      "\n",
      "Total benign train accuarcy: 89.29066666666667\n",
      "Total benign train loss: 364.87641130387783\n",
      "\n",
      "[ Test epoch: 55 ]\n",
      "\n",
      "Test accuarcy: 78.82\n",
      "Test average loss: 0.007384622621536255\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 56 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.921875\n",
      "Current benign train loss: 0.24322272837162018\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.921875\n",
      "Current benign train loss: 0.2573123574256897\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.8828125\n",
      "Current benign train loss: 0.3070271909236908\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9140625\n",
      "Current benign train loss: 0.27095064520835876\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9140625\n",
      "Current benign train loss: 0.2731158137321472\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.890625\n",
      "Current benign train loss: 0.29630082845687866\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.84375\n",
      "Current benign train loss: 0.3268716633319855\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.875\n",
      "Current benign train loss: 0.34587863087654114\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.8984375\n",
      "Current benign train loss: 0.3237345516681671\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.875\n",
      "Current benign train loss: 0.3249596655368805\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.90625\n",
      "Current benign train loss: 0.2890993654727936\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.8828125\n",
      "Current benign train loss: 0.3563792407512665\n",
      "\n",
      "Total benign train accuarcy: 89.52666666666667\n",
      "Total benign train loss: 359.493947699666\n",
      "\n",
      "[ Test epoch: 56 ]\n",
      "\n",
      "Test accuarcy: 79.42\n",
      "Test average loss: 0.007168986502289772\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 57 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.8828125\n",
      "Current benign train loss: 0.37160369753837585\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.8828125\n",
      "Current benign train loss: 0.27694329619407654\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.8984375\n",
      "Current benign train loss: 0.2695675790309906\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.890625\n",
      "Current benign train loss: 0.24614326655864716\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.8984375\n",
      "Current benign train loss: 0.2820027470588684\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.875\n",
      "Current benign train loss: 0.34211981296539307\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.90625\n",
      "Current benign train loss: 0.26429587602615356\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.90625\n",
      "Current benign train loss: 0.2822817862033844\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.8828125\n",
      "Current benign train loss: 0.35395246744155884\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.9296875\n",
      "Current benign train loss: 0.2381092756986618\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.9296875\n",
      "Current benign train loss: 0.19299830496311188\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.9296875\n",
      "Current benign train loss: 0.20968659222126007\n",
      "\n",
      "Total benign train accuarcy: 89.516\n",
      "Total benign train loss: 357.0055373311043\n",
      "\n",
      "[ Test epoch: 57 ]\n",
      "\n",
      "Test accuarcy: 69.12\n",
      "Test average loss: 0.012173975574970245\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 58 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.8515625\n",
      "Current benign train loss: 0.4133625030517578\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.90625\n",
      "Current benign train loss: 0.30995243787765503\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.8828125\n",
      "Current benign train loss: 0.3520495891571045\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.921875\n",
      "Current benign train loss: 0.25180602073669434\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.8828125\n",
      "Current benign train loss: 0.3671022951602936\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9296875\n",
      "Current benign train loss: 0.25339290499687195\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.8984375\n",
      "Current benign train loss: 0.3217763900756836\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.9140625\n",
      "Current benign train loss: 0.20983819663524628\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.8984375\n",
      "Current benign train loss: 0.3527531623840332\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.8984375\n",
      "Current benign train loss: 0.3260667622089386\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.9296875\n",
      "Current benign train loss: 0.30139949917793274\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.8828125\n",
      "Current benign train loss: 0.2319737672805786\n",
      "\n",
      "Total benign train accuarcy: 89.62733333333334\n",
      "Total benign train loss: 353.23004461824894\n",
      "\n",
      "[ Test epoch: 58 ]\n",
      "\n",
      "Test accuarcy: 77.55\n",
      "Test average loss: 0.007838667589426042\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 59 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.8984375\n",
      "Current benign train loss: 0.3244340717792511\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.8984375\n",
      "Current benign train loss: 0.32334959506988525\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.8828125\n",
      "Current benign train loss: 0.30749380588531494\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9140625\n",
      "Current benign train loss: 0.30530181527137756\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.8671875\n",
      "Current benign train loss: 0.3804192543029785\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.8671875\n",
      "Current benign train loss: 0.37105971574783325\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.20938411355018616\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.9140625\n",
      "Current benign train loss: 0.23877908289432526\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.9140625\n",
      "Current benign train loss: 0.25691157579421997\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.859375\n",
      "Current benign train loss: 0.2941473722457886\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.8671875\n",
      "Current benign train loss: 0.302092969417572\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.9140625\n",
      "Current benign train loss: 0.29576268792152405\n",
      "\n",
      "Total benign train accuarcy: 89.71533333333333\n",
      "Total benign train loss: 350.59888061881065\n",
      "\n",
      "[ Test epoch: 59 ]\n",
      "\n",
      "Test accuarcy: 74.32\n",
      "Test average loss: 0.009979623752832413\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 60 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.8984375\n",
      "Current benign train loss: 0.29135337471961975\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.90625\n",
      "Current benign train loss: 0.29608219861984253\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9296875\n",
      "Current benign train loss: 0.21638421714305878\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.921875\n",
      "Current benign train loss: 0.30330774188041687\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.890625\n",
      "Current benign train loss: 0.2924529016017914\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.8828125\n",
      "Current benign train loss: 0.38184666633605957\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.20178592205047607\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.90625\n",
      "Current benign train loss: 0.3475915193557739\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.90625\n",
      "Current benign train loss: 0.2616989314556122\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.9296875\n",
      "Current benign train loss: 0.2732391357421875\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.921875\n",
      "Current benign train loss: 0.2188071757555008\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.921875\n",
      "Current benign train loss: 0.25116845965385437\n",
      "\n",
      "Total benign train accuarcy: 89.80866666666667\n",
      "Total benign train loss: 348.373277425766\n",
      "\n",
      "[ Test epoch: 60 ]\n",
      "\n",
      "Test accuarcy: 69.11\n",
      "Test average loss: 0.013144333887100219\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 61 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.90625\n",
      "Current benign train loss: 0.2789805233478546\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.8828125\n",
      "Current benign train loss: 0.3618333339691162\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.921875\n",
      "Current benign train loss: 0.1974857598543167\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.8671875\n",
      "Current benign train loss: 0.3596503734588623\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.8671875\n",
      "Current benign train loss: 0.35070911049842834\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9296875\n",
      "Current benign train loss: 0.1711401343345642\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.9140625\n",
      "Current benign train loss: 0.21146269142627716\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.8828125\n",
      "Current benign train loss: 0.3170822262763977\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.921875\n",
      "Current benign train loss: 0.22355319559574127\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.8984375\n",
      "Current benign train loss: 0.3487912714481354\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.8828125\n",
      "Current benign train loss: 0.28924548625946045\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.9140625\n",
      "Current benign train loss: 0.27143317461013794\n",
      "\n",
      "Total benign train accuarcy: 89.978\n",
      "Total benign train loss: 342.58741246163845\n",
      "\n",
      "[ Test epoch: 61 ]\n",
      "\n",
      "Test accuarcy: 71.97\n",
      "Test average loss: 0.01102356578707695\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 62 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.8828125\n",
      "Current benign train loss: 0.2797171175479889\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.875\n",
      "Current benign train loss: 0.3134046494960785\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.8671875\n",
      "Current benign train loss: 0.37519708275794983\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.90625\n",
      "Current benign train loss: 0.302739679813385\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.8984375\n",
      "Current benign train loss: 0.3098270893096924\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.2132699191570282\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.890625\n",
      "Current benign train loss: 0.3522268831729889\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.9296875\n",
      "Current benign train loss: 0.2952142357826233\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.859375\n",
      "Current benign train loss: 0.30373066663742065\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.23138462007045746\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.9140625\n",
      "Current benign train loss: 0.3101840913295746\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.90625\n",
      "Current benign train loss: 0.2751988470554352\n",
      "\n",
      "Total benign train accuarcy: 89.828\n",
      "Total benign train loss: 343.73428162932396\n",
      "\n",
      "[ Test epoch: 62 ]\n",
      "\n",
      "Test accuarcy: 78.98\n",
      "Test average loss: 0.007312752830982208\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 63 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9296875\n",
      "Current benign train loss: 0.2300308644771576\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.8828125\n",
      "Current benign train loss: 0.322787880897522\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.90625\n",
      "Current benign train loss: 0.2671504318714142\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9140625\n",
      "Current benign train loss: 0.23320306837558746\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.24122211337089539\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.921875\n",
      "Current benign train loss: 0.24593403935432434\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.921875\n",
      "Current benign train loss: 0.2723376154899597\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.875\n",
      "Current benign train loss: 0.3306252658367157\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.8515625\n",
      "Current benign train loss: 0.4172205328941345\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.22157302498817444\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.90625\n",
      "Current benign train loss: 0.24333395063877106\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.9140625\n",
      "Current benign train loss: 0.24879223108291626\n",
      "\n",
      "Total benign train accuarcy: 89.904\n",
      "Total benign train loss: 344.7986875772476\n",
      "\n",
      "[ Test epoch: 63 ]\n",
      "\n",
      "Test accuarcy: 72.14\n",
      "Test average loss: 0.010633998173475266\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 64 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.24824188649654388\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.8828125\n",
      "Current benign train loss: 0.3564123809337616\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.859375\n",
      "Current benign train loss: 0.4169304668903351\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.921875\n",
      "Current benign train loss: 0.2188672125339508\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.890625\n",
      "Current benign train loss: 0.29339954257011414\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.90625\n",
      "Current benign train loss: 0.2392023652791977\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.90625\n",
      "Current benign train loss: 0.2506946921348572\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.9296875\n",
      "Current benign train loss: 0.25793471932411194\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.9140625\n",
      "Current benign train loss: 0.3729548454284668\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.8828125\n",
      "Current benign train loss: 0.2712133526802063\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.1960708498954773\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.921875\n",
      "Current benign train loss: 0.2785099744796753\n",
      "\n",
      "Total benign train accuarcy: 89.81533333333333\n",
      "Total benign train loss: 344.6476176008582\n",
      "\n",
      "[ Test epoch: 64 ]\n",
      "\n",
      "Test accuarcy: 42.72\n",
      "Test average loss: 0.04318117959499359\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 65 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.890625\n",
      "Current benign train loss: 0.31502634286880493\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.890625\n",
      "Current benign train loss: 0.3241350054740906\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.921875\n",
      "Current benign train loss: 0.21735455095767975\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9140625\n",
      "Current benign train loss: 0.2580674886703491\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.8046875\n",
      "Current benign train loss: 0.4437265396118164\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.90625\n",
      "Current benign train loss: 0.30389851331710815\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.9296875\n",
      "Current benign train loss: 0.1687111109495163\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.921875\n",
      "Current benign train loss: 0.2259717732667923\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.8984375\n",
      "Current benign train loss: 0.29320791363716125\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.875\n",
      "Current benign train loss: 0.4040137529373169\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.9140625\n",
      "Current benign train loss: 0.2582939565181732\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.90625\n",
      "Current benign train loss: 0.2875193953514099\n",
      "\n",
      "Total benign train accuarcy: 90.00133333333333\n",
      "Total benign train loss: 340.77542221546173\n",
      "\n",
      "[ Test epoch: 65 ]\n",
      "\n",
      "Test accuarcy: 70.79\n",
      "Test average loss: 0.010409253919124603\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 66 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.921875\n",
      "Current benign train loss: 0.2644597589969635\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.921875\n",
      "Current benign train loss: 0.28013452887535095\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.8671875\n",
      "Current benign train loss: 0.38198286294937134\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.921875\n",
      "Current benign train loss: 0.24489450454711914\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.8984375\n",
      "Current benign train loss: 0.2119760811328888\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.921875\n",
      "Current benign train loss: 0.2590351402759552\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.890625\n",
      "Current benign train loss: 0.3059057295322418\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.921875\n",
      "Current benign train loss: 0.25681042671203613\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.9140625\n",
      "Current benign train loss: 0.2065962255001068\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.90625\n",
      "Current benign train loss: 0.29737481474876404\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.84375\n",
      "Current benign train loss: 0.44298723340034485\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.8359375\n",
      "Current benign train loss: 0.4287551939487457\n",
      "\n",
      "Total benign train accuarcy: 90.09733333333334\n",
      "Total benign train loss: 337.2510809749365\n",
      "\n",
      "[ Test epoch: 66 ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test accuarcy: 72.35\n",
      "Test average loss: 0.009513972771167755\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 67 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.8984375\n",
      "Current benign train loss: 0.2948286235332489\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.890625\n",
      "Current benign train loss: 0.3411264419555664\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.8984375\n",
      "Current benign train loss: 0.27529042959213257\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.875\n",
      "Current benign train loss: 0.3368326723575592\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.8984375\n",
      "Current benign train loss: 0.2842724323272705\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.875\n",
      "Current benign train loss: 0.35909566283226013\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.9140625\n",
      "Current benign train loss: 0.3227026164531708\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.90625\n",
      "Current benign train loss: 0.24328619241714478\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.859375\n",
      "Current benign train loss: 0.4009701907634735\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.890625\n",
      "Current benign train loss: 0.3146435618400574\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.828125\n",
      "Current benign train loss: 0.40940243005752563\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.8828125\n",
      "Current benign train loss: 0.36260324716567993\n",
      "\n",
      "Total benign train accuarcy: 89.866\n",
      "Total benign train loss: 342.4102711677551\n",
      "\n",
      "[ Test epoch: 67 ]\n",
      "\n",
      "Test accuarcy: 54.07\n",
      "Test average loss: 0.019658449625968934\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 68 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.8671875\n",
      "Current benign train loss: 0.3930174708366394\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.921875\n",
      "Current benign train loss: 0.2427157163619995\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.890625\n",
      "Current benign train loss: 0.2916906177997589\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9140625\n",
      "Current benign train loss: 0.2601621150970459\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.890625\n",
      "Current benign train loss: 0.2564300000667572\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.921875\n",
      "Current benign train loss: 0.22095265984535217\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.890625\n",
      "Current benign train loss: 0.2522605359554291\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.21454937756061554\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.9140625\n",
      "Current benign train loss: 0.2314620018005371\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.8984375\n",
      "Current benign train loss: 0.30301955342292786\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.8984375\n",
      "Current benign train loss: 0.2745714783668518\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.890625\n",
      "Current benign train loss: 0.3309003710746765\n",
      "\n",
      "Total benign train accuarcy: 90.11666666666666\n",
      "Total benign train loss: 336.60718343406916\n",
      "\n",
      "[ Test epoch: 68 ]\n",
      "\n",
      "Test accuarcy: 68.91\n",
      "Test average loss: 0.011866789442300796\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 69 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9296875\n",
      "Current benign train loss: 0.22207388281822205\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.8984375\n",
      "Current benign train loss: 0.24425163865089417\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.24317525327205658\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.921875\n",
      "Current benign train loss: 0.23320934176445007\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.921875\n",
      "Current benign train loss: 0.27525386214256287\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9140625\n",
      "Current benign train loss: 0.2570960819721222\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.8671875\n",
      "Current benign train loss: 0.3899407386779785\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.8984375\n",
      "Current benign train loss: 0.22210536897182465\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.921875\n",
      "Current benign train loss: 0.23052212595939636\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.875\n",
      "Current benign train loss: 0.36065083742141724\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.8828125\n",
      "Current benign train loss: 0.3018421232700348\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.9296875\n",
      "Current benign train loss: 0.21844395995140076\n",
      "\n",
      "Total benign train accuarcy: 90.13133333333333\n",
      "Total benign train loss: 339.22076973319054\n",
      "\n",
      "[ Test epoch: 69 ]\n",
      "\n",
      "Test accuarcy: 55.57\n",
      "Test average loss: 0.02464839941263199\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 70 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.22049175202846527\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.8828125\n",
      "Current benign train loss: 0.3273733854293823\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.921875\n",
      "Current benign train loss: 0.2936919927597046\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.8984375\n",
      "Current benign train loss: 0.2960386574268341\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.90625\n",
      "Current benign train loss: 0.26782187819480896\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.90625\n",
      "Current benign train loss: 0.26700538396835327\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.22352083027362823\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.8828125\n",
      "Current benign train loss: 0.2594830095767975\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.8984375\n",
      "Current benign train loss: 0.3167763352394104\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.8828125\n",
      "Current benign train loss: 0.23091521859169006\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.90625\n",
      "Current benign train loss: 0.3748713433742523\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.8828125\n",
      "Current benign train loss: 0.3680315613746643\n",
      "\n",
      "Total benign train accuarcy: 90.13733333333333\n",
      "Total benign train loss: 337.4302609562874\n",
      "\n",
      "[ Test epoch: 70 ]\n",
      "\n",
      "Test accuarcy: 63.91\n",
      "Test average loss: 0.016023584938049316\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 71 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.8984375\n",
      "Current benign train loss: 0.3223000466823578\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.90625\n",
      "Current benign train loss: 0.28227952122688293\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9140625\n",
      "Current benign train loss: 0.23393236100673676\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9140625\n",
      "Current benign train loss: 0.21257102489471436\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9140625\n",
      "Current benign train loss: 0.24379149079322815\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.22039738297462463\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.8515625\n",
      "Current benign train loss: 0.3106619715690613\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.8828125\n",
      "Current benign train loss: 0.3289203643798828\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.8984375\n",
      "Current benign train loss: 0.24960839748382568\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.890625\n",
      "Current benign train loss: 0.28176525235176086\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.16150625050067902\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.875\n",
      "Current benign train loss: 0.2700723707675934\n",
      "\n",
      "Total benign train accuarcy: 90.14866666666667\n",
      "Total benign train loss: 335.3366748020053\n",
      "\n",
      "[ Test epoch: 71 ]\n",
      "\n",
      "Test accuarcy: 53.36\n",
      "Test average loss: 0.02475700752735138\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 72 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.16432368755340576\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.8984375\n",
      "Current benign train loss: 0.26509642601013184\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9296875\n",
      "Current benign train loss: 0.19043976068496704\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.921875\n",
      "Current benign train loss: 0.29092878103256226\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.8984375\n",
      "Current benign train loss: 0.2811910808086395\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.8984375\n",
      "Current benign train loss: 0.3926811218261719\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.890625\n",
      "Current benign train loss: 0.3231818675994873\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.921875\n",
      "Current benign train loss: 0.29220739006996155\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.890625\n",
      "Current benign train loss: 0.32152068614959717\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.9140625\n",
      "Current benign train loss: 0.30194568634033203\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.90625\n",
      "Current benign train loss: 0.32260793447494507\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.90625\n",
      "Current benign train loss: 0.2986440658569336\n",
      "\n",
      "Total benign train accuarcy: 90.06733333333334\n",
      "Total benign train loss: 337.3004126995802\n",
      "\n",
      "[ Test epoch: 72 ]\n",
      "\n",
      "Test accuarcy: 71.51\n",
      "Test average loss: 0.012267391389608383\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 73 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.8984375\n",
      "Current benign train loss: 0.2506944239139557\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.90625\n",
      "Current benign train loss: 0.21106678247451782\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.8828125\n",
      "Current benign train loss: 0.28992751240730286\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.8984375\n",
      "Current benign train loss: 0.3459058105945587\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.875\n",
      "Current benign train loss: 0.3014044761657715\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.19028553366661072\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.8515625\n",
      "Current benign train loss: 0.411878377199173\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.9296875\n",
      "Current benign train loss: 0.2562473714351654\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.90625\n",
      "Current benign train loss: 0.3238297700881958\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.859375\n",
      "Current benign train loss: 0.3230912387371063\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.8828125\n",
      "Current benign train loss: 0.3151354193687439\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.9296875\n",
      "Current benign train loss: 0.23453660309314728\n",
      "\n",
      "Total benign train accuarcy: 90.16733333333333\n",
      "Total benign train loss: 334.6788901463151\n",
      "\n",
      "[ Test epoch: 73 ]\n",
      "\n",
      "Test accuarcy: 43.9\n",
      "Test average loss: 0.029948380446434022\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 74 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.18877728283405304\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.16624292731285095\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.8671875\n",
      "Current benign train loss: 0.32407569885253906\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.875\n",
      "Current benign train loss: 0.350980281829834\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.8828125\n",
      "Current benign train loss: 0.3364661931991577\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.859375\n",
      "Current benign train loss: 0.31978246569633484\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.921875\n",
      "Current benign train loss: 0.17964878678321838\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.859375\n",
      "Current benign train loss: 0.31307291984558105\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.8984375\n",
      "Current benign train loss: 0.29585978388786316\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.9140625\n",
      "Current benign train loss: 0.31247901916503906\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.84375\n",
      "Current benign train loss: 0.43429720401763916\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.2062656432390213\n",
      "\n",
      "Total benign train accuarcy: 90.18333333333334\n",
      "Total benign train loss: 333.7249205261469\n",
      "\n",
      "[ Test epoch: 74 ]\n",
      "\n",
      "Test accuarcy: 49.01\n",
      "Test average loss: 0.026386636018753053\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 75 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.921875\n",
      "Current benign train loss: 0.21930697560310364\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.18156498670578003\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.8828125\n",
      "Current benign train loss: 0.3655317425727844\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9140625\n",
      "Current benign train loss: 0.24030165374279022\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.890625\n",
      "Current benign train loss: 0.2683643102645874\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.8828125\n",
      "Current benign train loss: 0.2720962464809418\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.8828125\n",
      "Current benign train loss: 0.36118626594543457\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.8828125\n",
      "Current benign train loss: 0.37537020444869995\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.875\n",
      "Current benign train loss: 0.300383061170578\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.8828125\n",
      "Current benign train loss: 0.34842920303344727\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.19888615608215332\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.890625\n",
      "Current benign train loss: 0.28978708386421204\n",
      "\n",
      "Total benign train accuarcy: 90.17733333333334\n",
      "Total benign train loss: 333.36912493407726\n",
      "\n",
      "[ Test epoch: 75 ]\n",
      "\n",
      "Test accuarcy: 58.35\n",
      "Test average loss: 0.019295767879486083\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 76 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9140625\n",
      "Current benign train loss: 0.3020956218242645\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9296875\n",
      "Current benign train loss: 0.2950010895729065\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.90625\n",
      "Current benign train loss: 0.250946044921875\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.921875\n",
      "Current benign train loss: 0.2730315923690796\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9140625\n",
      "Current benign train loss: 0.23550133407115936\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.8984375\n",
      "Current benign train loss: 0.33370402455329895\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.8828125\n",
      "Current benign train loss: 0.3351115584373474\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.9296875\n",
      "Current benign train loss: 0.23883533477783203\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.890625\n",
      "Current benign train loss: 0.23742198944091797\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.890625\n",
      "Current benign train loss: 0.33138230443000793\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.8984375\n",
      "Current benign train loss: 0.2916311025619507\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.890625\n",
      "Current benign train loss: 0.24837614595890045\n",
      "\n",
      "Total benign train accuarcy: 90.19733333333333\n",
      "Total benign train loss: 331.7284808680415\n",
      "\n",
      "[ Test epoch: 76 ]\n",
      "\n",
      "Test accuarcy: 50.64\n",
      "Test average loss: 0.03129587960243225\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 77 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.890625\n",
      "Current benign train loss: 0.3116647005081177\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.12644444406032562\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9140625\n",
      "Current benign train loss: 0.2840879559516907\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.8515625\n",
      "Current benign train loss: 0.39525848627090454\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.890625\n",
      "Current benign train loss: 0.3915662467479706\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.8984375\n",
      "Current benign train loss: 0.2575560212135315\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.8984375\n",
      "Current benign train loss: 0.22180171310901642\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.8984375\n",
      "Current benign train loss: 0.3262125551700592\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.8984375\n",
      "Current benign train loss: 0.26592209935188293\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.8828125\n",
      "Current benign train loss: 0.3592488169670105\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.2083216905593872\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.17604534327983856\n",
      "\n",
      "Total benign train accuarcy: 90.438\n",
      "Total benign train loss: 327.2142761722207\n",
      "\n",
      "[ Test epoch: 77 ]\n",
      "\n",
      "Test accuarcy: 56.54\n",
      "Test average loss: 0.01923711676597595\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 78 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.921875\n",
      "Current benign train loss: 0.2454141080379486\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9140625\n",
      "Current benign train loss: 0.22414182126522064\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9140625\n",
      "Current benign train loss: 0.2718869745731354\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9140625\n",
      "Current benign train loss: 0.2565622329711914\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.921875\n",
      "Current benign train loss: 0.21876932680606842\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.8828125\n",
      "Current benign train loss: 0.3222237825393677\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.8984375\n",
      "Current benign train loss: 0.30417144298553467\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.8984375\n",
      "Current benign train loss: 0.2905004918575287\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.19060388207435608\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.90625\n",
      "Current benign train loss: 0.24582929909229279\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.8828125\n",
      "Current benign train loss: 0.3052075207233429\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.8984375\n",
      "Current benign train loss: 0.3156593143939972\n",
      "\n",
      "Total benign train accuarcy: 90.39666666666666\n",
      "Total benign train loss: 326.2133252173662\n",
      "\n",
      "[ Test epoch: 78 ]\n",
      "\n",
      "Test accuarcy: 70.85\n",
      "Test average loss: 0.011364431869983673\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 79 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.875\n",
      "Current benign train loss: 0.345003217458725\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.8984375\n",
      "Current benign train loss: 0.2694249749183655\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.90625\n",
      "Current benign train loss: 0.23591166734695435\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.84375\n",
      "Current benign train loss: 0.35959115624427795\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.17000146210193634\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.8671875\n",
      "Current benign train loss: 0.3869018852710724\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.8515625\n",
      "Current benign train loss: 0.30928850173950195\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.890625\n",
      "Current benign train loss: 0.31170547008514404\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.15836840867996216\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.22574324905872345\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.875\n",
      "Current benign train loss: 0.3061072826385498\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.1436249166727066\n",
      "\n",
      "Total benign train accuarcy: 90.34933333333333\n",
      "Total benign train loss: 326.86669101566076\n",
      "\n",
      "[ Test epoch: 79 ]\n",
      "\n",
      "Test accuarcy: 61.23\n",
      "Test average loss: 0.018897735941410063\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 80 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.16014529764652252\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.8984375\n",
      "Current benign train loss: 0.2608203589916229\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.921875\n",
      "Current benign train loss: 0.26285040378570557\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9140625\n",
      "Current benign train loss: 0.24493470788002014\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.15216830372810364\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.8984375\n",
      "Current benign train loss: 0.27571630477905273\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.18662048876285553\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.16816531121730804\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.921875\n",
      "Current benign train loss: 0.2544019818305969\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.921875\n",
      "Current benign train loss: 0.26554644107818604\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.859375\n",
      "Current benign train loss: 0.3781532347202301\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.890625\n",
      "Current benign train loss: 0.32433634996414185\n",
      "\n",
      "Total benign train accuarcy: 90.48133333333334\n",
      "Total benign train loss: 325.5928196310997\n",
      "\n",
      "[ Test epoch: 80 ]\n",
      "\n",
      "Test accuarcy: 68.2\n",
      "Test average loss: 0.01296949023604393\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 81 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.859375\n",
      "Current benign train loss: 0.35752829909324646\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9296875\n",
      "Current benign train loss: 0.26907867193222046\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.890625\n",
      "Current benign train loss: 0.3057807683944702\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.90625\n",
      "Current benign train loss: 0.29774436354637146\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.18103966116905212\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.8671875\n",
      "Current benign train loss: 0.3151768445968628\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.890625\n",
      "Current benign train loss: 0.3127342462539673\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.17464818060398102\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.875\n",
      "Current benign train loss: 0.3831210136413574\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.9140625\n",
      "Current benign train loss: 0.24286504089832306\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.859375\n",
      "Current benign train loss: 0.39502620697021484\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.20722424983978271\n",
      "\n",
      "Total benign train accuarcy: 90.548\n",
      "Total benign train loss: 322.8594503700733\n",
      "\n",
      "[ Test epoch: 81 ]\n",
      "\n",
      "Test accuarcy: 64.76\n",
      "Test average loss: 0.015092026424407958\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 82 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9296875\n",
      "Current benign train loss: 0.25176653265953064\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.890625\n",
      "Current benign train loss: 0.35985878109931946\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.890625\n",
      "Current benign train loss: 0.2718473970890045\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.24651186168193817\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.8828125\n",
      "Current benign train loss: 0.2524625062942505\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.875\n",
      "Current benign train loss: 0.33375757932662964\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.90625\n",
      "Current benign train loss: 0.25960755348205566\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.10365195572376251\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.921875\n",
      "Current benign train loss: 0.17494142055511475\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.9296875\n",
      "Current benign train loss: 0.22273340821266174\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.9296875\n",
      "Current benign train loss: 0.22916220128536224\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.9140625\n",
      "Current benign train loss: 0.20268797874450684\n",
      "\n",
      "Total benign train accuarcy: 90.44333333333333\n",
      "Total benign train loss: 323.16496301442385\n",
      "\n",
      "[ Test epoch: 82 ]\n",
      "\n",
      "Test accuarcy: 48.14\n",
      "Test average loss: 0.02495233761072159\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 83 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.8828125\n",
      "Current benign train loss: 0.295970618724823\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9296875\n",
      "Current benign train loss: 0.19925673305988312\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9140625\n",
      "Current benign train loss: 0.2807433009147644\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.921875\n",
      "Current benign train loss: 0.1686956137418747\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.90625\n",
      "Current benign train loss: 0.2486884593963623\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.8984375\n",
      "Current benign train loss: 0.28706493973731995\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.90625\n",
      "Current benign train loss: 0.23298200964927673\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.9140625\n",
      "Current benign train loss: 0.288659930229187\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.9296875\n",
      "Current benign train loss: 0.2481537014245987\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.890625\n",
      "Current benign train loss: 0.32417353987693787\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.1994791179895401\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.9140625\n",
      "Current benign train loss: 0.24167490005493164\n",
      "\n",
      "Total benign train accuarcy: 90.502\n",
      "Total benign train loss: 323.7369509637356\n",
      "\n",
      "[ Test epoch: 83 ]\n",
      "\n",
      "Test accuarcy: 56.88\n",
      "Test average loss: 0.01817268377542496\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 84 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.890625\n",
      "Current benign train loss: 0.28483882546424866\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.20386020839214325\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.890625\n",
      "Current benign train loss: 0.2422291338443756\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.8984375\n",
      "Current benign train loss: 0.24483808875083923\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9296875\n",
      "Current benign train loss: 0.2057054340839386\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.921875\n",
      "Current benign train loss: 0.224493145942688\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.9140625\n",
      "Current benign train loss: 0.25917601585388184\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.9140625\n",
      "Current benign train loss: 0.2597084641456604\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.9296875\n",
      "Current benign train loss: 0.20881201326847076\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.90625\n",
      "Current benign train loss: 0.2587939500808716\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.9140625\n",
      "Current benign train loss: 0.2564746141433716\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.90625\n",
      "Current benign train loss: 0.24011437594890594\n",
      "\n",
      "Total benign train accuarcy: 90.65133333333333\n",
      "Total benign train loss: 317.6602276042104\n",
      "\n",
      "[ Test epoch: 84 ]\n",
      "\n",
      "Test accuarcy: 66.52\n",
      "Test average loss: 0.014617485231161118\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 85 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.90625\n",
      "Current benign train loss: 0.28349003195762634\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.921875\n",
      "Current benign train loss: 0.23492053151130676\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9296875\n",
      "Current benign train loss: 0.21522989869117737\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.18694959580898285\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9140625\n",
      "Current benign train loss: 0.2584308087825775\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9140625\n",
      "Current benign train loss: 0.30269476771354675\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.8828125\n",
      "Current benign train loss: 0.3126513361930847\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.859375\n",
      "Current benign train loss: 0.3450400233268738\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.8984375\n",
      "Current benign train loss: 0.32407239079475403\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.8515625\n",
      "Current benign train loss: 0.5208231806755066\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.19198668003082275\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.8984375\n",
      "Current benign train loss: 0.26891306042671204\n",
      "\n",
      "Total benign train accuarcy: 90.53866666666667\n",
      "Total benign train loss: 320.76766361296177\n",
      "\n",
      "[ Test epoch: 85 ]\n",
      "\n",
      "Test accuarcy: 58.59\n",
      "Test average loss: 0.020878516542911528\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 86 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.8984375\n",
      "Current benign train loss: 0.3285573124885559\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9140625\n",
      "Current benign train loss: 0.26727959513664246\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.8828125\n",
      "Current benign train loss: 0.34395337104797363\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9296875\n",
      "Current benign train loss: 0.2228630632162094\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.21321327984333038\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.921875\n",
      "Current benign train loss: 0.2657696306705475\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.921875\n",
      "Current benign train loss: 0.2621728181838989\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.8671875\n",
      "Current benign train loss: 0.4095207154750824\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.875\n",
      "Current benign train loss: 0.27802014350891113\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.21747668087482452\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.21200571954250336\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.90625\n",
      "Current benign train loss: 0.2841005325317383\n",
      "\n",
      "Total benign train accuarcy: 90.8\n",
      "Total benign train loss: 313.5283858180046\n",
      "\n",
      "[ Test epoch: 86 ]\n",
      "\n",
      "Test accuarcy: 40.06\n",
      "Test average loss: 0.04411377317905426\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 87 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9140625\n",
      "Current benign train loss: 0.2114776223897934\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.90625\n",
      "Current benign train loss: 0.2456188201904297\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.859375\n",
      "Current benign train loss: 0.41709017753601074\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9296875\n",
      "Current benign train loss: 0.20562799274921417\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.921875\n",
      "Current benign train loss: 0.22677963972091675\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9140625\n",
      "Current benign train loss: 0.2906429171562195\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.8671875\n",
      "Current benign train loss: 0.29765868186950684\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.8984375\n",
      "Current benign train loss: 0.26360589265823364\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.90625\n",
      "Current benign train loss: 0.3271523714065552\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.1751570850610733\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.26159384846687317\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.9140625\n",
      "Current benign train loss: 0.28365015983581543\n",
      "\n",
      "Total benign train accuarcy: 90.73533333333333\n",
      "Total benign train loss: 317.61339858174324\n",
      "\n",
      "[ Test epoch: 87 ]\n",
      "\n",
      "Test accuarcy: 56.05\n",
      "Test average loss: 0.020452434945106505\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 88 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.8828125\n",
      "Current benign train loss: 0.2872960865497589\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.90625\n",
      "Current benign train loss: 0.23436887562274933\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9140625\n",
      "Current benign train loss: 0.2356833666563034\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.90625\n",
      "Current benign train loss: 0.2913777232170105\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9140625\n",
      "Current benign train loss: 0.27884814143180847\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.875\n",
      "Current benign train loss: 0.3094235062599182\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.8828125\n",
      "Current benign train loss: 0.3385906517505646\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.921875\n",
      "Current benign train loss: 0.2600483298301697\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.875\n",
      "Current benign train loss: 0.41825276613235474\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.9140625\n",
      "Current benign train loss: 0.2857667803764343\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.8671875\n",
      "Current benign train loss: 0.4364013969898224\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.890625\n",
      "Current benign train loss: 0.3432471454143524\n",
      "\n",
      "Total benign train accuarcy: 90.688\n",
      "Total benign train loss: 316.4502320960164\n",
      "\n",
      "[ Test epoch: 88 ]\n",
      "\n",
      "Test accuarcy: 60.33\n",
      "Test average loss: 0.01799484088420868\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 89 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.21268227696418762\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9296875\n",
      "Current benign train loss: 0.23694604635238647\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.17115995287895203\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.90625\n",
      "Current benign train loss: 0.29941171407699585\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9140625\n",
      "Current benign train loss: 0.30797821283340454\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.20461657643318176\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.9140625\n",
      "Current benign train loss: 0.2909979522228241\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.875\n",
      "Current benign train loss: 0.3556109666824341\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.8828125\n",
      "Current benign train loss: 0.36163628101348877\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.8828125\n",
      "Current benign train loss: 0.28216221928596497\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.9296875\n",
      "Current benign train loss: 0.2734134793281555\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.09740102291107178\n",
      "\n",
      "Total benign train accuarcy: 90.80466666666666\n",
      "Total benign train loss: 313.983773201704\n",
      "\n",
      "[ Test epoch: 89 ]\n",
      "\n",
      "Test accuarcy: 49.75\n",
      "Test average loss: 0.023883557236194612\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 90 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9140625\n",
      "Current benign train loss: 0.24505192041397095\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.17020532488822937\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.12816691398620605\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.90625\n",
      "Current benign train loss: 0.23154078423976898\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.1983734667301178\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.1558798849582672\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.1572529524564743\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.9296875\n",
      "Current benign train loss: 0.20522134006023407\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.921875\n",
      "Current benign train loss: 0.1979416459798813\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.14315304160118103\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.15816974639892578\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.16780464351177216\n",
      "\n",
      "Total benign train accuarcy: 94.18733333333333\n",
      "Total benign train loss: 207.82399548590183\n",
      "\n",
      "[ Test epoch: 90 ]\n",
      "\n",
      "Test accuarcy: 87.04\n",
      "Test average loss: 0.004174369939416647\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 91 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.90625\n",
      "Current benign train loss: 0.2240849733352661\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.13440877199172974\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.1350696086883545\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.17387865483760834\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.16657930612564087\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.1689685434103012\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.12552410364151\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.15130701661109924\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.13845640420913696\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.16450782120227814\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0694742500782013\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.09439152479171753\n",
      "\n",
      "Total benign train accuarcy: 94.82266666666666\n",
      "Total benign train loss: 187.15016494318843\n",
      "\n",
      "[ Test epoch: 91 ]\n",
      "\n",
      "Test accuarcy: 87.97\n",
      "Test average loss: 0.0039785899192094805\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 92 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.15591195225715637\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.07380804419517517\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.09646762162446976\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.11794793605804443\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.90625\n",
      "Current benign train loss: 0.2548510432243347\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.14759498834609985\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.11271669715642929\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.13540048897266388\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.90625\n",
      "Current benign train loss: 0.2921662926673889\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.1538575291633606\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.13632993400096893\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.15921346843242645\n",
      "\n",
      "Total benign train accuarcy: 95.082\n",
      "Total benign train loss: 178.95378478616476\n",
      "\n",
      "[ Test epoch: 92 ]\n",
      "\n",
      "Test accuarcy: 87.68\n",
      "Test average loss: 0.004039639662206173\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 93 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.20182666182518005\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.09428390115499496\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.15575432777404785\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9296875\n",
      "Current benign train loss: 0.16236287355422974\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.071723073720932\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.1784185767173767\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.10793626308441162\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.1344045102596283\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.13451354205608368\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.9296875\n",
      "Current benign train loss: 0.18023572862148285\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.9296875\n",
      "Current benign train loss: 0.19279319047927856\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.158478245139122\n",
      "\n",
      "Total benign train accuarcy: 95.26666666666667\n",
      "Total benign train loss: 174.8226128667593\n",
      "\n",
      "[ Test epoch: 93 ]\n",
      "\n",
      "Test accuarcy: 88.47\n",
      "Test average loss: 0.0035730482041835786\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 94 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.07545981556177139\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9296875\n",
      "Current benign train loss: 0.21297399699687958\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.1189141795039177\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.0932643860578537\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.1910725235939026\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9296875\n",
      "Current benign train loss: 0.14031508564949036\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.921875\n",
      "Current benign train loss: 0.18751966953277588\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.1342572420835495\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.16456738114356995\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.12379172444343567\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.1461552232503891\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.17672431468963623\n",
      "\n",
      "Total benign train accuarcy: 95.328\n",
      "Total benign train loss: 169.8079288378358\n",
      "\n",
      "[ Test epoch: 94 ]\n",
      "\n",
      "Test accuarcy: 88.89\n",
      "Test average loss: 0.0035991397552192213\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 95 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.14520004391670227\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.10434764623641968\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.16569015383720398\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.16460950672626495\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.11641901731491089\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.16570182144641876\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.10840167850255966\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.13466091454029083\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.12737952172756195\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.9140625\n",
      "Current benign train loss: 0.22701120376586914\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.15475542843341827\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.18984049558639526\n",
      "\n",
      "Total benign train accuarcy: 95.33866666666667\n",
      "Total benign train loss: 170.4184377118945\n",
      "\n",
      "[ Test epoch: 95 ]\n",
      "\n",
      "Test accuarcy: 87.03\n",
      "Test average loss: 0.0041840994961559776\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 96 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.07899034023284912\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.12378612160682678\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.12831304967403412\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.921875\n",
      "Current benign train loss: 0.2115129977464676\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.1390407532453537\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.11310441792011261\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.9140625\n",
      "Current benign train loss: 0.24895846843719482\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.13362334668636322\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.1913834661245346\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.13202205300331116\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.15435881912708282\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.1375971883535385\n",
      "\n",
      "Total benign train accuarcy: 95.47733333333333\n",
      "Total benign train loss: 166.49238608032465\n",
      "\n",
      "[ Test epoch: 96 ]\n",
      "\n",
      "Test accuarcy: 88.02\n",
      "Test average loss: 0.0037609354048967363\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 97 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.0900452509522438\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.09920412302017212\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.1352420449256897\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.10048042982816696\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.0612361878156662\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.18603815138339996\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.1804753690958023\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.07811249047517776\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.20860372483730316\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.13939669728279114\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.9296875\n",
      "Current benign train loss: 0.16413089632987976\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.19539202749729156\n",
      "\n",
      "Total benign train accuarcy: 95.49533333333333\n",
      "Total benign train loss: 164.79501213505864\n",
      "\n",
      "[ Test epoch: 97 ]\n",
      "\n",
      "Test accuarcy: 88.06\n",
      "Test average loss: 0.0037845166712999344\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 98 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.1335873007774353\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.14325332641601562\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.921875\n",
      "Current benign train loss: 0.2337975800037384\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.15682324767112732\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.11783000081777573\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.06822588294744492\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.1133279949426651\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.11243584752082825\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.10905895382165909\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.08760785311460495\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.06783339381217957\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.06878647208213806\n",
      "\n",
      "Total benign train accuarcy: 95.60733333333333\n",
      "Total benign train loss: 162.09416277334094\n",
      "\n",
      "[ Test epoch: 98 ]\n",
      "\n",
      "Test accuarcy: 88.54\n",
      "Test average loss: 0.0037150164499878883\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 99 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.15086442232131958\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.09324080497026443\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.15462039411067963\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.921875\n",
      "Current benign train loss: 0.1578129678964615\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.10265667736530304\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.11563078314065933\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.921875\n",
      "Current benign train loss: 0.23996815085411072\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.16946591436862946\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.11291244626045227\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.1188644990324974\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.13857443630695343\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.15938130021095276\n",
      "\n",
      "Total benign train accuarcy: 95.60733333333333\n",
      "Total benign train loss: 162.31715131551027\n",
      "\n",
      "[ Test epoch: 99 ]\n",
      "\n",
      "Test accuarcy: 87.16\n",
      "Test average loss: 0.004075868146121502\n",
      "Model Saved!\n",
      "Total: 14415.620359659195 sec\n",
      "Train: 14412.942321538925 sec\n"
     ]
    }
   ],
   "source": [
    "train_start = time.time()\n",
    "\n",
    "# for epoch in range(0, 200):\n",
    "for epoch in range(0, 100):\n",
    "    adjust_learning_rate(optimizer, epoch)\n",
    "    train(epoch)\n",
    "    test(epoch)\n",
    "\n",
    "end = time.time()\n",
    "print(f'Total: {end - start} sec')\n",
    "print(f'Train: {end - train_start} sec')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOPIzvdWtH9nlTSWQL5mAew",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "ResNet18_CIFAR10_Train",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0dea8eb11bbc4c779008942559cff4db": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a1d1034a83034942b9174d8a46447ef0",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ff98ccdfba314fe5a6d9e477c6d4bd4b",
      "value": 1
     }
    },
    "0ec3fad637ae4f5d8f9aa3a84e2cd7bd": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1c9448bb0e7b4d4bb219f9313bff333f",
      "placeholder": "​",
      "style": "IPY_MODEL_516e46a6995e4c10b928f2dbbbdd005a",
      "value": " 170500096/? [00:20&lt;00:00, 100483168.85it/s]"
     }
    },
    "1c9448bb0e7b4d4bb219f9313bff333f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "516e46a6995e4c10b928f2dbbbdd005a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "987ce5cdc16f4c568f979204fa7506f2": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a1d1034a83034942b9174d8a46447ef0": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c33e7c07bfc847efa64429ee4eb640db": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0dea8eb11bbc4c779008942559cff4db",
       "IPY_MODEL_0ec3fad637ae4f5d8f9aa3a84e2cd7bd"
      ],
      "layout": "IPY_MODEL_987ce5cdc16f4c568f979204fa7506f2"
     }
    },
    "ff98ccdfba314fe5a6d9e477c6d4bd4b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
