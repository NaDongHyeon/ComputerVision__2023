{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/ndb796/Deep-Learning-Paper-Review-and-Practice/blob/master/code_practices/ResNet18_CIFAR10_Train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "\n",
    "torch.cuda.is_available()\n",
    "\n",
    "start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed(0)\n",
    "torch.cuda.manual_seed_all(0)\n",
    "cudnn.benchmark = False\n",
    "cudnn.deterministic = True\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x2SSsQMSknm2"
   },
   "source": [
    "#### ResNet18 모델 정의 및 인스턴스 초기화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "zpUcgk5xkgGZ"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import os\n",
    "\n",
    "\n",
    "# ResNet18을 위해 최대한 간단히 수정한 BasicBlock 클래스 정의\n",
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "\n",
    "        # 3x3 필터를 사용 (너비와 높이를 줄일 때는 stride 값 조절)\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes) # 배치 정규화(batch normalization)\n",
    "\n",
    "        # 3x3 필터를 사용 (패딩을 1만큼 주기 때문에 너비와 높이가 동일)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes) # 배치 정규화(batch normalization)\n",
    "\n",
    "        self.shortcut = nn.Sequential() # identity인 경우\n",
    "        if stride != 1: # stride가 1이 아니라면, Identity mapping이 아닌 경우\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, planes, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.tanh(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x) # (핵심) skip connection\n",
    "        out = F.tanh(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "# ResNet 클래스 정의\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 64\n",
    "\n",
    "        # 64개의 3x3 필터(filter)를 사용\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "        self.linear = nn.Linear(512, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1] * (num_blocks - 1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes # 다음 레이어를 위해 채널 수 변경\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.tanh(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "# ResNet18 함수 정의\n",
    "def ResNet18():\n",
    "    return ResNet(BasicBlock, [2, 2, 2, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nCNacrgtktlr"
   },
   "source": [
    "#### 데이터셋(Dataset) 다운로드 및 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 125,
     "referenced_widgets": [
      "c33e7c07bfc847efa64429ee4eb640db",
      "987ce5cdc16f4c568f979204fa7506f2",
      "0dea8eb11bbc4c779008942559cff4db",
      "0ec3fad637ae4f5d8f9aa3a84e2cd7bd",
      "ff98ccdfba314fe5a6d9e477c6d4bd4b",
      "a1d1034a83034942b9174d8a46447ef0",
      "516e46a6995e4c10b928f2dbbbdd005a",
      "1c9448bb0e7b4d4bb219f9313bff333f"
     ]
    },
    "id": "EmmQZ8p5kq_C",
    "outputId": "ae6624d1-332f-412c-b2fc-51141afb1520"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import ConcatDataset\n",
    "\n",
    "\n",
    "data_transformations = {\n",
    "    \"crop_flip\": transforms.Compose([  # 크롭 + 뒤집기\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),]), \n",
    "\n",
    "    \"color_blur\": transforms.Compose([  # 색깔 + 블러\n",
    "     transforms.ColorJitter(brightness=(0.5, 0.9), \n",
    "                           contrast=(0.4, 0.8), \n",
    "                           saturation=(0.7, 0.9),\n",
    "                           hue=(-0.2, 0.2),\n",
    "                          ),\n",
    "    transforms.GaussianBlur(kernel_size=(19, 19), sigma=(1.0, 2.0)),\n",
    "    transforms.ToTensor()]),\n",
    "\n",
    "    \"basic\": transforms.Compose([\n",
    "    transforms.ToTensor()])\n",
    "}\n",
    "\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=data_transformations[\"basic\"])\n",
    "train_aug_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, transform=data_transformations[\"crop_flip\"])\n",
    "train_aug_dataset2 = torchvision.datasets.CIFAR10(root='./data', train=True, transform=data_transformations[\"color_blur\"])\n",
    "                                                  \n",
    "augmented_train_data = ConcatDataset((train_dataset,train_aug_dataset, train_aug_dataset2 ))\n",
    "\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=data_transformations[\"basic\"])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(augmented_train_data, batch_size=128, shuffle=True, num_workers=4)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=100, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dl1-47E7pHD_"
   },
   "source": [
    "#### 환경 설정 및 학습(Training) 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "bhm_eVykk-Z8"
   },
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "\n",
    "net = ResNet18()\n",
    "net = net.to(device)\n",
    "net = torch.nn.DataParallel(net)\n",
    "cudnn.benchmark = True\n",
    "\n",
    "learning_rate = 0.1\n",
    "file_name = 'resnet18_cifar10.pt'\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9, weight_decay=0.0002)\n",
    "\n",
    "\n",
    "def train(epoch):\n",
    "    print('\\n[ Train epoch: %d ]' % epoch)\n",
    "    net.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        benign_outputs = net(inputs)\n",
    "        loss = criterion(benign_outputs, targets)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = benign_outputs.max(1)\n",
    "\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "        \n",
    "        if batch_idx % 100 == 0:\n",
    "            print('\\nCurrent batch:', str(batch_idx))\n",
    "            print('Current benign train accuracy:', str(predicted.eq(targets).sum().item() / targets.size(0)))\n",
    "            print('Current benign train loss:', loss.item())\n",
    "\n",
    "    print('\\nTotal benign train accuarcy:', 100. * correct / total)\n",
    "    print('Total benign train loss:', train_loss)\n",
    "\n",
    "\n",
    "def test(epoch):\n",
    "    print('\\n[ Test epoch: %d ]' % epoch)\n",
    "    net.eval()\n",
    "    loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for batch_idx, (inputs, targets) in enumerate(test_loader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        total += targets.size(0)\n",
    "\n",
    "        outputs = net(inputs)\n",
    "        loss += criterion(outputs, targets).item()\n",
    "\n",
    "        _, predicted = outputs.max(1)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "    print('\\nTest accuarcy:', 100. * correct / total)\n",
    "    print('Test average loss:', loss / total)\n",
    "\n",
    "    state = {\n",
    "        'net': net.state_dict()\n",
    "    }\n",
    "    if not os.path.isdir('checkpoint'):\n",
    "        os.mkdir('checkpoint')\n",
    "    torch.save(state, './checkpoint/' + file_name)\n",
    "    print('Model Saved!')\n",
    "\n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    lr = learning_rate\n",
    "    if epoch >= 50:\n",
    "        lr = 0.01\n",
    "    if epoch >= 90:\n",
    "        lr = 0.001\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0mv5z7CEMRrn"
   },
   "source": [
    "#### 학습(Training) 진행"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IFdh-H1MPf0c"
   },
   "source": [
    "* 대략 20번의 epoch 이후에도 85%가량의 test accuracy를 얻을 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "4voLj7TKlaB1",
    "outputId": "76463b85-2f4f-4bc0-a945-c73cc669c67e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ Train epoch: 0 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.0703125\n",
      "Current benign train loss: 2.325767755508423\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.328125\n",
      "Current benign train loss: 1.9956191778182983\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.3671875\n",
      "Current benign train loss: 1.8991990089416504\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.3125\n",
      "Current benign train loss: 1.9035181999206543\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.3671875\n",
      "Current benign train loss: 1.7265806198120117\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.2578125\n",
      "Current benign train loss: 1.9510366916656494\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.4453125\n",
      "Current benign train loss: 1.6624360084533691\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.453125\n",
      "Current benign train loss: 1.5394573211669922\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.4375\n",
      "Current benign train loss: 1.6587942838668823\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.4140625\n",
      "Current benign train loss: 1.6393587589263916\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.421875\n",
      "Current benign train loss: 1.5327097177505493\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.484375\n",
      "Current benign train loss: 1.4169321060180664\n",
      "\n",
      "Total benign train accuarcy: 37.111333333333334\n",
      "Total benign train loss: 2019.5401163101196\n",
      "\n",
      "[ Test epoch: 0 ]\n",
      "\n",
      "Test accuarcy: 51.17\n",
      "Test average loss: 0.013621014750003815\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 1 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.515625\n",
      "Current benign train loss: 1.3755733966827393\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.484375\n",
      "Current benign train loss: 1.3732244968414307\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.40625\n",
      "Current benign train loss: 1.5903534889221191\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.453125\n",
      "Current benign train loss: 1.3407182693481445\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.546875\n",
      "Current benign train loss: 1.2043429613113403\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.5703125\n",
      "Current benign train loss: 1.2170026302337646\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.6015625\n",
      "Current benign train loss: 1.1984535455703735\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.546875\n",
      "Current benign train loss: 1.22467041015625\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.5625\n",
      "Current benign train loss: 1.2772127389907837\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.6171875\n",
      "Current benign train loss: 1.1144676208496094\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.59375\n",
      "Current benign train loss: 1.1179147958755493\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.5703125\n",
      "Current benign train loss: 1.073794960975647\n",
      "\n",
      "Total benign train accuarcy: 55.874\n",
      "Total benign train loss: 1435.393410384655\n",
      "\n",
      "[ Test epoch: 1 ]\n",
      "\n",
      "Test accuarcy: 61.4\n",
      "Test average loss: 0.01066049686074257\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 2 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.59375\n",
      "Current benign train loss: 1.1389049291610718\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.546875\n",
      "Current benign train loss: 1.1810851097106934\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.5390625\n",
      "Current benign train loss: 1.124275803565979\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.6953125\n",
      "Current benign train loss: 0.9051957726478577\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.609375\n",
      "Current benign train loss: 1.1306886672973633\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.6328125\n",
      "Current benign train loss: 1.012257695198059\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.625\n",
      "Current benign train loss: 1.0019408464431763\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.6015625\n",
      "Current benign train loss: 1.0925816297531128\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.6171875\n",
      "Current benign train loss: 1.1228705644607544\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.6640625\n",
      "Current benign train loss: 1.129047155380249\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.6875\n",
      "Current benign train loss: 0.8559160232543945\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.640625\n",
      "Current benign train loss: 0.9676021337509155\n",
      "\n",
      "Total benign train accuarcy: 64.63733333333333\n",
      "Total benign train loss: 1165.8532584309578\n",
      "\n",
      "[ Test epoch: 2 ]\n",
      "\n",
      "Test accuarcy: 71.3\n",
      "Test average loss: 0.008215899497270585\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 3 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.6796875\n",
      "Current benign train loss: 0.8071063160896301\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.7265625\n",
      "Current benign train loss: 0.8002035021781921\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.6953125\n",
      "Current benign train loss: 0.9058310985565186\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.6796875\n",
      "Current benign train loss: 0.92050701379776\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.6796875\n",
      "Current benign train loss: 0.8493414521217346\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.6640625\n",
      "Current benign train loss: 0.9185704588890076\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.640625\n",
      "Current benign train loss: 0.926058828830719\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.640625\n",
      "Current benign train loss: 0.9073458313941956\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.6640625\n",
      "Current benign train loss: 0.9820798635482788\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.703125\n",
      "Current benign train loss: 0.7336611151695251\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.6953125\n",
      "Current benign train loss: 0.9239579439163208\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.640625\n",
      "Current benign train loss: 0.9802923202514648\n",
      "\n",
      "Total benign train accuarcy: 69.698\n",
      "Total benign train loss: 1009.2163279652596\n",
      "\n",
      "[ Test epoch: 3 ]\n",
      "\n",
      "Test accuarcy: 71.11\n",
      "Test average loss: 0.00843379948735237\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 4 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.7265625\n",
      "Current benign train loss: 0.7697564363479614\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.7109375\n",
      "Current benign train loss: 0.7679265737533569\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.7109375\n",
      "Current benign train loss: 0.7746249437332153\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.7265625\n",
      "Current benign train loss: 0.8224443793296814\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.65625\n",
      "Current benign train loss: 0.8141118288040161\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.734375\n",
      "Current benign train loss: 0.9008130431175232\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.71875\n",
      "Current benign train loss: 0.8095102906227112\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.7734375\n",
      "Current benign train loss: 0.6938539743423462\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.6875\n",
      "Current benign train loss: 0.9691764712333679\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.71875\n",
      "Current benign train loss: 0.7522231936454773\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.78125\n",
      "Current benign train loss: 0.6172344088554382\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.6953125\n",
      "Current benign train loss: 0.8195992708206177\n",
      "\n",
      "Total benign train accuarcy: 72.71466666666667\n",
      "Total benign train loss: 910.3580135703087\n",
      "\n",
      "[ Test epoch: 4 ]\n",
      "\n",
      "Test accuarcy: 75.33\n",
      "Test average loss: 0.007127894964814186\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 5 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.7265625\n",
      "Current benign train loss: 0.6465897560119629\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.7265625\n",
      "Current benign train loss: 0.6736868619918823\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.71875\n",
      "Current benign train loss: 0.7518414855003357\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.78125\n",
      "Current benign train loss: 0.6564791798591614\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.71875\n",
      "Current benign train loss: 0.7542531490325928\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.7578125\n",
      "Current benign train loss: 0.6868391036987305\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.8046875\n",
      "Current benign train loss: 0.5736879110336304\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.7734375\n",
      "Current benign train loss: 0.6757869124412537\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.765625\n",
      "Current benign train loss: 0.7654202580451965\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.796875\n",
      "Current benign train loss: 0.585229754447937\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.8046875\n",
      "Current benign train loss: 0.7021607160568237\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.78125\n",
      "Current benign train loss: 0.5611531734466553\n",
      "\n",
      "Total benign train accuarcy: 74.98066666666666\n",
      "Total benign train loss: 838.2965720593929\n",
      "\n",
      "[ Test epoch: 5 ]\n",
      "\n",
      "Test accuarcy: 74.77\n",
      "Test average loss: 0.007209786114096641\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 6 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.796875\n",
      "Current benign train loss: 0.6055938601493835\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.796875\n",
      "Current benign train loss: 0.5718464255332947\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.828125\n",
      "Current benign train loss: 0.5960429906845093\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.8125\n",
      "Current benign train loss: 0.6241905689239502\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.734375\n",
      "Current benign train loss: 0.7038561701774597\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.71875\n",
      "Current benign train loss: 0.6720436811447144\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.7578125\n",
      "Current benign train loss: 0.6914750337600708\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.765625\n",
      "Current benign train loss: 0.612995445728302\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.8125\n",
      "Current benign train loss: 0.545482873916626\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.7421875\n",
      "Current benign train loss: 0.6718301177024841\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.7578125\n",
      "Current benign train loss: 0.7852388620376587\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.7890625\n",
      "Current benign train loss: 0.6405286192893982\n",
      "\n",
      "Total benign train accuarcy: 76.628\n",
      "Total benign train loss: 785.2129926681519\n",
      "\n",
      "[ Test epoch: 6 ]\n",
      "\n",
      "Test accuarcy: 76.25\n",
      "Test average loss: 0.006788291037082672\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 7 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.828125\n",
      "Current benign train loss: 0.531144917011261\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.734375\n",
      "Current benign train loss: 0.7468425631523132\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.8203125\n",
      "Current benign train loss: 0.5285263657569885\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.71875\n",
      "Current benign train loss: 0.7393592596054077\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.6796875\n",
      "Current benign train loss: 0.8164301514625549\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.796875\n",
      "Current benign train loss: 0.5576440095901489\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.8046875\n",
      "Current benign train loss: 0.5202133059501648\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.6953125\n",
      "Current benign train loss: 0.780495285987854\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.7578125\n",
      "Current benign train loss: 0.6166166067123413\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.7421875\n",
      "Current benign train loss: 0.7730388045310974\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.7578125\n",
      "Current benign train loss: 0.6384788155555725\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.734375\n",
      "Current benign train loss: 0.7237988114356995\n",
      "\n",
      "Total benign train accuarcy: 77.92866666666667\n",
      "Total benign train loss: 736.952542424202\n",
      "\n",
      "[ Test epoch: 7 ]\n",
      "\n",
      "Test accuarcy: 73.41\n",
      "Test average loss: 0.008085767892003059\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 8 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.828125\n",
      "Current benign train loss: 0.49985527992248535\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.796875\n",
      "Current benign train loss: 0.5238713622093201\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.7578125\n",
      "Current benign train loss: 0.6530877947807312\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.8203125\n",
      "Current benign train loss: 0.5144347548484802\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.828125\n",
      "Current benign train loss: 0.5491415858268738\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.7890625\n",
      "Current benign train loss: 0.6224198341369629\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.8046875\n",
      "Current benign train loss: 0.5469896793365479\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.8515625\n",
      "Current benign train loss: 0.4274197518825531\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.8046875\n",
      "Current benign train loss: 0.6365578770637512\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.7578125\n",
      "Current benign train loss: 0.6772919297218323\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.7421875\n",
      "Current benign train loss: 0.6119689345359802\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.8203125\n",
      "Current benign train loss: 0.5667774081230164\n",
      "\n",
      "Total benign train accuarcy: 79.25733333333334\n",
      "Total benign train loss: 698.4265536367893\n",
      "\n",
      "[ Test epoch: 8 ]\n",
      "\n",
      "Test accuarcy: 76.57\n",
      "Test average loss: 0.007233615559339523\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 9 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.859375\n",
      "Current benign train loss: 0.44013711810112\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.859375\n",
      "Current benign train loss: 0.4601595103740692\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.7890625\n",
      "Current benign train loss: 0.7140598893165588\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.828125\n",
      "Current benign train loss: 0.47754576802253723\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.7734375\n",
      "Current benign train loss: 0.5514519810676575\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.796875\n",
      "Current benign train loss: 0.5618171691894531\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.8125\n",
      "Current benign train loss: 0.5012879371643066\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.8203125\n",
      "Current benign train loss: 0.6298786997795105\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.7578125\n",
      "Current benign train loss: 0.6482946872711182\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.78125\n",
      "Current benign train loss: 0.6443367600440979\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.7578125\n",
      "Current benign train loss: 0.7361018657684326\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.796875\n",
      "Current benign train loss: 0.5202492475509644\n",
      "\n",
      "Total benign train accuarcy: 80.05133333333333\n",
      "Total benign train loss: 669.7765288352966\n",
      "\n",
      "[ Test epoch: 9 ]\n",
      "\n",
      "Test accuarcy: 77.32\n",
      "Test average loss: 0.0066544671505689625\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 10 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.8359375\n",
      "Current benign train loss: 0.551658034324646\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.8125\n",
      "Current benign train loss: 0.5683212280273438\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.8125\n",
      "Current benign train loss: 0.553564190864563\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.859375\n",
      "Current benign train loss: 0.48819616436958313\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.765625\n",
      "Current benign train loss: 0.6162578463554382\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.796875\n",
      "Current benign train loss: 0.6243976354598999\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.8203125\n",
      "Current benign train loss: 0.579912006855011\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.6953125\n",
      "Current benign train loss: 0.8571527600288391\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.78125\n",
      "Current benign train loss: 0.5822855234146118\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.8203125\n",
      "Current benign train loss: 0.6613157391548157\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.828125\n",
      "Current benign train loss: 0.49889805912971497\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.78125\n",
      "Current benign train loss: 0.6122298240661621\n",
      "\n",
      "Total benign train accuarcy: 80.71133333333333\n",
      "Total benign train loss: 646.2495446503162\n",
      "\n",
      "[ Test epoch: 10 ]\n",
      "\n",
      "Test accuarcy: 76.6\n",
      "Test average loss: 0.006985768112540245\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 11 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.84375\n",
      "Current benign train loss: 0.5134121179580688\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.875\n",
      "Current benign train loss: 0.39210760593414307\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.84375\n",
      "Current benign train loss: 0.4364628791809082\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.8515625\n",
      "Current benign train loss: 0.524480402469635\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.78125\n",
      "Current benign train loss: 0.5998474359512329\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.796875\n",
      "Current benign train loss: 0.5962750315666199\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.828125\n",
      "Current benign train loss: 0.5066303610801697\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.7734375\n",
      "Current benign train loss: 0.6285082101821899\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.8125\n",
      "Current benign train loss: 0.5747647285461426\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.8203125\n",
      "Current benign train loss: 0.5306189656257629\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.7890625\n",
      "Current benign train loss: 0.5854914784431458\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.8046875\n",
      "Current benign train loss: 0.47823429107666016\n",
      "\n",
      "Total benign train accuarcy: 81.38666666666667\n",
      "Total benign train loss: 626.8928970694542\n",
      "\n",
      "[ Test epoch: 11 ]\n",
      "\n",
      "Test accuarcy: 78.11\n",
      "Test average loss: 0.0066608458191156385\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 12 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.796875\n",
      "Current benign train loss: 0.548043966293335\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.828125\n",
      "Current benign train loss: 0.47892051935195923\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.8671875\n",
      "Current benign train loss: 0.3818892538547516\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.84375\n",
      "Current benign train loss: 0.5199018120765686\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.8125\n",
      "Current benign train loss: 0.5232324600219727\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.78125\n",
      "Current benign train loss: 0.6184989809989929\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.859375\n",
      "Current benign train loss: 0.38736334443092346\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.8828125\n",
      "Current benign train loss: 0.3961367607116699\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.8125\n",
      "Current benign train loss: 0.4863039553165436\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.828125\n",
      "Current benign train loss: 0.37727445363998413\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.75\n",
      "Current benign train loss: 0.687015175819397\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.828125\n",
      "Current benign train loss: 0.5742582678794861\n",
      "\n",
      "Total benign train accuarcy: 81.98866666666666\n",
      "Total benign train loss: 605.879703938961\n",
      "\n",
      "[ Test epoch: 12 ]\n",
      "\n",
      "Test accuarcy: 80.44\n",
      "Test average loss: 0.00572683697938919\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 13 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.8125\n",
      "Current benign train loss: 0.407774418592453\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.765625\n",
      "Current benign train loss: 0.5680326819419861\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.8203125\n",
      "Current benign train loss: 0.5727940201759338\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.875\n",
      "Current benign train loss: 0.4656691551208496\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.84375\n",
      "Current benign train loss: 0.44301143288612366\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.7890625\n",
      "Current benign train loss: 0.5748016834259033\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.8359375\n",
      "Current benign train loss: 0.48854464292526245\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.8203125\n",
      "Current benign train loss: 0.4442848265171051\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.84375\n",
      "Current benign train loss: 0.4602507948875427\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.828125\n",
      "Current benign train loss: 0.4884476363658905\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.8515625\n",
      "Current benign train loss: 0.4255169928073883\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.8515625\n",
      "Current benign train loss: 0.48084622621536255\n",
      "\n",
      "Total benign train accuarcy: 82.272\n",
      "Total benign train loss: 590.5208613574505\n",
      "\n",
      "[ Test epoch: 13 ]\n",
      "\n",
      "Test accuarcy: 77.52\n",
      "Test average loss: 0.006830611434578896\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 14 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.8203125\n",
      "Current benign train loss: 0.5273371338844299\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.8359375\n",
      "Current benign train loss: 0.4661428928375244\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.8203125\n",
      "Current benign train loss: 0.4408271014690399\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.875\n",
      "Current benign train loss: 0.3205682635307312\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.84375\n",
      "Current benign train loss: 0.46449440717697144\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.8125\n",
      "Current benign train loss: 0.572850227355957\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.8046875\n",
      "Current benign train loss: 0.5879359841346741\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.7890625\n",
      "Current benign train loss: 0.5676873922348022\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.8671875\n",
      "Current benign train loss: 0.39942580461502075\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.8671875\n",
      "Current benign train loss: 0.3489028215408325\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.828125\n",
      "Current benign train loss: 0.46538877487182617\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.828125\n",
      "Current benign train loss: 0.5292356014251709\n",
      "\n",
      "Total benign train accuarcy: 82.82933333333334\n",
      "Total benign train loss: 577.3153903782368\n",
      "\n",
      "[ Test epoch: 14 ]\n",
      "\n",
      "Test accuarcy: 75.79\n",
      "Test average loss: 0.007166984465718269\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 15 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.8828125\n",
      "Current benign train loss: 0.356243759393692\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.84375\n",
      "Current benign train loss: 0.3882385194301605\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.8515625\n",
      "Current benign train loss: 0.43634384870529175\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.8203125\n",
      "Current benign train loss: 0.4887143671512604\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.875\n",
      "Current benign train loss: 0.3814657926559448\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.8359375\n",
      "Current benign train loss: 0.4919235110282898\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.828125\n",
      "Current benign train loss: 0.48355287313461304\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.828125\n",
      "Current benign train loss: 0.48670950531959534\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.7734375\n",
      "Current benign train loss: 0.6005897521972656\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.8671875\n",
      "Current benign train loss: 0.5293622612953186\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.8125\n",
      "Current benign train loss: 0.5100817680358887\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.8359375\n",
      "Current benign train loss: 0.429181307554245\n",
      "\n",
      "Total benign train accuarcy: 83.238\n",
      "Total benign train loss: 564.765691101551\n",
      "\n",
      "[ Test epoch: 15 ]\n",
      "\n",
      "Test accuarcy: 74.05\n",
      "Test average loss: 0.007874052128195762\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 16 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.828125\n",
      "Current benign train loss: 0.45903393626213074\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.8125\n",
      "Current benign train loss: 0.5059541463851929\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.8125\n",
      "Current benign train loss: 0.5670946836471558\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.8984375\n",
      "Current benign train loss: 0.3405824601650238\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.84375\n",
      "Current benign train loss: 0.479983389377594\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.875\n",
      "Current benign train loss: 0.3705001175403595\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.8671875\n",
      "Current benign train loss: 0.4112822413444519\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.8515625\n",
      "Current benign train loss: 0.5025947690010071\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.8046875\n",
      "Current benign train loss: 0.5869329571723938\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.828125\n",
      "Current benign train loss: 0.4577471613883972\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.84375\n",
      "Current benign train loss: 0.3905344307422638\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.859375\n",
      "Current benign train loss: 0.41491520404815674\n",
      "\n",
      "Total benign train accuarcy: 83.60733333333333\n",
      "Total benign train loss: 552.7982414066792\n",
      "\n",
      "[ Test epoch: 16 ]\n",
      "\n",
      "Test accuarcy: 79.04\n",
      "Test average loss: 0.006292220404744148\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 17 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.8828125\n",
      "Current benign train loss: 0.37384748458862305\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.84375\n",
      "Current benign train loss: 0.4599554240703583\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.8671875\n",
      "Current benign train loss: 0.4381565749645233\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.8515625\n",
      "Current benign train loss: 0.42819368839263916\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.828125\n",
      "Current benign train loss: 0.4627860188484192\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.8359375\n",
      "Current benign train loss: 0.4077782928943634\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.84375\n",
      "Current benign train loss: 0.39915892481803894\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.8984375\n",
      "Current benign train loss: 0.3561989963054657\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.8984375\n",
      "Current benign train loss: 0.30049270391464233\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.8359375\n",
      "Current benign train loss: 0.4306577742099762\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.84375\n",
      "Current benign train loss: 0.48685041069984436\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.8359375\n",
      "Current benign train loss: 0.44120705127716064\n",
      "\n",
      "Total benign train accuarcy: 83.84733333333334\n",
      "Total benign train loss: 541.6193848252296\n",
      "\n",
      "[ Test epoch: 17 ]\n",
      "\n",
      "Test accuarcy: 80.64\n",
      "Test average loss: 0.005866609290242195\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 18 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.859375\n",
      "Current benign train loss: 0.3906862735748291\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.84375\n",
      "Current benign train loss: 0.4450410008430481\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.875\n",
      "Current benign train loss: 0.3410782814025879\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.890625\n",
      "Current benign train loss: 0.32543811202049255\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.8359375\n",
      "Current benign train loss: 0.43317273259162903\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.84375\n",
      "Current benign train loss: 0.44876036047935486\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.8203125\n",
      "Current benign train loss: 0.46873965859413147\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.8125\n",
      "Current benign train loss: 0.4818025827407837\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.84375\n",
      "Current benign train loss: 0.5517204999923706\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.8359375\n",
      "Current benign train loss: 0.4530816078186035\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.796875\n",
      "Current benign train loss: 0.6159330010414124\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.8359375\n",
      "Current benign train loss: 0.37133166193962097\n",
      "\n",
      "Total benign train accuarcy: 84.07133333333333\n",
      "Total benign train loss: 535.0650811195374\n",
      "\n",
      "[ Test epoch: 18 ]\n",
      "\n",
      "Test accuarcy: 78.69\n",
      "Test average loss: 0.006649470868706703\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 19 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.828125\n",
      "Current benign train loss: 0.44839245080947876\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.890625\n",
      "Current benign train loss: 0.38882607221603394\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.7890625\n",
      "Current benign train loss: 0.5719242691993713\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.796875\n",
      "Current benign train loss: 0.6044395565986633\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.828125\n",
      "Current benign train loss: 0.45633432269096375\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.8359375\n",
      "Current benign train loss: 0.4999631643295288\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.8125\n",
      "Current benign train loss: 0.580940842628479\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.8515625\n",
      "Current benign train loss: 0.3931806981563568\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.859375\n",
      "Current benign train loss: 0.3176049590110779\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.8671875\n",
      "Current benign train loss: 0.3973577618598938\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.9140625\n",
      "Current benign train loss: 0.2518762946128845\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.828125\n",
      "Current benign train loss: 0.39085736870765686\n",
      "\n",
      "Total benign train accuarcy: 84.43533333333333\n",
      "Total benign train loss: 522.9587257951498\n",
      "\n",
      "[ Test epoch: 19 ]\n",
      "\n",
      "Test accuarcy: 80.82\n",
      "Test average loss: 0.005704171770811081\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 20 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.8828125\n",
      "Current benign train loss: 0.454781711101532\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.8046875\n",
      "Current benign train loss: 0.5657206177711487\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.828125\n",
      "Current benign train loss: 0.5380629897117615\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.890625\n",
      "Current benign train loss: 0.343507319688797\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.828125\n",
      "Current benign train loss: 0.45556584000587463\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.8828125\n",
      "Current benign train loss: 0.3632441759109497\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.7578125\n",
      "Current benign train loss: 0.510019838809967\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.8828125\n",
      "Current benign train loss: 0.46040457487106323\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.859375\n",
      "Current benign train loss: 0.384310245513916\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.8046875\n",
      "Current benign train loss: 0.5751281380653381\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.875\n",
      "Current benign train loss: 0.4432810842990875\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.8359375\n",
      "Current benign train loss: 0.47380489110946655\n",
      "\n",
      "Total benign train accuarcy: 84.67\n",
      "Total benign train loss: 514.1666199713945\n",
      "\n",
      "[ Test epoch: 20 ]\n",
      "\n",
      "Test accuarcy: 73.7\n",
      "Test average loss: 0.008690788358449936\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 21 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.8828125\n",
      "Current benign train loss: 0.31779205799102783\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.8359375\n",
      "Current benign train loss: 0.48647910356521606\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.84375\n",
      "Current benign train loss: 0.3971056342124939\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.8125\n",
      "Current benign train loss: 0.41152793169021606\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.828125\n",
      "Current benign train loss: 0.5121608376502991\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.8671875\n",
      "Current benign train loss: 0.36514222621917725\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.8046875\n",
      "Current benign train loss: 0.5198761224746704\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.875\n",
      "Current benign train loss: 0.3510555028915405\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.796875\n",
      "Current benign train loss: 0.6213744282722473\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.84375\n",
      "Current benign train loss: 0.39854925870895386\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.8125\n",
      "Current benign train loss: 0.5495043396949768\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.8515625\n",
      "Current benign train loss: 0.3898921310901642\n",
      "\n",
      "Total benign train accuarcy: 84.922\n",
      "Total benign train loss: 508.3955843895674\n",
      "\n",
      "[ Test epoch: 21 ]\n",
      "\n",
      "Test accuarcy: 77.62\n",
      "Test average loss: 0.007120754006505013\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 22 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.8125\n",
      "Current benign train loss: 0.5052369236946106\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.8671875\n",
      "Current benign train loss: 0.3639814853668213\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.8359375\n",
      "Current benign train loss: 0.4946902394294739\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.8984375\n",
      "Current benign train loss: 0.3388276696205139\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.859375\n",
      "Current benign train loss: 0.4363941550254822\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.828125\n",
      "Current benign train loss: 0.4434502124786377\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.84375\n",
      "Current benign train loss: 0.44107353687286377\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.8515625\n",
      "Current benign train loss: 0.434380441904068\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.828125\n",
      "Current benign train loss: 0.5245715975761414\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.8828125\n",
      "Current benign train loss: 0.40436235070228577\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.828125\n",
      "Current benign train loss: 0.4976175129413605\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.828125\n",
      "Current benign train loss: 0.3915932774543762\n",
      "\n",
      "Total benign train accuarcy: 85.13\n",
      "Total benign train loss: 501.5493069291115\n",
      "\n",
      "[ Test epoch: 22 ]\n",
      "\n",
      "Test accuarcy: 76.6\n",
      "Test average loss: 0.007900142949819566\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 23 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.84375\n",
      "Current benign train loss: 0.5081860423088074\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.859375\n",
      "Current benign train loss: 0.3546198904514313\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.8515625\n",
      "Current benign train loss: 0.40123051404953003\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.8359375\n",
      "Current benign train loss: 0.41930800676345825\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.8359375\n",
      "Current benign train loss: 0.4325256645679474\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.8359375\n",
      "Current benign train loss: 0.4224538505077362\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.796875\n",
      "Current benign train loss: 0.46776872873306274\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.84375\n",
      "Current benign train loss: 0.441459596157074\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.8828125\n",
      "Current benign train loss: 0.42410680651664734\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.8203125\n",
      "Current benign train loss: 0.44701865315437317\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.8828125\n",
      "Current benign train loss: 0.35538947582244873\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.859375\n",
      "Current benign train loss: 0.3292767107486725\n",
      "\n",
      "Total benign train accuarcy: 85.25866666666667\n",
      "Total benign train loss: 496.62660621106625\n",
      "\n",
      "[ Test epoch: 23 ]\n",
      "\n",
      "Test accuarcy: 77.98\n",
      "Test average loss: 0.006887898141145706\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 24 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.84375\n",
      "Current benign train loss: 0.450187623500824\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.8671875\n",
      "Current benign train loss: 0.3703157305717468\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.8515625\n",
      "Current benign train loss: 0.4110391438007355\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.8671875\n",
      "Current benign train loss: 0.44316643476486206\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.7890625\n",
      "Current benign train loss: 0.5411603450775146\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.8828125\n",
      "Current benign train loss: 0.3559021055698395\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.84375\n",
      "Current benign train loss: 0.45386597514152527\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.8046875\n",
      "Current benign train loss: 0.5037149786949158\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.84375\n",
      "Current benign train loss: 0.4255986213684082\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.8984375\n",
      "Current benign train loss: 0.3380070626735687\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.859375\n",
      "Current benign train loss: 0.43297019600868225\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.875\n",
      "Current benign train loss: 0.45315495133399963\n",
      "\n",
      "Total benign train accuarcy: 85.454\n",
      "Total benign train loss: 491.08680403232574\n",
      "\n",
      "[ Test epoch: 24 ]\n",
      "\n",
      "Test accuarcy: 72.88\n",
      "Test average loss: 0.009504579237103463\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 25 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.84375\n",
      "Current benign train loss: 0.3366556465625763\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.859375\n",
      "Current benign train loss: 0.4264882802963257\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.84375\n",
      "Current benign train loss: 0.43403804302215576\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.90625\n",
      "Current benign train loss: 0.3235566020011902\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.875\n",
      "Current benign train loss: 0.34330958127975464\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.8828125\n",
      "Current benign train loss: 0.31678304076194763\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.8515625\n",
      "Current benign train loss: 0.3766261637210846\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.84375\n",
      "Current benign train loss: 0.39909157156944275\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.8359375\n",
      "Current benign train loss: 0.46605753898620605\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.8671875\n",
      "Current benign train loss: 0.360481858253479\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.8828125\n",
      "Current benign train loss: 0.36500465869903564\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.8515625\n",
      "Current benign train loss: 0.3628775179386139\n",
      "\n",
      "Total benign train accuarcy: 85.55266666666667\n",
      "Total benign train loss: 485.18371476233006\n",
      "\n",
      "[ Test epoch: 25 ]\n",
      "\n",
      "Test accuarcy: 75.0\n",
      "Test average loss: 0.008604239940643311\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 26 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.8828125\n",
      "Current benign train loss: 0.3984832465648651\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.8359375\n",
      "Current benign train loss: 0.4823698401451111\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.8515625\n",
      "Current benign train loss: 0.35188165307044983\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.8671875\n",
      "Current benign train loss: 0.39497196674346924\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.875\n",
      "Current benign train loss: 0.4871085286140442\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.84375\n",
      "Current benign train loss: 0.48559096455574036\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.859375\n",
      "Current benign train loss: 0.44947218894958496\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.859375\n",
      "Current benign train loss: 0.40361717343330383\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.875\n",
      "Current benign train loss: 0.3740854561328888\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.828125\n",
      "Current benign train loss: 0.41936829686164856\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.828125\n",
      "Current benign train loss: 0.49748146533966064\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.828125\n",
      "Current benign train loss: 0.42682141065597534\n",
      "\n",
      "Total benign train accuarcy: 85.76666666666667\n",
      "Total benign train loss: 479.2009659409523\n",
      "\n",
      "[ Test epoch: 26 ]\n",
      "\n",
      "Test accuarcy: 79.74\n",
      "Test average loss: 0.00617596446275711\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 27 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.90625\n",
      "Current benign train loss: 0.3129846155643463\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.8828125\n",
      "Current benign train loss: 0.3376758098602295\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.90625\n",
      "Current benign train loss: 0.29918372631073\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.796875\n",
      "Current benign train loss: 0.46134328842163086\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.875\n",
      "Current benign train loss: 0.44714677333831787\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.8515625\n",
      "Current benign train loss: 0.38744863867759705\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.859375\n",
      "Current benign train loss: 0.312452107667923\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.8359375\n",
      "Current benign train loss: 0.5069929957389832\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.8125\n",
      "Current benign train loss: 0.4776514172554016\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.8203125\n",
      "Current benign train loss: 0.46054455637931824\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.875\n",
      "Current benign train loss: 0.43061363697052\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.90625\n",
      "Current benign train loss: 0.3353019654750824\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total benign train accuarcy: 85.76866666666666\n",
      "Total benign train loss: 477.8801783025265\n",
      "\n",
      "[ Test epoch: 27 ]\n",
      "\n",
      "Test accuarcy: 76.64\n",
      "Test average loss: 0.008124266678094863\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 28 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.8828125\n",
      "Current benign train loss: 0.29496464133262634\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.8671875\n",
      "Current benign train loss: 0.3703308701515198\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.8125\n",
      "Current benign train loss: 0.5045804977416992\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.8671875\n",
      "Current benign train loss: 0.3856733441352844\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.796875\n",
      "Current benign train loss: 0.5784821510314941\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.8671875\n",
      "Current benign train loss: 0.3375500440597534\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.84375\n",
      "Current benign train loss: 0.4123561680316925\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.7734375\n",
      "Current benign train loss: 0.6129114031791687\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.8671875\n",
      "Current benign train loss: 0.38736775517463684\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.8671875\n",
      "Current benign train loss: 0.48859724402427673\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.875\n",
      "Current benign train loss: 0.3711589574813843\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.8515625\n",
      "Current benign train loss: 0.3914404809474945\n",
      "\n",
      "Total benign train accuarcy: 86.12533333333333\n",
      "Total benign train loss: 470.22251322865486\n",
      "\n",
      "[ Test epoch: 28 ]\n",
      "\n",
      "Test accuarcy: 78.97\n",
      "Test average loss: 0.006524395549297333\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 29 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.8515625\n",
      "Current benign train loss: 0.4317469894886017\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.8671875\n",
      "Current benign train loss: 0.35897624492645264\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.921875\n",
      "Current benign train loss: 0.27988436818122864\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.84375\n",
      "Current benign train loss: 0.4891063868999481\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.875\n",
      "Current benign train loss: 0.33269721269607544\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.84375\n",
      "Current benign train loss: 0.48014765977859497\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.8203125\n",
      "Current benign train loss: 0.4499228596687317\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.8984375\n",
      "Current benign train loss: 0.36088529229164124\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.8984375\n",
      "Current benign train loss: 0.30829697847366333\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.8359375\n",
      "Current benign train loss: 0.40422582626342773\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.828125\n",
      "Current benign train loss: 0.47683003544807434\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.84375\n",
      "Current benign train loss: 0.40248098969459534\n",
      "\n",
      "Total benign train accuarcy: 86.06533333333333\n",
      "Total benign train loss: 469.7429503053427\n",
      "\n",
      "[ Test epoch: 29 ]\n",
      "\n",
      "Test accuarcy: 77.12\n",
      "Test average loss: 0.00784708442389965\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 30 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.859375\n",
      "Current benign train loss: 0.3878544569015503\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.8984375\n",
      "Current benign train loss: 0.3166930079460144\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.84375\n",
      "Current benign train loss: 0.4224625527858734\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.875\n",
      "Current benign train loss: 0.34188681840896606\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.8359375\n",
      "Current benign train loss: 0.41717329621315\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.84375\n",
      "Current benign train loss: 0.47266751527786255\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.7734375\n",
      "Current benign train loss: 0.5711865425109863\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.8515625\n",
      "Current benign train loss: 0.34622761607170105\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.8984375\n",
      "Current benign train loss: 0.34578800201416016\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.8828125\n",
      "Current benign train loss: 0.42260515689849854\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.828125\n",
      "Current benign train loss: 0.4666476547718048\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.875\n",
      "Current benign train loss: 0.36380887031555176\n",
      "\n",
      "Total benign train accuarcy: 86.39133333333334\n",
      "Total benign train loss: 461.04561308026314\n",
      "\n",
      "[ Test epoch: 30 ]\n",
      "\n",
      "Test accuarcy: 78.52\n",
      "Test average loss: 0.007046003445982933\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 31 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.859375\n",
      "Current benign train loss: 0.3203318417072296\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.8671875\n",
      "Current benign train loss: 0.311989963054657\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.8671875\n",
      "Current benign train loss: 0.3363530933856964\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.8046875\n",
      "Current benign train loss: 0.5071244239807129\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.8984375\n",
      "Current benign train loss: 0.3327329158782959\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.8984375\n",
      "Current benign train loss: 0.31166189908981323\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.8671875\n",
      "Current benign train loss: 0.39074087142944336\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.921875\n",
      "Current benign train loss: 0.2480078935623169\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.8515625\n",
      "Current benign train loss: 0.38765749335289\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.828125\n",
      "Current benign train loss: 0.4300251603126526\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.859375\n",
      "Current benign train loss: 0.36312660574913025\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.8046875\n",
      "Current benign train loss: 0.5681434273719788\n",
      "\n",
      "Total benign train accuarcy: 86.31466666666667\n",
      "Total benign train loss: 460.96305456757545\n",
      "\n",
      "[ Test epoch: 31 ]\n",
      "\n",
      "Test accuarcy: 80.66\n",
      "Test average loss: 0.005892441564798355\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 32 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.8515625\n",
      "Current benign train loss: 0.41386890411376953\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.8828125\n",
      "Current benign train loss: 0.34376856684684753\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.84375\n",
      "Current benign train loss: 0.4025995433330536\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.890625\n",
      "Current benign train loss: 0.41449859738349915\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.8828125\n",
      "Current benign train loss: 0.2949505150318146\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.8671875\n",
      "Current benign train loss: 0.3505624234676361\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.90625\n",
      "Current benign train loss: 0.30260998010635376\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.828125\n",
      "Current benign train loss: 0.4622569680213928\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.8671875\n",
      "Current benign train loss: 0.3860906958580017\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.8203125\n",
      "Current benign train loss: 0.4819473922252655\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.8671875\n",
      "Current benign train loss: 0.398944616317749\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.859375\n",
      "Current benign train loss: 0.373861700296402\n",
      "\n",
      "Total benign train accuarcy: 86.28866666666667\n",
      "Total benign train loss: 461.3209643214941\n",
      "\n",
      "[ Test epoch: 32 ]\n",
      "\n",
      "Test accuarcy: 78.97\n",
      "Test average loss: 0.006867381021380425\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 33 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.8515625\n",
      "Current benign train loss: 0.37561318278312683\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.921875\n",
      "Current benign train loss: 0.23339079320430756\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.8359375\n",
      "Current benign train loss: 0.4212368130683899\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.875\n",
      "Current benign train loss: 0.2997492253780365\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.8828125\n",
      "Current benign train loss: 0.3808010220527649\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.859375\n",
      "Current benign train loss: 0.45483988523483276\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.890625\n",
      "Current benign train loss: 0.33037278056144714\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.90625\n",
      "Current benign train loss: 0.259838342666626\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.828125\n",
      "Current benign train loss: 0.36385872960090637\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.875\n",
      "Current benign train loss: 0.35660606622695923\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.8359375\n",
      "Current benign train loss: 0.3766535818576813\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.8515625\n",
      "Current benign train loss: 0.38090357184410095\n",
      "\n",
      "Total benign train accuarcy: 86.47066666666667\n",
      "Total benign train loss: 454.2083647251129\n",
      "\n",
      "[ Test epoch: 33 ]\n",
      "\n",
      "Test accuarcy: 73.92\n",
      "Test average loss: 0.008453687474131584\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 34 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9296875\n",
      "Current benign train loss: 0.22694317996501923\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.8984375\n",
      "Current benign train loss: 0.3702508211135864\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.859375\n",
      "Current benign train loss: 0.4474676251411438\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.859375\n",
      "Current benign train loss: 0.3328193128108978\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.8515625\n",
      "Current benign train loss: 0.41379842162132263\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.90625\n",
      "Current benign train loss: 0.3073485195636749\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.8984375\n",
      "Current benign train loss: 0.35222628712654114\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.890625\n",
      "Current benign train loss: 0.3420345187187195\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.8828125\n",
      "Current benign train loss: 0.3531038165092468\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.90625\n",
      "Current benign train loss: 0.2701188921928406\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.8515625\n",
      "Current benign train loss: 0.41626694798469543\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.84375\n",
      "Current benign train loss: 0.39701730012893677\n",
      "\n",
      "Total benign train accuarcy: 86.67666666666666\n",
      "Total benign train loss: 449.51778899133205\n",
      "\n",
      "[ Test epoch: 34 ]\n",
      "\n",
      "Test accuarcy: 61.87\n",
      "Test average loss: 0.013810488510131835\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 35 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.8203125\n",
      "Current benign train loss: 0.5244795680046082\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.8984375\n",
      "Current benign train loss: 0.35729679465293884\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.859375\n",
      "Current benign train loss: 0.3777071237564087\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.8671875\n",
      "Current benign train loss: 0.34924712777137756\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.8671875\n",
      "Current benign train loss: 0.39121103286743164\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.859375\n",
      "Current benign train loss: 0.4381900429725647\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.8515625\n",
      "Current benign train loss: 0.3653823733329773\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.8203125\n",
      "Current benign train loss: 0.5016635060310364\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.828125\n",
      "Current benign train loss: 0.5313377976417542\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.8359375\n",
      "Current benign train loss: 0.40202900767326355\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.859375\n",
      "Current benign train loss: 0.396912544965744\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.8359375\n",
      "Current benign train loss: 0.4343480169773102\n",
      "\n",
      "Total benign train accuarcy: 86.69733333333333\n",
      "Total benign train loss: 451.7905120998621\n",
      "\n",
      "[ Test epoch: 35 ]\n",
      "\n",
      "Test accuarcy: 75.27\n",
      "Test average loss: 0.00887442244887352\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 36 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9140625\n",
      "Current benign train loss: 0.23726344108581543\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.8984375\n",
      "Current benign train loss: 0.33280375599861145\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.8984375\n",
      "Current benign train loss: 0.3235638439655304\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.8984375\n",
      "Current benign train loss: 0.31537163257598877\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.90625\n",
      "Current benign train loss: 0.2997075915336609\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.875\n",
      "Current benign train loss: 0.38427138328552246\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.875\n",
      "Current benign train loss: 0.3833276629447937\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.8828125\n",
      "Current benign train loss: 0.3095298707485199\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.875\n",
      "Current benign train loss: 0.36254116892814636\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.875\n",
      "Current benign train loss: 0.4224865138530731\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.8515625\n",
      "Current benign train loss: 0.4877677857875824\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.8828125\n",
      "Current benign train loss: 0.3151877522468567\n",
      "\n",
      "Total benign train accuarcy: 86.96533333333333\n",
      "Total benign train loss: 442.22285011410713\n",
      "\n",
      "[ Test epoch: 36 ]\n",
      "\n",
      "Test accuarcy: 73.84\n",
      "Test average loss: 0.009138365960121155\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 37 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.8984375\n",
      "Current benign train loss: 0.29602062702178955\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.8671875\n",
      "Current benign train loss: 0.40813741087913513\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.890625\n",
      "Current benign train loss: 0.3833672106266022\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.8359375\n",
      "Current benign train loss: 0.43720898032188416\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.875\n",
      "Current benign train loss: 0.3472237288951874\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.859375\n",
      "Current benign train loss: 0.3522934913635254\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.8359375\n",
      "Current benign train loss: 0.3569544851779938\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.921875\n",
      "Current benign train loss: 0.2670173943042755\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.8828125\n",
      "Current benign train loss: 0.34885382652282715\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.8359375\n",
      "Current benign train loss: 0.3929045498371124\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.890625\n",
      "Current benign train loss: 0.3344513773918152\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.859375\n",
      "Current benign train loss: 0.356339693069458\n",
      "\n",
      "Total benign train accuarcy: 86.85333333333334\n",
      "Total benign train loss: 442.4241201877594\n",
      "\n",
      "[ Test epoch: 37 ]\n",
      "\n",
      "Test accuarcy: 69.08\n",
      "Test average loss: 0.011424888223409653\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 38 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.8203125\n",
      "Current benign train loss: 0.5295017957687378\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.8671875\n",
      "Current benign train loss: 0.3922862410545349\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.8671875\n",
      "Current benign train loss: 0.38193002343177795\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.8359375\n",
      "Current benign train loss: 0.4244016408920288\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.26499322056770325\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.796875\n",
      "Current benign train loss: 0.4790255129337311\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.828125\n",
      "Current benign train loss: 0.43277254700660706\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.9140625\n",
      "Current benign train loss: 0.2989487051963806\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.875\n",
      "Current benign train loss: 0.314821720123291\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.8671875\n",
      "Current benign train loss: 0.32882311940193176\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.8203125\n",
      "Current benign train loss: 0.4574154019355774\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.8203125\n",
      "Current benign train loss: 0.5418790578842163\n",
      "\n",
      "Total benign train accuarcy: 86.91266666666667\n",
      "Total benign train loss: 442.99536930024624\n",
      "\n",
      "[ Test epoch: 38 ]\n",
      "\n",
      "Test accuarcy: 77.19\n",
      "Test average loss: 0.007578500071167946\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 39 ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.8984375\n",
      "Current benign train loss: 0.28446146845817566\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.84375\n",
      "Current benign train loss: 0.5032810568809509\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.8828125\n",
      "Current benign train loss: 0.37579402327537537\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.875\n",
      "Current benign train loss: 0.34282389283180237\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9296875\n",
      "Current benign train loss: 0.24695658683776855\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.84375\n",
      "Current benign train loss: 0.3732047379016876\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.8671875\n",
      "Current benign train loss: 0.3946641981601715\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.8828125\n",
      "Current benign train loss: 0.2961675226688385\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.8515625\n",
      "Current benign train loss: 0.3825491964817047\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.8671875\n",
      "Current benign train loss: 0.3391593396663666\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.921875\n",
      "Current benign train loss: 0.22718630731105804\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.890625\n",
      "Current benign train loss: 0.24117101728916168\n",
      "\n",
      "Total benign train accuarcy: 86.91733333333333\n",
      "Total benign train loss: 439.4403594583273\n",
      "\n",
      "[ Test epoch: 39 ]\n",
      "\n",
      "Test accuarcy: 72.88\n",
      "Test average loss: 0.010147725987434388\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 40 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.875\n",
      "Current benign train loss: 0.38136589527130127\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.90625\n",
      "Current benign train loss: 0.24759075045585632\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.890625\n",
      "Current benign train loss: 0.34875184297561646\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.8984375\n",
      "Current benign train loss: 0.2928932309150696\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.8125\n",
      "Current benign train loss: 0.44617223739624023\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9296875\n",
      "Current benign train loss: 0.2945525050163269\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.8046875\n",
      "Current benign train loss: 0.47234633564949036\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.875\n",
      "Current benign train loss: 0.34338900446891785\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.8984375\n",
      "Current benign train loss: 0.3818857669830322\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.875\n",
      "Current benign train loss: 0.3252984285354614\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.8984375\n",
      "Current benign train loss: 0.39173224568367004\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.828125\n",
      "Current benign train loss: 0.5296895503997803\n",
      "\n",
      "Total benign train accuarcy: 87.03733333333334\n",
      "Total benign train loss: 439.39044873416424\n",
      "\n",
      "[ Test epoch: 40 ]\n",
      "\n",
      "Test accuarcy: 78.46\n",
      "Test average loss: 0.007058680415153503\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 41 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.8828125\n",
      "Current benign train loss: 0.4554424583911896\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.8515625\n",
      "Current benign train loss: 0.368486613035202\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.8671875\n",
      "Current benign train loss: 0.39000290632247925\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.875\n",
      "Current benign train loss: 0.3725825548171997\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.890625\n",
      "Current benign train loss: 0.30941084027290344\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.8984375\n",
      "Current benign train loss: 0.27300897240638733\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.859375\n",
      "Current benign train loss: 0.39482012391090393\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.875\n",
      "Current benign train loss: 0.39933663606643677\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.8671875\n",
      "Current benign train loss: 0.3732733428478241\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.8359375\n",
      "Current benign train loss: 0.51663738489151\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.875\n",
      "Current benign train loss: 0.37015026807785034\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.890625\n",
      "Current benign train loss: 0.3293617367744446\n",
      "\n",
      "Total benign train accuarcy: 87.012\n",
      "Total benign train loss: 439.23580427467823\n",
      "\n",
      "[ Test epoch: 41 ]\n",
      "\n",
      "Test accuarcy: 78.78\n",
      "Test average loss: 0.006528411918878555\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 42 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9296875\n",
      "Current benign train loss: 0.21951468288898468\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.8984375\n",
      "Current benign train loss: 0.34438320994377136\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.84375\n",
      "Current benign train loss: 0.40000009536743164\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.8984375\n",
      "Current benign train loss: 0.31566911935806274\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.859375\n",
      "Current benign train loss: 0.36490118503570557\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9140625\n",
      "Current benign train loss: 0.31222814321517944\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.9140625\n",
      "Current benign train loss: 0.31035685539245605\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.7890625\n",
      "Current benign train loss: 0.5382439494132996\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.828125\n",
      "Current benign train loss: 0.466332346200943\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.8359375\n",
      "Current benign train loss: 0.4490169584751129\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.921875\n",
      "Current benign train loss: 0.2774806320667267\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.890625\n",
      "Current benign train loss: 0.42291730642318726\n",
      "\n",
      "Total benign train accuarcy: 87.11133333333333\n",
      "Total benign train loss: 433.9949617385864\n",
      "\n",
      "[ Test epoch: 42 ]\n",
      "\n",
      "Test accuarcy: 74.71\n",
      "Test average loss: 0.008171253883838653\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 43 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.8984375\n",
      "Current benign train loss: 0.2772960960865021\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.8515625\n",
      "Current benign train loss: 0.37247326970100403\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.8984375\n",
      "Current benign train loss: 0.30655306577682495\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.875\n",
      "Current benign train loss: 0.3108189105987549\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.828125\n",
      "Current benign train loss: 0.3775295317173004\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.84375\n",
      "Current benign train loss: 0.47043657302856445\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.8203125\n",
      "Current benign train loss: 0.4743778109550476\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.9296875\n",
      "Current benign train loss: 0.24503719806671143\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.84375\n",
      "Current benign train loss: 0.39485815167427063\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.890625\n",
      "Current benign train loss: 0.31540820002555847\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.890625\n",
      "Current benign train loss: 0.36565759778022766\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.859375\n",
      "Current benign train loss: 0.375247061252594\n",
      "\n",
      "Total benign train accuarcy: 87.20066666666666\n",
      "Total benign train loss: 431.4009599983692\n",
      "\n",
      "[ Test epoch: 43 ]\n",
      "\n",
      "Test accuarcy: 80.62\n",
      "Test average loss: 0.0059841791972517966\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 44 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.890625\n",
      "Current benign train loss: 0.3157799243927002\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.8515625\n",
      "Current benign train loss: 0.45136237144470215\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.8828125\n",
      "Current benign train loss: 0.31060534715652466\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.8203125\n",
      "Current benign train loss: 0.3605283200740814\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.828125\n",
      "Current benign train loss: 0.5495588183403015\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.890625\n",
      "Current benign train loss: 0.3747667670249939\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.84375\n",
      "Current benign train loss: 0.4091745913028717\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.859375\n",
      "Current benign train loss: 0.349864661693573\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.859375\n",
      "Current benign train loss: 0.3457654118537903\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.9140625\n",
      "Current benign train loss: 0.2498358190059662\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.859375\n",
      "Current benign train loss: 0.42030051350593567\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.8359375\n",
      "Current benign train loss: 0.5178607702255249\n",
      "\n",
      "Total benign train accuarcy: 87.27266666666667\n",
      "Total benign train loss: 430.97933000326157\n",
      "\n",
      "[ Test epoch: 44 ]\n",
      "\n",
      "Test accuarcy: 66.62\n",
      "Test average loss: 0.012088133543729783\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 45 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.859375\n",
      "Current benign train loss: 0.33356672525405884\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.90625\n",
      "Current benign train loss: 0.2774644196033478\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.8515625\n",
      "Current benign train loss: 0.40832284092903137\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.8828125\n",
      "Current benign train loss: 0.3387358784675598\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9140625\n",
      "Current benign train loss: 0.2767474949359894\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.890625\n",
      "Current benign train loss: 0.2836327850818634\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.8671875\n",
      "Current benign train loss: 0.47358936071395874\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.875\n",
      "Current benign train loss: 0.3650608956813812\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.8828125\n",
      "Current benign train loss: 0.36322054266929626\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.8125\n",
      "Current benign train loss: 0.5014194250106812\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.8359375\n",
      "Current benign train loss: 0.388424277305603\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.9140625\n",
      "Current benign train loss: 0.34566885232925415\n",
      "\n",
      "Total benign train accuarcy: 87.28466666666667\n",
      "Total benign train loss: 429.56942062079906\n",
      "\n",
      "[ Test epoch: 45 ]\n",
      "\n",
      "Test accuarcy: 74.6\n",
      "Test average loss: 0.008593098485469818\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 46 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9140625\n",
      "Current benign train loss: 0.2132185697555542\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.90625\n",
      "Current benign train loss: 0.26968419551849365\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.8515625\n",
      "Current benign train loss: 0.3516407608985901\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.890625\n",
      "Current benign train loss: 0.3625597059726715\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.890625\n",
      "Current benign train loss: 0.2919304072856903\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.8671875\n",
      "Current benign train loss: 0.3734930157661438\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.890625\n",
      "Current benign train loss: 0.38040053844451904\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.890625\n",
      "Current benign train loss: 0.2943486273288727\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.859375\n",
      "Current benign train loss: 0.37281960248947144\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.84375\n",
      "Current benign train loss: 0.46624740958213806\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.8515625\n",
      "Current benign train loss: 0.3241877555847168\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.859375\n",
      "Current benign train loss: 0.40555134415626526\n",
      "\n",
      "Total benign train accuarcy: 87.43533333333333\n",
      "Total benign train loss: 424.36906795203686\n",
      "\n",
      "[ Test epoch: 46 ]\n",
      "\n",
      "Test accuarcy: 76.06\n",
      "Test average loss: 0.0073330422222614286\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 47 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.8515625\n",
      "Current benign train loss: 0.4370918869972229\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.8359375\n",
      "Current benign train loss: 0.4304048418998718\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.875\n",
      "Current benign train loss: 0.3818739652633667\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.875\n",
      "Current benign train loss: 0.35740387439727783\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.8828125\n",
      "Current benign train loss: 0.3071182072162628\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.90625\n",
      "Current benign train loss: 0.25584274530410767\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.890625\n",
      "Current benign train loss: 0.33867037296295166\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.8671875\n",
      "Current benign train loss: 0.3950269818305969\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.859375\n",
      "Current benign train loss: 0.353009432554245\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.8515625\n",
      "Current benign train loss: 0.4481453001499176\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.9140625\n",
      "Current benign train loss: 0.28281766176223755\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.8828125\n",
      "Current benign train loss: 0.3539144694805145\n",
      "\n",
      "Total benign train accuarcy: 87.51533333333333\n",
      "Total benign train loss: 423.0897762924433\n",
      "\n",
      "[ Test epoch: 47 ]\n",
      "\n",
      "Test accuarcy: 67.85\n",
      "Test average loss: 0.013839754700660706\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 48 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.8359375\n",
      "Current benign train loss: 0.4949689507484436\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.8984375\n",
      "Current benign train loss: 0.3077946603298187\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.859375\n",
      "Current benign train loss: 0.38058900833129883\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9140625\n",
      "Current benign train loss: 0.262563556432724\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.875\n",
      "Current benign train loss: 0.45889270305633545\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.890625\n",
      "Current benign train loss: 0.2672872841358185\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.8515625\n",
      "Current benign train loss: 0.39782145619392395\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.84375\n",
      "Current benign train loss: 0.4156990647315979\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.859375\n",
      "Current benign train loss: 0.40914371609687805\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.875\n",
      "Current benign train loss: 0.36570098996162415\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.90625\n",
      "Current benign train loss: 0.27378764748573303\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.8671875\n",
      "Current benign train loss: 0.3405791223049164\n",
      "\n",
      "Total benign train accuarcy: 87.404\n",
      "Total benign train loss: 425.75367215275764\n",
      "\n",
      "[ Test epoch: 48 ]\n",
      "\n",
      "Test accuarcy: 72.33\n",
      "Test average loss: 0.01096666002869606\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 49 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.90625\n",
      "Current benign train loss: 0.2507259249687195\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.8671875\n",
      "Current benign train loss: 0.32397592067718506\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9140625\n",
      "Current benign train loss: 0.24857878684997559\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.8671875\n",
      "Current benign train loss: 0.38572192192077637\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.8671875\n",
      "Current benign train loss: 0.3956242501735687\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.8515625\n",
      "Current benign train loss: 0.4489747881889343\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.875\n",
      "Current benign train loss: 0.3359069526195526\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.8828125\n",
      "Current benign train loss: 0.3344511389732361\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.84375\n",
      "Current benign train loss: 0.47626736760139465\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.8671875\n",
      "Current benign train loss: 0.36345958709716797\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.890625\n",
      "Current benign train loss: 0.34004324674606323\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.8984375\n",
      "Current benign train loss: 0.3423088490962982\n",
      "\n",
      "Total benign train accuarcy: 87.412\n",
      "Total benign train loss: 422.62136352062225\n",
      "\n",
      "[ Test epoch: 49 ]\n",
      "\n",
      "Test accuarcy: 79.35\n",
      "Test average loss: 0.0067768036127090455\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 50 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.8984375\n",
      "Current benign train loss: 0.37274616956710815\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.8984375\n",
      "Current benign train loss: 0.25275132060050964\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9140625\n",
      "Current benign train loss: 0.17934800684452057\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.1592686027288437\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.1895374059677124\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.90625\n",
      "Current benign train loss: 0.2806020677089691\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.18875397741794586\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.1760970950126648\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.17077511548995972\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.15804126858711243\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.921875\n",
      "Current benign train loss: 0.18797896802425385\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.12743932008743286\n",
      "\n",
      "Total benign train accuarcy: 93.97866666666667\n",
      "Total benign train loss: 215.11304675787687\n",
      "\n",
      "[ Test epoch: 50 ]\n",
      "\n",
      "Test accuarcy: 89.15\n",
      "Test average loss: 0.0034299311086535456\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 51 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.09924662113189697\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9296875\n",
      "Current benign train loss: 0.1507071554660797\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9296875\n",
      "Current benign train loss: 0.1705007702112198\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.08312483876943588\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.16163383424282074\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.192870631814003\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.10493229329586029\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.11490016430616379\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.11174910515546799\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.10297919064760208\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.09236124902963638\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.08979542553424835\n",
      "\n",
      "Total benign train accuarcy: 95.472\n",
      "Total benign train loss: 163.2438322380185\n",
      "\n",
      "[ Test epoch: 51 ]\n",
      "\n",
      "Test accuarcy: 88.99\n",
      "Test average loss: 0.0034751107513904572\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 52 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.14324024319648743\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.11376795172691345\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.08104170113801956\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.18476466834545135\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.10371339321136475\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.11078059673309326\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.124176986515522\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.921875\n",
      "Current benign train loss: 0.2351866215467453\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.15454980731010437\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.09229621291160583\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.04085911810398102\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.12512566149234772\n",
      "\n",
      "Total benign train accuarcy: 95.90733333333333\n",
      "Total benign train loss: 146.99439941346645\n",
      "\n",
      "[ Test epoch: 52 ]\n",
      "\n",
      "Test accuarcy: 89.48\n",
      "Test average loss: 0.0034941419683396815\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 53 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.1006830558180809\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.12400344759225845\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9296875\n",
      "Current benign train loss: 0.17347364127635956\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.09643984586000443\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.07273346185684204\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.14341841638088226\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.10251370072364807\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.056253302842378616\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.061156656593084335\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.07759378850460052\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.09969785809516907\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.07608363777399063\n",
      "\n",
      "Total benign train accuarcy: 96.35866666666666\n",
      "Total benign train loss: 134.59575323015451\n",
      "\n",
      "[ Test epoch: 53 ]\n",
      "\n",
      "Test accuarcy: 89.28\n",
      "Test average loss: 0.003591559924930334\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 54 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.07377810776233673\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.05596138909459114\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.04953620955348015\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.232057124376297\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.17266570031642914\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.028428560122847557\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.08571211248636246\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.07592391967773438\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.111466184258461\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.08186797797679901\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.06266409158706665\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.11438322067260742\n",
      "\n",
      "Total benign train accuarcy: 96.38933333333334\n",
      "Total benign train loss: 129.3666615318507\n",
      "\n",
      "[ Test epoch: 54 ]\n",
      "\n",
      "Test accuarcy: 89.28\n",
      "Test average loss: 0.0035112167470157146\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 55 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.10814254730939865\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.1273985654115677\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.08536588400602341\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.0611337274312973\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.1050194650888443\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.04090718924999237\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.05629829689860344\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.14304055273532867\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.0377848781645298\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.1428309679031372\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.12348698079586029\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.10115142166614532\n",
      "\n",
      "Total benign train accuarcy: 96.61133333333333\n",
      "Total benign train loss: 123.27750937081873\n",
      "\n",
      "[ Test epoch: 55 ]\n",
      "\n",
      "Test accuarcy: 89.31\n",
      "Test average loss: 0.0036209359981119633\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 56 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.04615006595849991\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.048393525183200836\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.13420017063617706\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.056679870933294296\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.14123529195785522\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.05292642116546631\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.11046431958675385\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.10218431055545807\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.0808015912771225\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.15230846405029297\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.08457131683826447\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.12119860202074051\n",
      "\n",
      "Total benign train accuarcy: 96.66733333333333\n",
      "Total benign train loss: 121.5952546223998\n",
      "\n",
      "[ Test epoch: 56 ]\n",
      "\n",
      "Test accuarcy: 89.12\n",
      "Test average loss: 0.0036817069426178933\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 57 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.11473570019006729\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.13624408841133118\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.06022873520851135\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.05702650174498558\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.07615548372268677\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.1344967931509018\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.06816810369491577\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.09290792793035507\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.07664511352777481\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.07649018615484238\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.06580453366041183\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.04122844338417053\n",
      "\n",
      "Total benign train accuarcy: 96.80133333333333\n",
      "Total benign train loss: 116.61885584145784\n",
      "\n",
      "[ Test epoch: 57 ]\n",
      "\n",
      "Test accuarcy: 89.43\n",
      "Test average loss: 0.0036034028142690657\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 58 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.1298251897096634\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.05970168858766556\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.12071572244167328\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.07035411149263382\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.10718438029289246\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.048170726746320724\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.13336527347564697\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.054933659732341766\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.0726616308093071\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.1003265306353569\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.07110010087490082\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.07510615140199661\n",
      "\n",
      "Total benign train accuarcy: 96.81933333333333\n",
      "Total benign train loss: 114.83721928484738\n",
      "\n",
      "[ Test epoch: 58 ]\n",
      "\n",
      "Test accuarcy: 88.72\n",
      "Test average loss: 0.00401292327940464\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 59 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.12234354019165039\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.06580305844545364\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9296875\n",
      "Current benign train loss: 0.1972997486591339\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.07448071241378784\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.11738227307796478\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.16402624547481537\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.0881657674908638\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.08918561041355133\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.051396626979112625\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.11093440651893616\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.06192410737276077\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.16448290646076202\n",
      "\n",
      "Total benign train accuarcy: 96.82266666666666\n",
      "Total benign train loss: 114.32752140052617\n",
      "\n",
      "[ Test epoch: 59 ]\n",
      "\n",
      "Test accuarcy: 89.02\n",
      "Test average loss: 0.003899697417020798\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 60 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.034924834966659546\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.06727387756109238\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.05841456726193428\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.11679793894290924\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.06363404542207718\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.14302730560302734\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.08272843807935715\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.9296875\n",
      "Current benign train loss: 0.1914503276348114\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.06394710391759872\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.1154514029622078\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.10747584700584412\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.07822025567293167\n",
      "\n",
      "Total benign train accuarcy: 96.85666666666667\n",
      "Total benign train loss: 113.87840850558132\n",
      "\n",
      "[ Test epoch: 60 ]\n",
      "\n",
      "Test accuarcy: 88.57\n",
      "Test average loss: 0.00390674849152565\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 61 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.1140136644244194\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.1360115259885788\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.10319142043590546\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.08134855329990387\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.07408803701400757\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.0700598806142807\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.051569484174251556\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.04889882728457451\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.02874627895653248\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.13215966522693634\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.13276231288909912\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.17699070274829865\n",
      "\n",
      "Total benign train accuarcy: 96.94666666666667\n",
      "Total benign train loss: 110.52689233794808\n",
      "\n",
      "[ Test epoch: 61 ]\n",
      "\n",
      "Test accuarcy: 89.09\n",
      "Test average loss: 0.0038957257151603698\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 62 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.07992692291736603\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.07772748917341232\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.10681244730949402\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.12400952726602554\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.0933682769536972\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.05247948318719864\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.18370658159255981\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.09202487021684647\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.08969256281852722\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.1182173565030098\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.0915418416261673\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.09826190024614334\n",
      "\n",
      "Total benign train accuarcy: 96.894\n",
      "Total benign train loss: 110.55269674025476\n",
      "\n",
      "[ Test epoch: 62 ]\n",
      "\n",
      "Test accuarcy: 88.79\n",
      "Test average loss: 0.003927333895862102\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 63 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.06388484686613083\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.08432158827781677\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.050607237964868546\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.1001715436577797\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.0481424406170845\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.060713015496730804\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.09197074919939041\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.12756574153900146\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.15928499400615692\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.07862745225429535\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.05901363864541054\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.10848981887102127\n",
      "\n",
      "Total benign train accuarcy: 96.886\n",
      "Total benign train loss: 110.37671127356589\n",
      "\n",
      "[ Test epoch: 63 ]\n",
      "\n",
      "Test accuarcy: 88.09\n",
      "Test average loss: 0.0045119223095476625\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 64 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.06444510072469711\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.09297928214073181\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.13491779565811157\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.15649619698524475\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.09315203875303268\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.10101845115423203\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.07224387675523758\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.04549809545278549\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.12637737393379211\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.08771591633558273\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.045824240893125534\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.12095727771520615\n",
      "\n",
      "Total benign train accuarcy: 96.852\n",
      "Total benign train loss: 111.91530168242753\n",
      "\n",
      "[ Test epoch: 64 ]\n",
      "\n",
      "Test accuarcy: 88.53\n",
      "Test average loss: 0.004105644542723894\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 65 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.05777491629123688\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.08068892359733582\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.07945876568555832\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.07216896861791611\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.18350644409656525\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.07226637750864029\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.036233700811862946\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.05364754796028137\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.11270967125892639\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.13805308938026428\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.0711643174290657\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.10588875412940979\n",
      "\n",
      "Total benign train accuarcy: 96.78466666666667\n",
      "Total benign train loss: 114.16627841070294\n",
      "\n",
      "[ Test epoch: 65 ]\n",
      "\n",
      "Test accuarcy: 88.28\n",
      "Test average loss: 0.004330092550814152\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 66 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.1106363907456398\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.0528305247426033\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.17667825520038605\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.063100166618824\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.05422305315732956\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.12446030229330063\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.15058191120624542\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.06448135524988174\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.09448022395372391\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.083412304520607\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.11247656494379044\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.10965273529291153\n",
      "\n",
      "Total benign train accuarcy: 96.87133333333334\n",
      "Total benign train loss: 111.85203634761274\n",
      "\n",
      "[ Test epoch: 66 ]\n",
      "\n",
      "Test accuarcy: 87.51\n",
      "Test average loss: 0.004485919058322906\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 67 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.1811428666114807\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.10988840460777283\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.11169898509979248\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.11604326963424683\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.08709748834371567\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.1010943278670311\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.10336422920227051\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.1107497587800026\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.9296875\n",
      "Current benign train loss: 0.15507397055625916\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.06370960921049118\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.07294151186943054\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.11817660927772522\n",
      "\n",
      "Total benign train accuarcy: 96.81533333333333\n",
      "Total benign train loss: 113.39406351186335\n",
      "\n",
      "[ Test epoch: 67 ]\n",
      "\n",
      "Test accuarcy: 87.13\n",
      "Test average loss: 0.00476240419074893\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 68 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.1211206242442131\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.09022971987724304\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.12193501740694046\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.06538160145282745\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.05284649133682251\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.05425557866692543\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.13083751499652863\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.043443042784929276\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.09252642840147018\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.12348990142345428\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.9296875\n",
      "Current benign train loss: 0.1798015832901001\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.15744146704673767\n",
      "\n",
      "Total benign train accuarcy: 96.85066666666667\n",
      "Total benign train loss: 112.18395573273301\n",
      "\n",
      "[ Test epoch: 68 ]\n",
      "\n",
      "Test accuarcy: 89.12\n",
      "Test average loss: 0.003826578788459301\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 69 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.10447922348976135\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.03917071223258972\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.11866866052150726\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.040024470537900925\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.12454679608345032\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.09022240340709686\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.1740601509809494\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.06283646821975708\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.05268426984548569\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.06076887995004654\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.10431790351867676\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.08025538921356201\n",
      "\n",
      "Total benign train accuarcy: 96.71333333333334\n",
      "Total benign train loss: 116.14944110251963\n",
      "\n",
      "[ Test epoch: 69 ]\n",
      "\n",
      "Test accuarcy: 88.53\n",
      "Test average loss: 0.004027238255739212\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 70 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.05723535269498825\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.09639124572277069\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.1084306389093399\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.08610044419765472\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.05283425375819206\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.921875\n",
      "Current benign train loss: 0.19697360694408417\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.03213110938668251\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.10457112640142441\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.12786652147769928\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.025417236611247063\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.11215506494045258\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.1382913589477539\n",
      "\n",
      "Total benign train accuarcy: 96.79933333333334\n",
      "Total benign train loss: 112.66332380846143\n",
      "\n",
      "[ Test epoch: 70 ]\n",
      "\n",
      "Test accuarcy: 86.33\n",
      "Test average loss: 0.0055352047771215435\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 71 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.06375288963317871\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.10104642063379288\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.0904298946261406\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.04799406975507736\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.06318236887454987\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.07198678702116013\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.10798516869544983\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.08755839616060257\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.1477583646774292\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.1344543695449829\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.030534595251083374\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.07362988591194153\n",
      "\n",
      "Total benign train accuarcy: 96.72\n",
      "Total benign train loss: 114.74810434877872\n",
      "\n",
      "[ Test epoch: 71 ]\n",
      "\n",
      "Test accuarcy: 86.72\n",
      "Test average loss: 0.005150361774861813\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 72 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.09082046896219254\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.1397823542356491\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.046297043561935425\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.10396786779165268\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.15419107675552368\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.15182867646217346\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.12454837560653687\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.11656934767961502\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.12733696401119232\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.10002357512712479\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.10773109644651413\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.13979168236255646\n",
      "\n",
      "Total benign train accuarcy: 96.67666666666666\n",
      "Total benign train loss: 116.73841963894665\n",
      "\n",
      "[ Test epoch: 72 ]\n",
      "\n",
      "Test accuarcy: 84.82\n",
      "Test average loss: 0.005990959271788597\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 73 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.07386592775583267\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.10875552892684937\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.02495487593114376\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.13943982124328613\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.10529956221580505\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.08716221153736115\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.12501858174800873\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.05030714347958565\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.17372477054595947\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.09602399915456772\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.0812988355755806\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.08370702713727951\n",
      "\n",
      "Total benign train accuarcy: 96.63533333333334\n",
      "Total benign train loss: 116.84748505242169\n",
      "\n",
      "[ Test epoch: 73 ]\n",
      "\n",
      "Test accuarcy: 87.62\n",
      "Test average loss: 0.004454011899977923\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 74 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.040412548929452896\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.04436312988400459\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.03638995811343193\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.10456181317567825\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9296875\n",
      "Current benign train loss: 0.19060759246349335\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.06208853796124458\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.04856029897928238\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.0754161849617958\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.08660139888525009\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.09877489507198334\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.1351158320903778\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.052029721438884735\n",
      "\n",
      "Total benign train accuarcy: 96.628\n",
      "Total benign train loss: 116.7832350358367\n",
      "\n",
      "[ Test epoch: 74 ]\n",
      "\n",
      "Test accuarcy: 87.01\n",
      "Test average loss: 0.004807263992726803\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 75 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.08768516778945923\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.08169379085302353\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.921875\n",
      "Current benign train loss: 0.17623329162597656\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.03675326332449913\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.07652274519205093\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.08546021580696106\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.10682669281959534\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.19584615528583527\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.1977826952934265\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.15156826376914978\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.08911139518022537\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.1317494660615921\n",
      "\n",
      "Total benign train accuarcy: 96.63733333333333\n",
      "Total benign train loss: 117.17855137959123\n",
      "\n",
      "[ Test epoch: 75 ]\n",
      "\n",
      "Test accuarcy: 88.41\n",
      "Test average loss: 0.004208515438437462\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 76 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.10166860371828079\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.06168974190950394\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.1012701764702797\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.06934612989425659\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.08429104089736938\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.038537733256816864\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.9296875\n",
      "Current benign train loss: 0.17356370389461517\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.08369467407464981\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.08930885046720505\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.11456695944070816\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.10315351188182831\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.06628641486167908\n",
      "\n",
      "Total benign train accuarcy: 96.61533333333334\n",
      "Total benign train loss: 117.9138593096286\n",
      "\n",
      "[ Test epoch: 76 ]\n",
      "\n",
      "Test accuarcy: 87.96\n",
      "Test average loss: 0.0045876334384083745\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 77 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.14168207347393036\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.025401201099157333\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.09178396314382553\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.1502484828233719\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.09180808067321777\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.08827197551727295\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.07723342627286911\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.11215489357709885\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.10365583002567291\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.08715103566646576\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.08974196761846542\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.07934964448213577\n",
      "\n",
      "Total benign train accuarcy: 96.61933333333333\n",
      "Total benign train loss: 118.49772986210883\n",
      "\n",
      "[ Test epoch: 77 ]\n",
      "\n",
      "Test accuarcy: 88.41\n",
      "Test average loss: 0.004100597277283668\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 78 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.04390101879835129\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.08095818012952805\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.07642700523138046\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.05102047324180603\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.1069553941488266\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.0953964963555336\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.08329486846923828\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.07365799695253372\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.06791616976261139\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.1374274045228958\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.09656815230846405\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.14032764732837677\n",
      "\n",
      "Total benign train accuarcy: 96.59\n",
      "Total benign train loss: 117.69157040305436\n",
      "\n",
      "[ Test epoch: 78 ]\n",
      "\n",
      "Test accuarcy: 87.83\n",
      "Test average loss: 0.004541964660584927\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 79 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.1313255876302719\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.10612410306930542\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.921875\n",
      "Current benign train loss: 0.1806158721446991\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.13376730680465698\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.0825071707367897\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.11974654346704483\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.10309887677431107\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.07543223351240158\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.041181448847055435\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.13439291715621948\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.23794248700141907\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.0750894621014595\n",
      "\n",
      "Total benign train accuarcy: 96.57733333333333\n",
      "Total benign train loss: 119.83707099407911\n",
      "\n",
      "[ Test epoch: 79 ]\n",
      "\n",
      "Test accuarcy: 86.39\n",
      "Test average loss: 0.00564073096960783\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 80 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.05742653086781502\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.07577718049287796\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.08105400949716568\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.030001463368535042\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.06597162038087845\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.1213156133890152\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.07324770838022232\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.08721867203712463\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.11764337122440338\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.03434573486447334\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.08424010127782822\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.13640528917312622\n",
      "\n",
      "Total benign train accuarcy: 96.58866666666667\n",
      "Total benign train loss: 119.0458267852664\n",
      "\n",
      "[ Test epoch: 80 ]\n",
      "\n",
      "Test accuarcy: 87.24\n",
      "Test average loss: 0.00456029345691204\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 81 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9296875\n",
      "Current benign train loss: 0.23764990270137787\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.08327823132276535\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.05889208987355232\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.1604187935590744\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.1011447161436081\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.11655273288488388\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.14000603556632996\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.10082025825977325\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.2206311970949173\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.14392052590847015\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.20287375152111053\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.04708988964557648\n",
      "\n",
      "Total benign train accuarcy: 96.53133333333334\n",
      "Total benign train loss: 119.62951058708131\n",
      "\n",
      "[ Test epoch: 81 ]\n",
      "\n",
      "Test accuarcy: 86.33\n",
      "Test average loss: 0.005173429268598557\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 82 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9296875\n",
      "Current benign train loss: 0.16589583456516266\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.09949155151844025\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.0835304707288742\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.03695426508784294\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.07606697082519531\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.09974026679992676\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.11706231534481049\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.060098111629486084\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.09197207540273666\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.0943341851234436\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.04746871441602707\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.08591999113559723\n",
      "\n",
      "Total benign train accuarcy: 96.59533333333333\n",
      "Total benign train loss: 118.63222656212747\n",
      "\n",
      "[ Test epoch: 82 ]\n",
      "\n",
      "Test accuarcy: 87.02\n",
      "Test average loss: 0.005032418888807297\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 83 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9140625\n",
      "Current benign train loss: 0.18847183883190155\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.04898112267255783\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.90625\n",
      "Current benign train loss: 0.17524857819080353\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.052999719977378845\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.08213039487600327\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.09607671201229095\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.0707133561372757\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.08153822273015976\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.10616406798362732\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.08864392340183258\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.14879702031612396\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.06436631083488464\n",
      "\n",
      "Total benign train accuarcy: 96.53666666666666\n",
      "Total benign train loss: 120.95779725536704\n",
      "\n",
      "[ Test epoch: 83 ]\n",
      "\n",
      "Test accuarcy: 86.85\n",
      "Test average loss: 0.004803882484138012\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 84 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.11340437829494476\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.05880366638302803\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.12621228396892548\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.07066983729600906\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.049243681132793427\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.10660340636968613\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.9296875\n",
      "Current benign train loss: 0.21238502860069275\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.14801892638206482\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.06777852773666382\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.06156788021326065\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.18438108265399933\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.0499187633395195\n",
      "\n",
      "Total benign train accuarcy: 96.6\n",
      "Total benign train loss: 118.24773059599102\n",
      "\n",
      "[ Test epoch: 84 ]\n",
      "\n",
      "Test accuarcy: 85.18\n",
      "Test average loss: 0.0056692128404974935\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 85 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.1303335279226303\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.10778491199016571\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.07017353177070618\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.06267523020505905\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.1684427261352539\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.921875\n",
      "Current benign train loss: 0.22175352275371552\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.12436406314373016\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.08259550482034683\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.09104221314191818\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.921875\n",
      "Current benign train loss: 0.15024247765541077\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.12997034192085266\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.10457675158977509\n",
      "\n",
      "Total benign train accuarcy: 96.51066666666667\n",
      "Total benign train loss: 120.70087374001741\n",
      "\n",
      "[ Test epoch: 85 ]\n",
      "\n",
      "Test accuarcy: 87.31\n",
      "Test average loss: 0.004652978105843067\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 86 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.14068461954593658\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.07480229437351227\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.10743166506290436\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.07808533310890198\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.08816016465425491\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.08304452896118164\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.11991437524557114\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.0903247743844986\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.05908665433526039\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.0952664241194725\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.06650737673044205\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.10373298823833466\n",
      "\n",
      "Total benign train accuarcy: 96.64866666666667\n",
      "Total benign train loss: 117.33718746900558\n",
      "\n",
      "[ Test epoch: 86 ]\n",
      "\n",
      "Test accuarcy: 85.55\n",
      "Test average loss: 0.005863055084645748\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 87 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.12753720581531525\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.10664733499288559\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.09672275185585022\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.0775180235505104\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.11906135827302933\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.08781309425830841\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.133926123380661\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.1001071184873581\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.1413244903087616\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.9296875\n",
      "Current benign train loss: 0.21858341991901398\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.12818357348442078\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.07381851971149445\n",
      "\n",
      "Total benign train accuarcy: 96.53533333333333\n",
      "Total benign train loss: 120.08780193515122\n",
      "\n",
      "[ Test epoch: 87 ]\n",
      "\n",
      "Test accuarcy: 84.86\n",
      "Test average loss: 0.005931942576169968\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 88 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.06966757774353027\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.08191245794296265\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.15817363560199738\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.08537057787179947\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.08010251075029373\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.052288323640823364\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.09277301281690598\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.08125606179237366\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.1553119271993637\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.08113934099674225\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.10865505784749985\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.13452588021755219\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total benign train accuarcy: 96.52133333333333\n",
      "Total benign train loss: 120.24106722138822\n",
      "\n",
      "[ Test epoch: 88 ]\n",
      "\n",
      "Test accuarcy: 86.17\n",
      "Test average loss: 0.005592467391490936\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 89 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.100846067070961\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.19329464435577393\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.12529054284095764\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.07734140753746033\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.08244490623474121\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.047136206179857254\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.04376944527029991\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.09750961512327194\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.9296875\n",
      "Current benign train loss: 0.15985511243343353\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.18244388699531555\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.07543235272169113\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.04125512018799782\n",
      "\n",
      "Total benign train accuarcy: 96.582\n",
      "Total benign train loss: 120.46390817128122\n",
      "\n",
      "[ Test epoch: 89 ]\n",
      "\n",
      "Test accuarcy: 87.74\n",
      "Test average loss: 0.004532623558491469\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 90 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.04885290563106537\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.0818476751446724\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.051392316818237305\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.07122626155614853\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.05831347033381462\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.10371993482112885\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.05591651424765587\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.10863343626260757\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.04215973988175392\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.06084591895341873\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.07860395312309265\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.06790249049663544\n",
      "\n",
      "Total benign train accuarcy: 98.144\n",
      "Total benign train loss: 68.63676503580064\n",
      "\n",
      "[ Test epoch: 90 ]\n",
      "\n",
      "Test accuarcy: 90.7\n",
      "Test average loss: 0.003317542453855276\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 91 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.0708816796541214\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.05266717076301575\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.02417551726102829\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.036075882613658905\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.0665794238448143\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.060792405158281326\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.01313739363104105\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.05235027149319649\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.027393987402319908\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.0640542283654213\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.030175156891345978\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.011391948908567429\n",
      "\n",
      "Total benign train accuarcy: 98.476\n",
      "Total benign train loss: 56.015750323887914\n",
      "\n",
      "[ Test epoch: 91 ]\n",
      "\n",
      "Test accuarcy: 90.75\n",
      "Test average loss: 0.0033619592674076558\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 92 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.03997983783483505\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.008174768649041653\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.03618340194225311\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00795834232121706\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.05135464295744896\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.022230295464396477\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.03882096707820892\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.030720815062522888\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.050084177404642105\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.039796169847249985\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.021197879686951637\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.009953144006431103\n",
      "\n",
      "Total benign train accuarcy: 98.60333333333334\n",
      "Total benign train loss: 50.91096450062469\n",
      "\n",
      "[ Test epoch: 92 ]\n",
      "\n",
      "Test accuarcy: 90.79\n",
      "Test average loss: 0.0033004783317446707\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 93 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.03640815615653992\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.044837918132543564\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.030946964398026466\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.02146109566092491\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.02350192330777645\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.062238503247499466\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.044312771409749985\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.02779374085366726\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.047557614743709564\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.05139221251010895\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.08357425779104233\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.05636823922395706\n",
      "\n",
      "Total benign train accuarcy: 98.68066666666667\n",
      "Total benign train loss: 48.71667583612725\n",
      "\n",
      "[ Test epoch: 93 ]\n",
      "\n",
      "Test accuarcy: 91.16\n",
      "Test average loss: 0.0032963158257305622\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 94 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.013893920928239822\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.05525072291493416\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.06771846115589142\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.005791478790342808\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.0533369742333889\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.011255362071096897\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.020939523354172707\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.032324112951755524\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.016884230077266693\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.026097217574715614\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.040960900485515594\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.026844508945941925\n",
      "\n",
      "Total benign train accuarcy: 98.776\n",
      "Total benign train loss: 46.07106253900565\n",
      "\n",
      "[ Test epoch: 94 ]\n",
      "\n",
      "Test accuarcy: 90.85\n",
      "Test average loss: 0.0033071825355291368\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 95 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.02997042052447796\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.022634517401456833\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.06312759220600128\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.06365350633859634\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.010232529602944851\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.030814379453659058\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.017986245453357697\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.03997453674674034\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.04296352341771126\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.047570694237947464\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.015066736377775669\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.042795173823833466\n",
      "\n",
      "Total benign train accuarcy: 98.782\n",
      "Total benign train loss: 44.852669338695705\n",
      "\n",
      "[ Test epoch: 95 ]\n",
      "\n",
      "Test accuarcy: 91.01\n",
      "Test average loss: 0.003313121269643307\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 96 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.031510669738054276\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.04277001693844795\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.03994199261069298\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.07808593660593033\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.053007133305072784\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.034411169588565826\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.0958719477057457\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.013378359377384186\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.08461613953113556\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.05896272137761116\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.05238967761397362\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.029682980850338936\n",
      "\n",
      "Total benign train accuarcy: 98.86933333333333\n",
      "Total benign train loss: 42.31792570557445\n",
      "\n",
      "[ Test epoch: 96 ]\n",
      "\n",
      "Test accuarcy: 90.85\n",
      "Test average loss: 0.00332327601313591\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 97 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.030429404228925705\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.011872632429003716\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.02471824921667576\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.016685962677001953\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.016589399427175522\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.07102500647306442\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.04017515107989311\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.019559377804398537\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.04077162593603134\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.017879793420433998\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.05330918729305267\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.03761155158281326\n",
      "\n",
      "Total benign train accuarcy: 98.884\n",
      "Total benign train loss: 41.396012612152845\n",
      "\n",
      "[ Test epoch: 97 ]\n",
      "\n",
      "Test accuarcy: 90.9\n",
      "Test average loss: 0.003267337244004011\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 98 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.028160342946648598\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.0717703104019165\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.1013045608997345\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.0903959646821022\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.02117745205760002\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.03616001084446907\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.01977282203733921\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.07032721489667892\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.03138145059347153\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.02244301326572895\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.0287492498755455\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.0323808379471302\n",
      "\n",
      "Total benign train accuarcy: 98.91333333333333\n",
      "Total benign train loss: 40.96247763838619\n",
      "\n",
      "[ Test epoch: 98 ]\n",
      "\n",
      "Test accuarcy: 91.33\n",
      "Test average loss: 0.0032821334861218928\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 99 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.03358076885342598\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.045790210366249084\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.02898940071463585\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.014352693222463131\n",
      "\n",
      "Current batch: 400\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.03113608993589878\n",
      "\n",
      "Current batch: 500\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.01807340234518051\n",
      "\n",
      "Current batch: 600\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.08291097730398178\n",
      "\n",
      "Current batch: 700\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.03415129333734512\n",
      "\n",
      "Current batch: 800\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.030639687553048134\n",
      "\n",
      "Current batch: 900\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.01680903509259224\n",
      "\n",
      "Current batch: 1000\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.02653052657842636\n",
      "\n",
      "Current batch: 1100\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.0564204677939415\n",
      "\n",
      "Total benign train accuarcy: 98.9\n",
      "Total benign train loss: 40.64374693413265\n",
      "\n",
      "[ Test epoch: 99 ]\n",
      "\n",
      "Test accuarcy: 91.28\n",
      "Test average loss: 0.003281441016495228\n",
      "Model Saved!\n",
      "Total: 14494.10172009468 sec\n",
      "Train: 14490.816592693329 sec\n"
     ]
    }
   ],
   "source": [
    "train_start = time.time()\n",
    "\n",
    "# for epoch in range(0, 200):\n",
    "for epoch in range(0, 100):\n",
    "    adjust_learning_rate(optimizer, epoch)\n",
    "    train(epoch)\n",
    "    test(epoch)\n",
    "\n",
    "end = time.time()\n",
    "print(f'Total: {end - start} sec')\n",
    "print(f'Train: {end - train_start} sec')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOPIzvdWtH9nlTSWQL5mAew",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "ResNet18_CIFAR10_Train",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0dea8eb11bbc4c779008942559cff4db": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a1d1034a83034942b9174d8a46447ef0",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ff98ccdfba314fe5a6d9e477c6d4bd4b",
      "value": 1
     }
    },
    "0ec3fad637ae4f5d8f9aa3a84e2cd7bd": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1c9448bb0e7b4d4bb219f9313bff333f",
      "placeholder": "​",
      "style": "IPY_MODEL_516e46a6995e4c10b928f2dbbbdd005a",
      "value": " 170500096/? [00:20&lt;00:00, 100483168.85it/s]"
     }
    },
    "1c9448bb0e7b4d4bb219f9313bff333f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "516e46a6995e4c10b928f2dbbbdd005a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "987ce5cdc16f4c568f979204fa7506f2": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a1d1034a83034942b9174d8a46447ef0": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c33e7c07bfc847efa64429ee4eb640db": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0dea8eb11bbc4c779008942559cff4db",
       "IPY_MODEL_0ec3fad637ae4f5d8f9aa3a84e2cd7bd"
      ],
      "layout": "IPY_MODEL_987ce5cdc16f4c568f979204fa7506f2"
     }
    },
    "ff98ccdfba314fe5a6d9e477c6d4bd4b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
